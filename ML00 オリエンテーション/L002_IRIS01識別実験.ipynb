{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRIS データの読み込み\n",
    "iris = load_iris()\n",
    "columns = ['がく片の長さ','がく片の幅','花片の長さ','花片の幅']\n",
    "X = pd.DataFrame(iris.data, columns = columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape # データ個数×特徴数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[0] # 最初のデータ（4次元ベクトル）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target # .targetにラベルが入っている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape # データ個数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names # ラベルの意味"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Iris flower data set @ Wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "\n",
    "\n",
    "|class|image|license|\n",
    "|------|------|--|\n",
    "| Iris setosa |<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg\" width=200> | CC BY-SA 3.0 by Radomil |\n",
    "|Iris versicolor|<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg\" width=200>|CC BY-SA 3.0 by Danielle Langlois|\n",
    "|Iris virginica|<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/736px-Iris_virginica.jpg\" width=200>|CC BY-SA 2.0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(iris.DESCR) # データの詳細な記述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習器を作って学習させてみよう\n",
    "その前にデータをシャッフル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ShuffleSplit(n_splits=1,      # 分割を1個生成\n",
    "                  train_size=0.5,  # 学習は半分\n",
    "                  test_size =0.5,  # テストも半分\n",
    "                  random_state=0)  # 乱数種（再現用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータのインデックスを作成\n",
    "train_index, test_index = next(ss.split(X))\n",
    "train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X.iloc[train_index], X.iloc[test_index] # 学習データ，テストデータ\n",
    "y_train, y_test = y[train_index], y[test_index] # 学習データのラベル，テストデータのラベル\n",
    "y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# シャッフルされて偏りがないことに注意せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線型回帰識別器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形モデルを準備\n",
    "from sklearn import linear_model\n",
    "# 識別器を作成\n",
    "clf = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train); # 識別器の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_train, y_train)) # 学習データの精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_test, y_test)) # テストデータの精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "１回だけではたまたまの結果なのかもしれないので、１０回試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ShuffleSplit(n_splits=10,     # 分割を10個生成\n",
    "                  train_size=0.5,  # 学習は半分\n",
    "                  test_size =0.5,  # テストも半分\n",
    "                  random_state=0)  # 乱数種（再現用）\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in ss.split(X): # 学習データとテストデータのインデックスを作成\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] # 学習データ，テストデータ\n",
    "    y_train, y_test = y[train_index], y[test_index] # 学習データのラベル，テストデータのラベル\n",
    "\n",
    "    clf.fit(X_train, y_train)         # 識別器の学習\n",
    "    score = clf.score(X_test, y_test) # テストデータの精度\n",
    "    scores.append(score)\n",
    "\n",
    "scores = np.array(scores)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean() # 正解率の平均値を求める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.std() # 正解率の標準偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"識別実験結果　認識率　{0} +/- {1}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlibの準備\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの分量を0.1, 0.2, ..., 0.9と変えて実験してみる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.arange(0.1, 1.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean = []\n",
    "all_std  = []\n",
    "\n",
    "for train_size in train_sizes: #  ループを回る毎に学習に用いる割合を増やして繰り返す\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=100,\n",
    "                      train_size=train_size,     \n",
    "                      test_size=1-train_size)\n",
    "\n",
    "    scores = []\n",
    "    for train_index, test_index in ss.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    print(\"train_size {0:.0f}%: {1:4.2f} +/- {2:4.2f} %\".format(train_size    * 100, \n",
    "                                                                scores.mean() * 100, \n",
    "                                                                scores.std()  * 100))\n",
    "    all_mean.append(scores.mean() * 100)\n",
    "    all_std.append(scores.std() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# グラフ化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, all_mean) #  学習データの割合に対する平均認識率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, all_mean)  #  学習データの割合に対する平均認識率\n",
    "plt.ylim(70,100)\n",
    "plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, all_mean)\n",
    "plt.ylim(70,100)\n",
    "plt.xlim(0,1)\n",
    "plt.errorbar(train_sizes, all_mean, yerr=all_std)\n",
    "plt.xlabel(\"training size [%]\")\n",
    "plt.ylabel(\"recognition rate\")\n",
    "plt.title(\"Average of 10 hold-out tests for different training size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 課題\n",
    "ML00 で出てきた他の識別器を使って同じ実験を試し、識別性能を比較せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# オブジェクト作成\n",
    "clf = svm.LinearSVC(C=1)\n",
    "clf = svm.LinearSVC(C=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
