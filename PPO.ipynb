{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/MLLesson/blob/master/PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CS72K-uiAQn"
      },
      "source": [
        "# AtariスペースインベーダのPPO による強化学習の実装\n",
        "\n",
        "参考\n",
        "\n",
        "- https://github.com/vpj/rl_samples\n",
        "http://blog.varunajayasiri.com/ml/ppo_pytorch.html\n",
        "\n",
        "基本的なアルゴリズムは上記参考プログラムに準拠しています。\n",
        "\n",
        "違いはクラウドログサービスを WandB に変更してあることと、\n",
        "\n",
        "実験的にεグリーディを pytorch 頼りとは別に設定できるようにしてありますが、使う必要ないようです。\n",
        "\n",
        "#### 他に参考にしたサイト\n",
        "\n",
        "- [PythonでPPOを実装してみた](https://qiita.com/oki_uta_aiota/items/a15ba5de6ed3c1268ed3#%E5%85%A8%E4%BD%93%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S2e1GxIKGiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860c4623-3563-4db5-b849-f390a5081151"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(time.time())\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(repr(device))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device(type='cuda', index=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7B5y3RLEPsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3089bd5f-4725-44d0-a804-921e63215594"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ndL3LBK3Vg"
      },
      "source": [
        "# 外部ライブラリの追加"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7cJQgKWihEN"
      },
      "source": [
        "!pip install pfrl > /dev/null\n",
        "!pip install wandb > /dev/null\n",
        "!pip install fastprogress > /dev/null\n",
        "#!pip install gym[atari] > /dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avyWPx9-iAQ-"
      },
      "source": [
        "import multiprocessing\n",
        "import multiprocessing.connection\n",
        "from typing import Dict, List\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "\n",
        "import gym\n",
        "from gym import ObservationWrapper\n",
        "from gym.spaces import Box\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.distributions import Categorical\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from pfrl.wrappers.atari_wrappers import FrameStack,NoopResetEnv,MaxAndSkipEnv\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvyoQhmZLybp"
      },
      "source": [
        "# ラッパー定義\r\n",
        "\r\n",
        "mode 0: １エピソード１ライフ、画面はリセット  \r\n",
        "mode 1: １エピソード１ライフ、画面は継続  \r\n",
        "mode 3: １エピソード３ライフ　（mode 2 でも同じ）  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq2fQjdZiARA"
      },
      "source": [
        "class myCrop(ObservationWrapper):\n",
        "    def __init__(self, env, tmgn=0, bmgn=0,lmgn=0,rmgn=0,igcolors=[],bgcolor=[0,0,0]):\n",
        "        super(myCrop, self).__init__(env)\n",
        "        self.tmgn, self.bmgn = tmgn, bmgn\n",
        "        self.lmgn, self.rmgn = lmgn, rmgn\n",
        "        self.igcolors, self.bgcolors = igcolors, bgcolor\n",
        "        self.observation_space = Box(low=0, high=255, shape=(84,84), dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        img_mask = np.zeros(obs.shape[:2],np.uint8)\n",
        "        for color in self.igcolors:\n",
        "            bgrLower = np.array(color)    \n",
        "            bgrUpper = np.array(color)\n",
        "            tmask = cv2.inRange(obs, bgrLower, bgrUpper) \n",
        "            img_mask = cv2.bitwise_or(img_mask,tmask)\n",
        "        obs = cv2.bitwise_and(obs,obs,mask=255-img_mask) # 元画像とマスクを合成\n",
        "        RIGHT=obs.shape[1]-self.rmgn\n",
        "        BOTTOM=obs.shape[0]-self.bmgn\n",
        "        obs = obs[self.tmgn:BOTTOM,self.lmgn:RIGHT]\n",
        "        obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
        "        observation = cv2.resize(obs, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        return observation\n",
        "\n",
        "class myFrameStack(FrameStack):\n",
        "    def __init__(self, env, k=8, mode=0,demo=False):\n",
        "        super(myFrameStack, self).__init__(env, k=k, channel_order=\"chw\")\n",
        "        self.lives = 0\n",
        "        self.lsumrewards = 0\n",
        "        self.localsteps = 0\n",
        "        self.demo = demo\n",
        "        self.mode = mode\n",
        "    def reset(self):\n",
        "        ob = self.env.reset()\n",
        "        for _ in range(self.k):\n",
        "          self.frames.append(ob)\n",
        "        return self._reset()\n",
        "    def _reset(self):\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        self.lsumrewards = 0\n",
        "        self.localsteps = 0\n",
        "        return  np.array([list(self.frames)])\n",
        "    def step(self, action):\n",
        "        self.localsteps += 1  \n",
        "        ob, reward, done1, info = self.env.step(action)\n",
        "        self.lsumrewards += reward\n",
        "        self.frames.append(ob)\n",
        "        returnobs = np.array([list(self.frames)])\n",
        "        episode_info = None\n",
        "        if self.demo:\n",
        "            return returnobs,reward,done1,info\n",
        "        # 残機数確認\n",
        "        else: # if train mode\n",
        "            lives = self.env.unwrapped.ale.lives()\n",
        "            if done1 or ( self.mode < 2 and lives < self.lives): # １機死んだら終了とする\n",
        "                done = True\n",
        "                episode_info = {\"reward\": self.lsumrewards, \"length\": self.localsteps}\n",
        "                if done1 or self.mode == 0: \n",
        "                  self.reset() \n",
        "                elif self.mode == 1: # mode 1 ライフが減っただけの場合はシーンは継続\n",
        "                  self._reset()\n",
        "            else: # not done1 adn mode > 1  \n",
        "                done = False\n",
        "            return returnobs, reward, done, episode_info\n",
        "\n",
        "def mkenv(envname,k=8,skip=1,tmgn=0,bmgn=0,lmgn=0,rmgn=0,igcolors=[],noop_max=30, mode = 0, demo=False):\n",
        "  env=gym.make(envname)\n",
        "  if noop_max > 0:\n",
        "      env = NoopResetEnv(env, noop_max=noop_max)\n",
        "  if skip > 1:\n",
        "      env = MaxAndSkipEnv(env, skip=skip)\n",
        "  env=myCrop(env, tmgn=tmgn, bmgn=bmgn, lmgn=lmgn, rmgn=rmgn, igcolors=igcolors)\n",
        "  env=myFrameStack(env,k=k,mode=mode,demo=demo)\n",
        "  return env"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWIH0JlWiARD"
      },
      "source": [
        "# Game Environment の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc2-DseiARG"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "random.seed(datetime.now())\n",
        "DEFAULTSEED = random.randint(1, 10000)\n",
        "def Game(seed=DEFAULTSEED,k=8,skip=1,noop_max=30, mode = 0, demo=False):\n",
        "    ENV_NAME = 'SpaceInvadersNoFrameskip-v4'\n",
        "    Tmgn=10\n",
        "    Bmgn=12\n",
        "    Lmgn=8\n",
        "    Rmgn=8\n",
        "    #NOCOLOR=[[162,134,56]]  # 背景と同一視するカラー\n",
        "    NOCOLOR=[]\n",
        "\n",
        "    env = mkenv(ENV_NAME,k,skip,Tmgn,Bmgn,Lmgn,Rmgn,NOCOLOR,noop_max=noop_max, mode = mode,demo=demo)\n",
        "    env.seed(seed)\n",
        "    return env"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhWKKV7miARI"
      },
      "source": [
        "### 補足\n",
        "**k** : 過去何フレーム分の画面をデータとするか  \n",
        "**skip** : 何フレームおきにサンプリングするか。値は奇数とすべき。※\n",
        "**Tmgn,Bmgn,Lmgn,Rmgn** カットする余白量  \n",
        "**NOCOLOR** 黒に置き換える色をRGB指定。複数指定可能  \n",
        "上の設定はインベーダ決め打ち\n",
        "\n",
        "※　理由は、インベーダゲームは自弾の表示と敵の弾の表示が一方が偶数フレーム、他方が奇数フレームとなっているので、skipを偶数にするとどちらかが表示されなくなるから。\n",
        "\n",
        "\n",
        "## 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZisujiNyiARJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "cda81de6-b8e9-4147-cdfb-a0dbe01c7935"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "DEFAULTSEED = random.seed(datetime.now())\n",
        "\n",
        "# 原画像が表示できるかテスト\n",
        "game = Game(DEFAULTSEED,7)\n",
        "orgimg = game.render(mode='rgb_array')\n",
        "display(Image.fromarray(orgimg))\n",
        "display(orgimg.shape)\n",
        "\n",
        "# リセット画像の確認\n",
        "plt.figure(figsize=(8,4),dpi=150)\n",
        "imgs = game.reset()\n",
        "imgs = imgs[0]\n",
        "for i,img in enumerate(imgs):\n",
        "    plt.subplot(2,8,i+1)\n",
        "    plt.imshow(img)\n",
        "# ステップ画像の確認\n",
        "for _ in range(60):\n",
        "  imgs,r,d,i= game.step(game.action_space.sample()) \n",
        "imgs = imgs[0]\n",
        "for i,img in enumerate(imgs):\n",
        "    plt.subplot(2,8,i+9)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# Check types\n",
        "display(imgs.shape,imgs[0,0,0],imgs[0,40,40],type(imgs[0,0,0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAADn0lEQVR4nO3dsa7TVhgHcF/EM3QqDJ0qVV2YeIcuFUwsPEjUscqDsMPWd2BiqZA6dejlQRiCbq3cOD4mx/6Ov/P7DYhEf4xPPn9x7OM4wwAAAAAAe3A3fvDizxez/+DTH59WW5lza6/Pu+PL2czbw8fvXv5Sa6zP3Xxk2tICtLYBLbW0AC1sQJMdPFWYqA5eY33GBZgqTFQH11qfah1cUoDWNqCllhaghQ1IB3+jgy/QwXWfX4MO/kYHX6CD6z6/BsfBMxwHz3AcXJ4HAAAAAGCR4/GZfB5nw5sdbW/5fTsN72GQha9OP/ndGw+1ZLS95WPdNB88djbUw+FevgVPqizlNNrTIE9/Xt+0e8sHqtPBj4d3fYvuLR+oTgeTXGuHJa3lA1Xo4IuHDVfG3FseAAAA2Moqs0klJ2Z7y0epOZs09VA+ULXJhoetuHBz7i0fpcJb9NT2OzXy3vK719rJ/dbysZ7WWtDhcD++zkG+ESb8mdPaW2Jr+Vg6ODkFBgAAAPjfxbN0s6f6+snHciYruWoFPjv5Lt+IavPBw/Kh9pbfsYcps8K5s97ySRwX3nWmt3wIH7KSU2DKtPaptbX8jj3eFV3fOfWWBwAAALbiHh0b5aO4R8cW+UDVbic8FN/ivrd8LLf03yIfqM5b9NnwZkfbWz6D1qbnWstHMeFPgdY+tbaWD6SDmXNx+y05zOgkDwAAAGzFFR0b5aO4omOLfKCaV3QMw3A43JdfEdFJPpbJhuRq3oRlWL4h95bfq9M4T1+TLRlzb/ndGw+y/AXqJx/IPjg5BU6u5q0MxxcalhxKdpUHAAAA9mXp8X5v+RCu6NgiH6jyFR3Xn+wzH8vP6myU37fW3hJbywcyXUiB1q6gaC2/b629mq3lY3mLZk5rn1dbywMAAAAAAAAAAAAAAPSq2q+u3OKv1z8//P239/9YfkW+fJZcfIHHm//jh5Z/o/gCsyoFTk6Bk1Pg5BQ4OQVOToGTCy7wxaPGioeSe1/+7XRwcgqcnAInp8DJKXBylX8B/PuM51DX+Ai69+XfQgcDAAAAAA1o4rtJUd4dX85m3h4+brAm63EuOrmuO3jKuLN1ME1rYj44Ssk+eO90cHL2wRfYB7Mb9sHJ6eDkZvbBv7/5YZv1YCWTBa5Y2v9++XEYhuefv9Ra4H69+vWnYRg+/P3vZv/jUz2am31wcgqcnAInd2cfnJsOTk6Bk1Pg5BQ4OQVOToGTU+DkFDi5r/CCTwE5labXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=160x210 at 0x7F1745920128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(210, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(7, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "numpy.uint8"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAGiCAYAAACidvTnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAXEQAAFxEByibzPwAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZAc533m+e+bWdVdfd+Nkzh5AaR4gJIokrqte0a2rJHDVoTtsMbh3bHXO/ZYO+E/LEsTkmZ2ZsPasCcm1vZ6LEu2Z2Nsa2T5kEaiZZk6KFIUSZGiQBIkARAgCKCBvo/q6q7KfPePqgbQF9Doq3759vOJYJRQlZ391O/pTvvtqsp03ntEREREREQkO6J6BxAREREREZHro4WciIiIiIhIxmghJyIiIiIikjFayImIiIiIiGSMFnIiIiIiIiIZo4WciIiIiIhIxmghJyIiIiIikjFayImIiIiIiGSMFnIiIiIiIiIZo4WciIiIiIhIxmghJyIiIiIikjFayImIiIiIiGSMFnIiIiIiIiIZo4WciIiIiIhIxtR9Ieeca3LOfdI594JzruScO+uc+6xzble9s8nqqddwqdtwqdtwqdswqddwqVtZCee9r983d64A/BPwBuAc8G1gH/B64CLwBu/9iboFlFVRr+FSt+FSt+FSt2FSr+FSt7JS9X5F7mNUf0gfAW723v+09/5e4KNAH/DZeoaTVVOv4VK34VK34VK3YVKv4VK3siJ1e0XOOdcAXAA6gCPe+x8sePxp4A7gtd77J+oQUVZBvYZL3YZL3YZL3YZJvYZL3cr1qOcrcg9Q/SE9vvCHtOYLtdv3b14kWQfqNVzqNlzqNlzqNkzqNVzqVlasngu5O2u3Ty7z+Nz9d2xCFlk/6jVc6jZc6jZc6jZM6jVc6lZWLFfH772ndntmmcfn7t+72m/gnDsPNAOvrHYfct221W7f7pw7esX9NwBF4N21f6+6V1C3daJuw7VUtzcARe/9dnQ8zjJ1GyYdj8O14d2qV1OuPB5ft3ou5Fprt8VlHp+q3bZda0cLftCv1OeiOGrs6D3sHeAAD1EZoolpANL2Jny8/L7jUgrTM+AcvqWRNOeq+1lq22ICs2VcHJMWclQK1Q2jpPr4chlWLIqodDaSFnx1Zwm42v8kV/2sY34M3PQsLo5ICnmSwjL78hDPQjRezVDpvvocctMeN1m6ZobK6Di+WCJPY08DjT1zX19kEk8K19ErqFt1i7q90iZ2W2SSiGiuSx2PF8pArwDphXGSSok8DT0NFC51W/udBXW7WAa61fFY3aLf2csy0OuVGUgvHX8XHo+vWz0Xcpuh3Exb4wPJ+5i592bGDjZQaXK0n0po/uvvATD5nnuZ6YwoDKe0PzcCZ87j9+9i8EgnPgc9T0/CY8/gGhuZedMdTOzO0TyY0Hp0EH/+IlFvNwPv2AlA/3eH8cdPEfV0U3zNLi7elQcPe/7wKD5Jl82wUlFrG2d//jWM316m+USeXQ9NkXvhFdK9Ozj2y00A7P9LKDz6Aq6jnYkjO7lwJIfzsP+/HAPvmbrvRkZvylEpQMfJlLb//igAAz97P6VeaBqA/scniE+cpXxoD6++uYm0AXY8Uqbhq9+/Zoahz3+RqW89xg2Nt3Jg9qZL2R/xDzLF+Hr+5Ufdqlt1u4HdPuIfXK8+56jXTe4VoPyJL3LuzGPs4gA3utsB/c5eSxa61fFY3a6Req3D8XguQzI+fin7Wnut50JusnbbvMzjLbXbiWvtyHt/21L3O+eOkqaH04kJ4pkUrnKCTpeCm56hMj5OPN1XXUUvt20FXLFEMjGBa266VjySsXHw/poZrkeUQDwxQzI0TNzTBVwlh4dkaLiaoZTgkuVrjxJPPDVb3W9xO84vv9+lMkSNDQAkvrLcl624V1C36lbdZq1b9WqnV4Aornabkiz3per2Kqx2q+Px2m2FbtWrnV43Sj0Xcqdrt7uXeXzu/lNr+i6FRqJDh5na1kDasMxrvhvM3XUY5/26Zpht84zd3klz3xEme/Ow/P+R3jBLZYh7OgEo+anlvmx9egV1u4HUrbpdQMfjq7DaK0ChUOuWZd+qpG6vwmq3Oh6v3ZbvVr1umM3MUM+F3NO12yPLPD53/w/X8k3SfMTU3lbSnKNh3OMST+NIefF2OUi6W8mVd1HpbK6+p3W5fTY40p52coDvXPwWZT9bJj8+S9NAdbzFvS3guWaGa0oSmi+mlE/nicow3euYaW8kzTsKp6tv4M2PT+KTZP7blB3EN+6vvnTcmSPNX+VbNDhmtrXSOLuf6d4m/MLzml4jQ9pwA6PAeGVouW+xLr2CugXUrbqtfouMdKte2dReAVrjXgAmGFnu26jbhTLQrY7H6hb9zl6WgV6vzLCe6rmQexgYAw465+7y3j+14PEP1W7/bi3fJJqYpvnL88/geuUQ47InmoVyc8Tw7e1weztQeyl5FlySXnq1NyqnxLMw0xYxc3cX0FW9f7a2QZrivSe9eBE3NEzPY8v/tK+myLRYpOMvH6cjXv5Tl75cIU0Tos4OorInLlXvP/Wh+SfDiWcgKvsr/u2JS45yK5y/txHurW7vEoiT6nNfSYbUJ5wnz7SfYIJR2lznwk3WpVdQt+pW3WatW/VavX+zegVIZmfIkWeaKSa8ul2JLHSr47G6Rb+zl2Sh1yszrCfn/Tq9KXU139y5TwO/BXwXeJf31deRnXO/AXwG+Kb3/q1r2P/RFtoP3+fetR5xZYVe8j/iZZ6ngx6O8CZil5v7MOcA1dPqrqlXULf1om7DtbDbx/gGAFOMfxQdjzNtqW6nGH8W+GPUbWbpeByuje5WvdpR6/XZ5T7PeC31Pmvlp4F3APcDLzrnvk31uhj3AheBf1nHbLJK+znEMBcYY4iH+Spdvpfp6tlyt6FeM03dhmthtwkVfPXvrZ9B3WbaUt0C+1G3mabjcbjUrazUwnd4birvfQl4G/ApqteT+wDVhdzngCPe+xP1SyerFbuYe3gL+zlETMwFzs5dI2MU9Zpp6jZcC7utLuRS0PE485bqFsijbjNNx+NwqVtZqXq/Iof3fhr4eO0/CUTsYg5yGwepvlJce+n4rPf+TJ2jyRqp23Bd2e3cdeQm/dhH6hxL1sHCbqcYf8F7r24zTsfjcKlbWYm6viJnRhTj8g24fPXaHS7fQG7/XqLC0pd9j5qbcbnc5W337Vl6W+eIWlouf11LC3FfH3Fvj80MIbIwVwsZQmRhrhYyhMbCTC1kCJGFuVrIECILc7WQITQWZmohg2F1f0XOgrivB9pacJUEPzyK6+1m6lAfzcVpKJXmb9vTDf09RONT+OI0rqONydu30zI5NX9b54iam+GmvcRnBiBJYXsvSVuBqFiGwSFzGUJkYa4WMoTIwlwtZAiNhZlayBAiC3O1kCFEFuZqIUNoLMzUQgbLtJADxt68n9EbYxpHPE3DOyn2Rez8yqskw6OLtr3447eQNkBU7sVH1dOP9jwzQbKg9Ki1FX/zHl55dwcN453kJz0ugc5jk6Q/et5khhBZmKuFDCGyMFcLGUJjYaYWMoTIwlwtZAiRhblayBAaCzO1kMEyvbUS6Hh6kMKwZ/Zd49zway8w9roZXv6ZXUR7dy3atv/BU5S6HWPvLOJ/YoiJ905y7FcKxH1987ZLJyeJXj5Hx4mUwj8bYOdHTlD6F6Oc+bE2ottvNZkhRBbmaiFDiCzM1UKG0FiYqYUMIbIwVwsZQmRhrhYyhMbCTC1ksEyvyAG+qYGJvfCxw1+jmDbywOuO8/lvvw83Nb1o28rZc3S9pcD7dz1D3iWcmO7jy4/fSToysmCnHnI5zj/g+ejex8i7hAtd7fzZM2+Dk6+YzBAiC3O1kCFEFuZqIUNoLMzUQoYQWZirhQwhsjBXCxlCY2GmFjJYpoUcML27FYBPPPRB9vw9vPrhMo39Dt/StGhbd9dhBobzfO6Rd9I04Jne7nAHSkQd7SRDw5e3yzdAdwdRzwy//6fvp2nAM/jGMoXE4fbshOdeNJchRBbmaiFDiCzM1UKG0FiYqYUMIbIwVwsZQmRhrhYyhMbCTC1ksEwLOaDp1AQ70zbi2ZTcN55kZ/w64tIsjI4v2jYem6Lvb7bTcWyUaHCMZHsXo7e24ksz87bzSYIbGaf7a730fn8QLo7QMrCPqDKLG58ymSFEFuZqIUOILMzVQobQWJiphQwhsjBXCxlCZGGuFjKExsJMLWSwzHnv651hwzjnjrbQfvg+9656R9nyatc/edZ7f9t67E/d2qFuw3TFdeTceuxPvdqh39lwqdtwrWe36tWOtfaqk52IiIiIiIhkjBZyIiIiIiIiGaPPyFH70ONdt3Dm7W0Ud6a0norY/WcvkgwOVs9ss0DytiOcu6/A9PaEwoWYfX/0EsnAhcU7jmJy2/p4/jf34SNP99MR/Y8Okxw9ZjJDiCzM1UKGEFmYq4UMobEwUwsZQmRhrhYyhMjCXC1kCI2FmVrIYJlekQOSN9zG6Xe30fbWAT7+7i/i3zTKwE/eSG7XzkXb5vbewPGfi7jlPS9yx50vEx0Z4/mP7SdqaZm/YRST27ubZz+xh86Dw7zt9Udp/elzvPK+HnLbt5nMECILc7WQIUQW5mohQ2gszNRChhBZmKuFDCGyMFcLGUJjYaYWMlimhRwwvr9AqT/h/Jlufu/Y25kcaGX0sCftblu07cA7d5MbzPP06d0cu9BPaboBHLhd28FdPidA1NJMZVsHABOTTXzv7F5OnewjKcD4/ftMZgiRhblayBAiC3O1kCE0FmZqIUOILMzVQoYQWZirhQyhsTBTCxks01srgXIzuIqj+Xie8clO2s5ETNxSxufjRdtO7oH24zA13cRMV4JLHY0jEWlbAVwEPgHA5XKkjTENF2PK5QIVD+0nY7yDye0xzQYzhMjCXC1kCJGFuVrIEBoLM7WQIUQW5mohQ4gszNVChtBYmKmFDJZpIQfEM5CfdBSGPPiIxhHPVDHGVVIWvvvWpY7CcEKaj3G++kPUOAKki/frKp7CsAMXEc06mi6mlJsdfonXQS1kCJGFuVrIECILc7WQITQWZmohQ4gszNVChhBZmKuFDKGxMFMLGSzLWNyNkS96fAyz7Y7dn3mM8QOQm3K42cribSeg1BXRfqpC+wkPKeQnPK6czN8wSYhmKuTHqz9m275fxiWQ5h35Ja41aCFDiCzM1UKGEFmYq4UMobEwUwsZQmRhrhYyhMjCXC1kCI2FmVrIYJkuCC6bQhcpDZe6DZMuCB4u/c6GS92GSxcED5MuCC4iIiIiIrLFaCEnIiIiIiKSMVrIAbn9e8kd2DfvPnf3bcTt7Yu2jW6/lait7dJpTF1jI/HNB4k7O+Z/fS5H3NNNfPPBeffldmwnvnG/yQwhsjBXCxlCZGGuFjKExsJMLWQIkYW5WsgQIgtztZAhNBZmaiGDZTprJVC8pZ/Z9piOyMHoOHR3cv7ednaMdsH4+Lxth4900Z2LyI1N4XMxaWcLE7ubaUtTGBu/dJV519gI23oZP9RFWyFPNDGNjyNKe7qpNMcUXjppLkOILMzVQoYQWZirhQyhsTBTCxlCZGGuFjKEyMJcLWQIjYWZWshgmRZyQLEvx9iNjlLXdgrD/RT7Yyb2eba1NC3admqnA99BmutgtsNRaYb8JLQeb2TeNSryOZL2AhN7YoYPd1MY9OQnodwC8SwUDGYIkYW5WsgQIgtztZAhNBZmaiFDiCzM1UKGEFmYq4UMobEwUwsZLNNbK4HuZ8bofi6luMPx7//jHwGw8+EEd3F40bZ7/voCOBh95zTx24eY7fTkJz2cfBXSy6c3TSenyJ26QK7oKfUl7P6Zk4zeCm1nEvq/8arJDCGyMFcLGUJkYa4WMoTGwkwtZAiRhblayBAiC3O1kCE0FmZqIYNlekUOSJ96lo4XmikMH2b2Z2N2/u1pKq+eI0mTRdsmx16i89hLjN14HyO7c/Q9C12ff5R0wWUcfKVC5dx5ev/oIuVfv5dzB9rZ+a0yDV97nMVXvrCRIUQW5mohQ4gszNVChtBYmKmFDCGyMFcLGUJkYa4WMoTGwkwtZLBM15ED0jfexehNTTgP3U+Pc/H17eSmofcbp6mcmb8y9/ffydBrmmkaTMlNp5S6YmY6Inb81YskFy9e/t75BuIbdvLqP99Jy/mUxuEyEzc0kJ/2dDw7SvrD581l2Ej1uraNhblayLCR1G2Y3dbrOnIWZmohw0bS76y6XSl1G2a36jWcXvWKHJB/8Sx9A624JCU5fYZtxX2QJKTDI4u2zb14lm0jnbjRCXy5TEtLM76liXTBBy59pUw6cJGd/9iIG5vET07SdKKr+tjImMkMIbIwVwsZQmRhrhYyhMbCTC1kCJGFuVrIECILc7WQITQWZmohg2V6RU42Rb3+SigbT92GqV6vyMnG0+9suNRtuOrxipxsvLX2qpOdiIiIiIiIZIzeWjknioka8hDH+EoFPzOzom1JEtJS6eq7bmkBwM+W8ZXypetYmMwQIgtztZAhRBbmaiFDaCzM1EKGEFmYq4UMIbIwVwsZQmNhphYyGKWFHIBzxLccYODNvUztgraXofcvfkg6NbX05nfeyvn7Oyhu9zRddGz/wyeW/aGKmps5+Zt34B30PZXS8eR5KidP2cwQIgtztZAhRBbmaiFDaCzM1EKGEFmYq4UMIbIwVwsZQmNhphYyGKbPyAGTP3UvAz85w6/e+RD/8/ztjJSaGP1hLzf+6SDJcy/O2zZ9y91s+z9PUkpynJnoxDlPaTbPjv9lmOTCxXlXjXeHDjLxH0vsbK1+cLKU5Hnukf0c/Itx/A+Omsuwker1vn0Lc7WQYSOp2zC7rddn5CzM1EKGjaTfWXW7Uuo2zG7Vazi96jNyQOdjZ2l7uJlvDN7KbBpTyFXY+9US/sz5RdvmnnyJx755iDMTndzWfZ5CrkLbn7STDg3PeznWz87iXn4V/8d93Nx6gZbcLEdf2UH3UXDHTprMECILc7WQIUQW5mohQ2gszNRChhBZmKuFDCGyMFcLGUJjYaYWMlimt1YCfmyctlcrHH1yH9u+B+femnLowgjp7OyibdOJCVpedUyN9PNwSz8+59l7oYivLLiEoPek0yWaz8/y/z18P82nYwoRNA2VSYtFkxlCZGGuFjKEyMJcLWQIjYWZWsgQIgtztZAhRBbmaiFDaCzM1EIGy7SQA+jvBQ99j0PbX36fUtfrmd3eRsP5ZpIF76vN7dhOrujpfbpEbmKG6Z0tTO5pouPJwvwPVEYxUVsro3sa2fu3FZqOX2D0tdvAQdzbQzI4ZC9DiCzM1UKGEFmYq4UMobEwUwsZQmRhrhYyhMjCXC1kCI2FmVrIYJjeWgmU+9sA6H58EHzKtu+OMrWjAdfSvGjbyt5+CiMpDWeGSZ96lpanX2VqW4RrbZm3nYtjXHsbxW0RDQ8+QfLSSVrOlHAJ+O19JjOEyMJcLWQIkYW5WsgQGgsztZAhRBbmaiFDiCzM1UKG0FiYqYUMlulkJ7IpdJHScKnbMOmC4OHS72y41G24dEHwMOlkJyIiIiIiIluMFnIiIiIiIiIZo5Od1OR2bKd4x26K2/K0npkl/+1n8OXFZ8QByN2wm6k7djDdk6NxLKHpbx5bfsfOMfqzbwAHnc9PEh9/lWRo2GyGEFmYq4UMIbIwVwsZQmNhphYyhMjCXC1kCJGFuVrIEBoLM7WQwSot5ABe/xpOv7mN4l3TpJMRE6820tl/hK5vvkzl3PzrVMS33cJLH+6msq9EOuloPpUjv+d+dn7+RyTj45e2c7kc8Y7tvPJTe2h+xwWGnuljfH8bHS/dTM8j56mceNlehhBZmKuFDCGyMFcLGUJjYaYWMoTIwlwtZAiRhblayBAaCzO1kMEwvbUSGLy7la53nuO3X/tl9h64QPlQkXM/lpBs71m07ehrunjve7/Pvz3yILv2DTK9M2HnB1/GdXeCu3xOANfQQHlPL2/+8BP89s1/T7JjhubXDnLhXk/xpl6TGUJkYa4WMoTIwlwtZAiNhZlayBAiC3O1kCFEFuZqIUNoLMzUQgbL9IocUCk4ZpOYb47eQiFXpql5hompPM57Fp7Ts9zsODvdQeodjbkKDduKnBruYm9+ev6GzpE2RPQ1TPBnA/fT1j5NJYlxiSNpWrx+tpAhRBbmaiFDiCzM1UKG0FiYqYUMIbIwVwsZQmRhrhYyhMbCTC1ksGzdLj/gnHsIeMtVNnmv9/6rS3zdLwC/AhwGZoFHgU9777+7DplWdHrV6I5bmbi5g9mWiOaLFU590HPo3x4nGRlZcvuXP30fXc95Zjoixm9KufHfPLrkdrnt23jut/dx6HfOc/Z9u4jKnp5nirhHnjaZYSmP+4cYZXDZx+/ijfS67YvuP+tf5gzHmWIcR4THk1A56b0/sKJvfA3qVt1amKuFDEtZj24TEmJyJFQe0PHYRq+wft0Ck8C71a2NbnU8VrcLbWS36nV9jsfrweLlB/4H8Pkl/nt14YbOud8F/gS4Hfg68BjwTuBbzrkPbEC2ZRX7Iobu8kSzKb3bxzn/M7eSu2H3ktvO7igzdlPEbAfgYOBf30+8rX/ey7ZzfOR55YO7yE96xg/CuQdacHcv3ZWFDMvpZxc72LvovwJNi7Y95p/iWR5nknG62UYH3SRUAPZvdq9gY64WMixH3apbWNxtTDzXrY7HxnqFtXcLtKJuzXWr47G6BVvdWpiphQxWbcQrcvu99y+vYPt3AP8ADAH3ee9frN1/H/AQUKzta3QNmVb2F4dCAdfRjmsqkA6N4Hb0w9gE6fDokmfFye3fC+UKeA/5HJQrVM4NQJos2HFMbs8uqCT46enqleVny6Rj46TForkMS5n7S9IDvJcm13LN7Yf8AD/g2+Rp4HW8jWbXBsB3/FcoUfTAGGvsFdTt9WZYirpVt3OW6vYR/yAJFUoUZ9Hx2ESvsH7dTjF+EtiFujXRrY7H6nbOZnSrXq8vw0Za6yty9fyM3G/Ubj89t4gD8N4/4pz7A+BfA78IfGajg6SlEszMzAWAycnL/3sJlZdPL75zqW3ThMqpV8BF1R+g4ZFlt7WQYT2cplrlfg5dOvgAxNUftRGgm03qFWzM1UKG9aBut2y3Oh5ntFdYvltgGnWb2W51PFa36Hd20zJYVpdP9DnnmoC31/75hSU2mbvv/ZuTiGpxc+Vd+b+vtu2V/11t27m/Aqx0v/XMsAaJTxjhAlB9C8ES5s79unm9go25WsiwBup2S3er43EGewV1azrDGuh4rG7R7+zmZzBqI16R+0XnXA+QAi8AX/LeL1we3wI0Ahe992eW2MeTtds7NiDfsly+gbi3m8r5gWuWGbW14eIIX5qp/rXgats2N1dfEh6fXPYChpYyLOUsJyn7WcDRTCv97KLgmudtU2SClJQ8jYseq5k7bdCm9go25mohw1LU7TLbqts5Oh4b6xXU7ZLbBtCtjsfLbKtu59SlWwsztZDBoo1YyH1swb9/xzn3Ke/9p664b0/tdqlFHN77KefcKNDlnGvz3k9sQM5LXC6Ha2zE7ejnlZ/Ywe7PzuCnp0lnZhb/sEQxUUOe2dfdTLktpuXUJNGLp0inppbYsSNqbSW5/QAT+5roeuIi6akz+HJl0Xt1LWS4mpM8P+/fL/JD9vtDHHCHL91Xovqe4qU+uFvjgU3rFWzM1UKGq1G3C3esbq+k47G9XkHdzt9xON3qeLxwx+p2gU3t1sJMLWSwbD0Xct8C/ivwXeAccAPwIaoLu08658a9979X27a1dnu1TxNOAZ1AG3DVH1Tn3NFlHjq4kuAjH34dI4cgzcN//eAf8L81/Ctmuj03fX6E9Efzf/Fm3nOE0++L6No7wshIK7mzHfTftY2OXyxROXvu0g9VVCjgb7+R9D+N8uo/ttD2xgsc/0ALuafvYdc3i7iHnzKXYSld9LGL/XTQQyNNlChygTOc5HlO8Cw5n2ePuwlg7oxKRNUzoi1nxb2CulW3y7MwVwsZllLPbtXrxvUK6jbUbnU8Vreg39ks9WrFun1Gznv/ce/9n3vvT3jvp733L3jv/wMwd5rUf1f7bJw5+ekUH0Ha4Pnf/+BfUdxTITcNrlxZtG3D6Cxx9wzjz/XQ9kSB3KRjupzDz5bnbee9x5UTpit58hMw/WA/ldmYpOCJJxa/zGshw1IOutvY4fbS7FqJXUyLa2O/O8Sd3AfACZ4l8Xb/cmFhrhYyLEXdqluLLMzUQoblqNswu81yr2BjrhYyLCXL3VqYqYUMlm34WSu99w865x4HXgvcS/XSArVTzrDkG4Br5s7Res2/JC13ys7aXyIOL/XYlRpHKnS82EDjBDSfm+a8b2LndybxZwcWbRtPzpA/2k3fDyvE0wljBxpo/pMu0pET81/iTRLc9CyvHO/j8JdOM3HPTuJSgY6XK/DS4jPqWMhwPXrcdtp9F+OMMMYQ3fTPnVGJlKsekFbcK6hbdbs8C3O1kOF6bEa36nXzewV1G2q3Oh6r2yXod9Zwr5tts85aOXd5gR2127kpLXk1P+dcC9WXjUc2473dM105nIe2FycYO1BgxyNF4mdfJp07xekVhu/qou/pCrmphLQhovVcQtvDJ/GV+X8ZcI2NpC0Fms5Vfyln2mJ6nivR/NTpJa9PYSHD9WqqvUN2lupfLwq1dXnp0mdxF3FsYq9gY64WMlwvdatuL+XR8TgTvYK6hTC71fFY3V4ZCf3Omu91M23WQq6rdjv3acNjwAzQ55xb6vyqR2q3P9zoYAC5qZSmoYT4/BA+gvipF0nGx5c8K04aQ+vRAfITs+SKCS0nxkgGLiy532i2QvdzCb7QQONEQsOJi9Wz7RjNcL0qVM/uM/cXpGbaiIgoM0PJL3kQmntr7ab0CjbmaiHD9VK36vYKOh5noFdQt6F2q+Oxur3CpnZrYaYWMljm/AZfM8E51wecpPpS8A1zlxtwzn0FeC/wb7z3v7vga36P6kVK/w/v/aoveLjSK9e7xkYAfLlC1JC/6qlKo0KBdLZM1JDHJ+nVT1Uaxbh87tK+r3YWHAsZrsesn+FhvkJCwht536XT5P7Af4chznMzd1768C5cunL9MNULWa6pV1C315vhegH5ZR4AACAASURBVKhbdQvVXgGmGP/P6Hi86Rmu1/V2O8X4s8DXUbebnuF66HisbuesZ7fq9foybKS54/Fyb4O9lnX5jJxz7n6gH/g77y9/YtM5tw/4c6qLuL9dcM24/5vqQu5jzrkve+9frH3NfcD/SvX0qn+8Hvmuxc9dMR5IS1cvcu4H6FrbVTdK8DMr+8GwkGGhUT/ILDP0sRPn3KX7p/0UP+IxEhJ62THvWid7uIkhznOS5+j122l2bcClMzF1sYm9go25WsiwkLq92sbqdkG3Oh7XIcNS1rNbqn/ZV7d1yLCQjsdX21jd1rNbCzO1kMGy9TrZyc3AnwDnnXNPUv0h2wvcAxSAo8AvXfkF3vuv1155+zXgKefcPwANwDupvgf4I9770XXKJ6tQZJJneZwGCrT5TvLkmabIBCOkpLTQzmHumfc1PW4bN/gbeYWXeJSv0+O3kZLOXRtFvRqhbsO1Xt2WKM79Pw451K0J69ktsB9IULd1p+NxuNStbLT1Wsh9D/h9qmelfB3VvxhMAU8BfwX8vveL3+zrvf9159xTwK9SXcDNUn2rx6e8999dp2yySh10s5sDjDHMOCNUmCUmRxud9LOb3RwkdouvdXKLu4s238krHGeIASIiYmISkpPe+y/V4anIAuo2XOvVbUoy1+2bdTy2YT27pXr26Her2/rT8Thc6lY22ros5Lz3zwG/ssqv/RzwufXIIeurxbVz66XPwl+fnW4fO9l36d+19wAvexom2VzqNlzr1e3cZ+Qm/Zj+H30j1rPbKcZPaxFng47H4VK3stE266yVIiIiIiIisk60kBMREREREckYLeREREREREQyRgs5ERERERGRjNFCTkREREREJGO0kBMREREREckYLeREREREREQyZr0uCL5luXwD8a7tAKQXh0iLRfB+zfuNmpuJ+nrAOfzoGMno2Jr3CRB3duBaWiAX44slkosX12W/IVK34VK3YVKv4VK34VK3YVKvm0MLuTVwuRzxru2ce88uAPqf6CB69gTp1NQad+zg5n0MvLaDNAc9R3vIff850lJpbfuNYiq37Wd8X4FKwdF6vkLhayP4SmVt+w2Qug2Xug2Teg2Xug2Xug2Tet08WsitQbxrBwPv2MX7f/lbAPy3r7+Jm3+/H146uab9ujjm+M908J53PE5Xvsif/9ObuGn6Rnj8R2vab27HNl74iSZe84aX2Nk0zj++fDMHfrSDyqlX1rTfEKnbcKnbMKnXcKnbcKnbMKnXzaPPyK3BzP4+hu5JLv379W84RtLduvYdxzF3vfEF2nPVvzA07Zng4j1ta95teV8/uf2TvKbjLD0Nk7xxzwlKB/shite879Co23Cp2zCp13Cp23Cp2zCp182jhVwGOLf29xQvJXLphuxXVk7dhkvdhkm9hkvdhkvdhkm9aiEnIiIiIiKSOVrIrVLU1sbUzga6dl0+W053Q5GRQ63kdu1c/X6bm6ncdxtdDUXi2l8EdnWMMbkH4p7uNWW+eHczfe2Tl/7dGFUYeH0jLrb/0vFmUrfhUrdhUq/hUrfhUrdhUq+bSwu5VYra25jcGfHGnScu3deZLzJ2M1R29ax6v665iYt3F+hruPwD9ZrOs1T2lqC7c02ZR+8os6996NK/m+IyyT0TuFg/BldSt+FSt2FSr+FSt+FSt2FSr5tLZ61crVxMmoeufJFSmgcg7xKSgidtiFe/Qo5jKk3V/zm338aoQkNjBfJrqytuqZB3KeU0JiEi9Y7O1iJE9n9QN5W6DZe6DZN6DZe6DZe6DZN63VRayK3RSLmZxy7sBeBQ9wAuceuy33OlDp4f7SdJI/Z1DK/LPr2H01NdnJjooZzEtDeW8H598oZI3YZL3YZJvYZL3YZL3YZJvW4OLeRWyZdmaD3j+erXX8uB334CgCd/9bV0jnlyoyVWfb6b2TKtr3i+99d3sOf/fY50coqTH76H9CZwU6NrytzwYhMTX91F9xNDNA2OUnzdPgZ/LKYzsX+djM2kbsOlbsOkXsOlbsOlbsOkXjeX835jTt1pgXPuaAvth+9z71r/nUcxcXsrrlCgcn4AgLi3B5KUtFjEz8ysbr/OEXe0Q76BZHAQvCfu7MAVCiSDQ2u6yny8rR9mZkinpvGVMlFzM1F7G5Vz51e9z5V6xD/IFOPPeu9vW4/9qdv51O0KqdsVe8Q/CMCkH1uXP0uq1/n0O7tC6va6qFvU7Qqo1/my3KtekVutNCEZHQMun5UnGRxafvuV8r6238sWfp/VSgYuzPt3OjVFOjW15v0GR92GS92GSb2GS92GS92GSb1uKvuf4hMREREREZF5tJATERERERHJGL218npEMS6fw8/OVk9xU48IhQLk88s+7qen1/Q+4S1L3YZL3YZJvYZL3YZL3YZJvdaNFnIr5BobKb/xds7d18j+z5+m8uo5SJNNzRD3dPPcv7+RX7jvO5euar/Q337mbfR+5SWSixc3NVuWqdtwqdswqddwqdtwqdswqdf60kJuBVxjI9GN+zj5857De09y4cw++v4RKq+c2dQcycgYh/+vCzzSdfe8+4fuaOc7n/7PAPxV59txuXhTc2WZug2Xug2Teg2Xug2Xug2Teq0/LeRWynt8KaY5N0vDRAqVCkTxpv7VIW5v5cVf2sHe158h4vJL13e1vkyjq72cnI3rF9qibsOlbsOkXsOlbsOlbsOkXutKC7kViLu7GHxtD+3bRomc58I9EU2DO8hPFUnGxzcthy9XaD0Nx1t2zvuBfLm/G254eNNyhETdhkvdhkm9hkvdhkvdhkm91t+WWMjFnR2Qb4Bodcvx8oHtDB7xvKZrmFIlT8cdQwyd7mHb0E7ii4V1Trs8V2gkLkHjYDzvB7WUL3CmMglA0ghpTydxuvR7hOtmMIYN+IypujVA3V5VZrsd3Ji3oKhXA/Q7e1XqdjF1a8AGdKteDVhjr8Ev5FwuZubIjVRaYtLcKn5QHUzujCncMMbgdAsAjbkKF/ZBPNNFYbRjfQNfRbnZUfrxMX7ppkeJFnyY8wsTtwMw2+kZuauT/NQacjlI8g4fQW7GwzqcgCj9hwaYWPt+rqRuV0HdqtsVSv+hYW07WIJ6XQX9zqrb66Bur07dXqZeV8Fgr87X6TShm8E5N04ubstv61nDPjxR5HHOU6mE9yHJpTjnaWmYodElDM804/3a31hcHhiCSjLhvW9fh4jqdpXUbbjWu9vywBAuF5NOz6zLJwvU6+rodzZc6jZc1rtVr6tjsdfQF3LngT6gDByvc5zNcLB2a/G53gAUvffb12Nnzrky1QvaP78e+zPOcq+gbtfCcrfr3auOx3ao29Wz3CvoeLwWW6bbLfY7C7a7XVOvQS/kAJxzRwG897fVO8tG03MN01Z6rrC1nu9Weq6wtZ7vVnqusHWe71Z5nnO20vPdSs8VttbzDfm5RvUOICIiIiIiItdHCzkREREREZGM0UJOREREREQkY7SQExERERERyRgt5ERERERERDIm+LNWioiIiIiIhEavyImIiIiIiGSMFnIiIiIiIiIZo4WciIiIiIhIxmghJyIiIiIikjFayImIiIiIiGSMFnIiIiIiIiIZo4WciIiIiIhIxgS5kHPONTnnPumce8E5V3LOnXXOfdY5t6ve2VbDOfeQc85f5b/3LPN1v+Cce8w5N+mcG3bOfcU5d/9m519P6vbS16lbw9TrfOo2zG5D6hXU7ZXU7aWvU7eGqVfI1TvAenPOFYBvAG8AzgF/A+wDPgL8c+fcG7z3J+qXcE3+BzC5xP2vLrzDOfe7wK8B08CDQAF4J/Au59yHvPdf2sigG0HdVqnbTNnSvYK6hTC7DbhXULfqFnWbMVu3V+99UP8BnwY88F2g9Yr7f6N2/0P1zriK5/RQLfu+FW7/jtr2g8BNV9x/HzADjACd9X5e6lbdhtqtelW3oXcbWq/qVt2q2+x1q159WAs5oAEYrZV09xKPP1177J56Z73O53W9P6hfqW3/60s89nu1xz5a7+elbtVtqN2qV3Ubcrch9qpu1a26zV636tUH9xm5B4AO4Lj3/gdLPP6F2u37Ny/S5nLONQFvr/3zC0tsktUZqFt1m7XntSIB9wrqNtRut3SvoG7J3vNaMXWbuee1IqH2Gtpn5O6s3T65zONz99+xCVk2wi8653qAFHgB+JL3/vSCbW4BGoGL3vszS+wjqzNQt+o2a88LtnavoG5D7TbkXkHdgrpVt9myZXsNbSG3p3a7VEFX3r93E7JshI8t+PfvOOc+5b3/1BX3XXUG3vsp59wo0OWca/PeT2xE0A2gbtVtFrvdyr2Cug2125B7BXUL6hbUbZZs2V5De2tla+22uMzjU7Xbtk3Isp6+BfwccBBopvpXhd8CKsAnnXO/dsW215oBZHMO6lbdZuk5qdcqdVsVWrch9grqFtQtqNssPact32toC7kgee8/7r3/c+/9Ce/9tPf+Be/9fwA+UNvk39Xe+ysZo27DpF7DpW7DpW7DpW7DpF7DW8jNXUOieZnHW2q3mXi59Fq89w8CjwOdwL21u681A8jmHNStus3Sc1rSFusV1G2o3W6ZXkHdLpDF57QsdTtPFp/TkrZSr6Et5OY+2Lh7mcfn7j+1CVk2y4u12x2126vOwDnXQvUHeyQr7/+tUbfqNpRut0qvoG5D7Xar9QrqlgX3q1t1a92W6DW0hdzTtdsjyzw+d/8PNyHLZumq3c69r/cY1Ysa9jnndi2xfVZnoG7Vbdae13K2Sq+gbkPtdqv1CuqWBfdn7Xldjbqdf3/WntdytkSvoS3kHgbGgIPOubuWePxDtdu/27xIG8c51we8qfbPJwG899PAN2r3/dQSX5bVGahbdZu157XIFusV1G2o3W6ZXkHdLpDV57UkdTtPVp/XIluq14282ng9/gM+TfXK7A8DLVfc/xu1+x+qd8brfD73U/3QZrzg/n3Ad2rP6W8WPPaO2v2DwE1X3H8fUAJGgM56Pzd1q25D7Fa9qtut0G1Ivapbdatus9eteq1lr3eADSi2ADxaK+os8BdX/PsCcKDeGa/z+fxCLfs54MvAf6v9gE7X7v8R0L/E1/1u7fEp4EvAV4Ay1VOyfqDez0vdqttQu1Wv6nYrdBtSr+pW3arb7HWrXmvPp94BNqjcJuCTwEtU3w97DvgTYHe9s63iuRwC/h/gidovWRkYBR6h+heUpqt87S9QPWvPFNW/MvxP4P56Pyd1q25D7la9qtut0m0ovapbdatus9eteq3+52pPSERERERERDIitJOdiIiIiIiIBE8LORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMkYLORERERERkYzRQk5ERERERCRjtJATERERERHJGC3kREREREREMqbuCznnXJNz7pPOuReccyXn3Fnn3Gedc7vqnU1WT72GS92GS92GS92GSb2GS93KSjjvff2+uXMF4J+ANwDngG8D+4DXAxeBN3jvT9QtoKyKeg2Xug2Xug2Xug2Teg2XupWVqvcrch+j+kP6CHCz9/6nvff3Ah8F+oDP1jOcrJp6DZe6DZe6DZe6DZN6DZe6lRWp2ytyzrkG4ALQARzx3v9gweNPA3cAr/XeP1GHiLIK6jVc6jZc6jZc6jZM6jVc6lauRz1fkXuA6g/p8YU/pDVfqN2+f/MiyTpQr+FSt+FSt+FSt2FSr+FSt7Ji9VzI3Vm7fXKZx+fuv2MTssj6Ua/hUrfhUrfhUrdhUq/hUreyYrk6fu89tdszyzw+d//e1X4D59x5oBl4ZbX7kOu2rXb7dufc0SvuvwEoAu+u/XvVvYK6rRN1G66lur0BKHrvt6PjcZap2zDpeByuDe9WvZpy5fH4utVzIddauy0u8/hU7bbtWjta8IN+pT4XxVFjR+9h7wAHeIjKEE1MA5C2N+Hj5fcdl1KYngHn8C2NpDlX3c9S2xYTmC3j4pi0kKNSqG4YJdXHl8uwYlFEpbORtOCrO0vA1f4nuepnHfNj4KZncXFEUsiTFJbZl4d4FqLxaoZK99XnkJv2uMnSNTNURsfxxRJ5GnsaaOyZ+/oik3hSuI5eQd2qW9TtlTax2yKTRERzXep4vFAGegVIL4yTVErkaehpoHCp29rvLKjbxTLQrY7H6hb9zl6WgV6vzEB66fi78Hh83eq5kNsM5WbaGh9I3sfMvTczdrCBSpOj/VRC819/D4DJ99zLTGdEYTil/bkROHMev38Xg0c68TnoeXoSHnsG19jIzJvuYGJ3jubBhNajg/jzF4l6uxl4x04A+r87jD9+iqinm+JrdnHxrjx42POHR/FJumyGlYpa2zj7869h/PYyzSfy7HpoitwLr5Du3cGxX24CYP9fQuHRF3Ad7Uwc2cmFIzmch/3/5Rh4z9R9NzJ6U45KATpOprT990cBGPjZ+yn1QtMA9D8+QXziLOVDe3j1zU2kDbDjkTINX/3+NTMMff6LTH3rMW5ovJUDszddyv6If5ApxtfzLz/qVt2q2w3s9hH/4Hr1OUe9bnKvAOVPfJFzZx5jFwe40d0O6Hf2WrLQrY7H6naN1GsdjsdzGZLx8UvZ19prPRdyk7Xb5mUeb6ndTlxrR97725a63zl3lDQ9nE5MEM+kcJUTdLoU3PQMlfFx4um+6ip6uW0r4IolkokJXHPTteKRjI2D99fMcD2iBOKJGZKhYeKeLuAqOTwkQ8PVDKUElyxfe5R44qnZ6n6L23F++f0ulSFqbAAg8ZXlvmzFvYK6VbfqNmvdqlc7vQJEcbXblGS5L1W3V2G1Wx2P124rdKte7fS6Ueq5kDtdu929zONz959a03cpNBIdOszUtgbShmVe891g7q7DOO/XNcNsm2fs9k6a+44w2ZuH5f+P9IZZKkPc0wlAyU8t92Xr0yuo2w2kbtXtAjoeX4XVXgEKhVq3LPtWJXV7FVa71fF47bZ8t+p1w2xmhnou5J6u3R5Z5vG5+3+4lm+S5iOm9raS5hwN4x6XeBpHyou3y0HS3UquvItKZ3P1Pa3L7bPBkfa0kwN85+K3KPvZMvnxWZoGquMt7m0BzzUzXFOS0HwxpXw6T1SG6V7HTHsjad5ROF19A29+fBKfJPPfpuwgvnF/9aXjzhxp/irfosExs62Vxtn9TPc24Ree1/QaGdKGGxgFxitDy32LdekV1C2gbtVt9VtkpFv1yqb2CtAa9wIwwchy30bdLpSBbnU8Vrfod/ayDPR6ZYb1VM+F3MPAGHDQOXeX9/6pBY9/qHb7d2v5JtHENM1fnn8G1yuHGJc90SyUmyOGb2+H29uB2kvJs+CS9NKrvVE5JZ6FmbaImbu7gK7q/bO1DdIU7z3pxYu4oWF6Hlv+p301RabFIh1/+Tgd8fKfuvTlCmmaEHV2EJU9cal6/6kPzT8ZTjwDUdlf8W9PXHKUW+H8vY1wb3V7l0CcVJ/7SjKkPuE8eab9BBOM0uY6F26yLr2CulW36jZr3arX6v2b1StAMjtDjjzTTDHh1e1KZKFbHY/VLfqdvSQLvV6ZYT0579fpTamr+ebOfRr4LeC7wLu8r76O7Jz7DeAzwDe9929dw/6PttB++D73rvWIKyv0kv8RL/M8HfRwhDcRu9zchzkHqJ5Wd029grqtF3UbroXdPsY3AJhi/KPoeJxpS3U7xfizwB+jbjNLx+NwbXS36tWOWq/PLvd5xmup91krPw28A7gfeNE5922q18W4F7gI/Ms6ZpNV2s8hhrnAGEM8zFfp8r1MV8+Wuw31mmnqNlwLu02o4Kt/b/0M6jbTluoW2I+6zTQdj8OlbmWlFr7Dc1N570vA24BPUb2e3AeoLuQ+Bxzx3p+oXzpZrdjF3MNb2M8hYmIucHbuGhmjqNdMU7fhWthtdSGXgo7HmbdUt0AedZtpOh6HS93KStX7FTm899PAx2v/SSBiF3OQ2zhI9ZXi2kvHZ733Z+ocTdZI3Ybrym7nriM36cc+UudYsg4WdjvF+Avee3WbcToeh0vdykrU9RU5M6IYl2/A5avX7nD5BnL79xIVlr7se9TcjMvlLm+7b8/S2zpH1NJy+etaWoj7+oh7e2xmCJGFuVrIECILc7WQITQWZmohQ4gszNVChhBZmKuFDKGxMFMLGQyr+ytyFsR9PdDWgqsk+OFRXG83U4f6aC5OQ6k0f9uebujvIRqfwhencR1tTN6+nZbJqfnbOkfU3Aw37SU+MwBJCtt7SdoKRMUyDA6ZyxAiC3O1kCFEFuZqIUNoLMzUQoYQWZirhQwhsjBXCxlCY2GmFjJYpoUcMPbm/YzeGNM44mka3kmxL2LnV14lGR5dtO3FH7+FtAGici8+qp5+tOeZCZIFpUetrfib9/DKuztoGO8kP+lxCXQemyT90fMmM4TIwlwtZAiRhblayBAaCzO1kCFEFuZqIUOILMzVQobQWJiphQyW6a2VQMfTgxSGPbPvGueGX3uBsdfN8PLP7CLau2vRtv0PnqLU7Rh7ZxH/E0NMvHeSY79SIO7rm7ddOjlJ9PI5Ok6kFP7ZADs/coLSvxjlzI+1Ed1+q8kMIbIwVwsZQmRhrhYyhMbCTC1kCJGFuVrIECILc7WQITQWZmohg2V6RQ7wTQ1M7IWPHf4axbSRB153nM9/+324qelF21bOnqPrLQXev+sZ8i7hxHQfX378TtKRkQU79ZDLcf4Bz0f3PkbeJVzoaufPnnkbnHzFZIYQWZirhQwhsjBXCxlCY2GmFjKEyMJcLWQIkYW5WsgQGgsztZDBMi3kgOndrQB84qEPsufv4dUPl2nsd/iWpkXbursOMzCc53OPvJOmAc/0doc7UCLqaCcZGr68Xb4BujuIemb4/T99P00DnsE3likkDrdnJzz3orkMIbIwVwsZQmRhrhYyhMbCTC1kCJGFuVrIECILc7WQITQWZmohg2VayAFNpybYmbYRz6bkvvEkO+PXEZdmYXR80bbx2BR9f7OdjmOjRINjJNu7GL21FV+ambedTxLcyDjdX+ul9/uDcHGEloF9RJVZ3PiUyQwhsjBXCxlCZGGuFjKExsJMLWQIkYW5WsgQIgtztZAhNBZmaiGDZc57X+8MG8Y5d7SF9sP3uXfVO8qWV7v+ybPe+9vWY3/q1g51G6YrriPn1mN/6tUO/c6GS92Gaz27Va92rLVXnexEREREREQkY7SQExERERERyRh9Ro7ahx7vuoUzb2+juDOl9VTE7j97kWRwsHpmmwWStx3h3H0FprcnFC7E7Pujl0gGLizecRST29bH87+5Dx95up+O6H90mOToMZMZQmRhrhYyhMjCXC1kCI2FmVrIECILc7WQIUQW5mohQ2gszNRCBsv0ihyQvOE2Tr+7jba3DvDxd38R/6ZRBn7yRnK7di7aNrf3Bo7/XMQt73mRO+58mejIGM9/bD9RS8v8DaOY3N7dPPuJPXQeHOZtrz9K60+f45X39ZDbvs1khhBZmKuFDCGyMFcLGUJjYaYWMoTIwlwtZAiRhblayBAaCzO1kMEyLeSA8f0FSv0J589083vH3s7kQCujhz1pd9uibQfeuZvcYJ6nT+/m2IV+StMN4MDt2g7u8jkBopZmKts6AJiYbOJ7Z/dy6mQfSQHG799nMkOILMzVQoYQWZirhQyhsTBTCxlCZGGuFjKEyMJcQyHIJwAAIABJREFULWQIjYWZWshgmd5aCZSbwVUczcfzjE920nYmYuKWMj4fL9p2cg+0H4ep6SZmuhJc6mgciUjbCuAi8AkALpcjbYxpuBhTLheoeGg/GeMdTG6PaTaYIUQW5mohQ4gszNVChtBYmKmFDCGyMFcLGUJkYa4WMoTGwkwtZLBMCzkgnoH8pKMw5MFHNI54pooxrpKy8N23LnUUhhPSfIzz1R+ixhEgXbxfV/EUhh24iGjW0XQxpdzs8Eu8DmohQ4gszNVChhBZmKuFDKGxMFMLGUJkYa4WMoTIwlwtZAiNhZlayGBZxuJujHzR42OYbXfs/sxjjB+A3JTDzVYWbzsBpa6I9lMV2k94SCE/4XHlZP6GSUI0UyE/Xv0x2/b9Mi6BNO/IL3GtQQsZQmRhrhYyhMjCXC1kCI2FmVrIECILc7WQIUQW5mohQ2gszNRCBst0QXDZFLpIabjUbZh0QfBw6Xc2XOo2XLogeJh0QXAREREREZEtRgs5ERERERGRjNFCDsjt30vuwL5597m7byNub1+0bXT7rURtbZdOY+oaG4lvPkjc2TH/63M54p5u4psPzrsvt2M78Y37TWYIkYW5WsgQIgtztZAhNBZmaiFDiCzM1UKGEFmYq4UMobEwUwsZLNNZK4HiLf3Mtv//7d1rcGRnfefx79OnW2q17tJIM5LGc7Nn7LGxPb5gM8aQDTEJUGHDUlAFVdkqUhS72SwbCLupfbGQSoGTzW6RLciLwG4uhA1JFQupGLI4xBjWEBsbYxvbeGZsz308F82MNLq3Wuo+59kX3ZJ1acmSutV6ztO/T5WqrdOPzvzP/9d9yk/3uQS0JwyMjkNXB4P3ttE32gnj44vGXruzk65kguTYFDYZEHU0M7EzQ2sUwdj4/F3mTWMjbN/G+MFOWtMpEhPT2CBBblcXhUxA+sRp52rwkQt9daEGH7nQVxdq8I0LPXWhBh+50FcXavCRC311oQbfuNBTF2pwmSZyQLYnydgNhlznDtLXesn2BkzssWxvblo2dqrfgG0nSrYz224oZCA1CS0nG1l0j4pUkrAtzcSugGs3d5EesqQmId8MwSykHazBRy701YUafORCX12owTcu9NSFGnzkQl9dqMFHLvTVhRp840JPXajBZTq0Euj6+RhdxyKyfYY/+KM/A6D/iRBz9dqysbv+/goYGH3nNME7hpntsKQmLZy+ANHrlzeNJqdInr1CMmvJ9YTs/NBpRm+C1vMhvT+44GQNPnKhry7U4CMX+upCDb5xoacu1OAjF/rqQg0+cqGvLtTgGxd66kINLtM3ckD0/FHaX82QvnYzs78e0P/tcxQuXCKMwmVjw1dO0PHKCcZuOMzIziQ9R6Hzq08RLbmNgy0UKFwaZNufXSX/yXu5tK+N/h/lafinZ1h+5ws3avCRC311oQYfudBXF2rwjQs9daEGH7nQVxdq8JELfXWhBt+40FMXanCZ7iMHRPcfYnR/E8ZC1wvjXL2njeQ0bPvBOQrnF8/M7X23M3xrhqahiOR0RK4zYKY9Qd83jhNevfr6v51qILiunwu/2k/zYETjtTwT1zWQmra0Hx0levFl52rYTFt1bxsX+upCDZtJ2fqZ7VbdR86FnrpQw2bSe1bZrpWy9TNb5epPrvpGDkgdv0jP5RZMGBGeO8/27B4IQ6JrI8vGJo9fZPtIB2Z0ApvP09ycwTY3ES054dIW8kSXr9L//UbM2CR2cpKmU53F50bGnKzBRy701YUafORCX12owTcu9NSFGnzkQl9dqMFHLvTVhRp840JPXajBZfpGTmpiqz4llM2nbP20Vd/IyebTe9ZfytZfW/GNnGy+SnPVxU5ERERERERiRodWzkkEJBpSEATYQgE7M7OmsYQhUS63+qqbmwGws3lsIT9/Hwsna/CRC311oQYfudBXF2rwjQs9daEGH7nQVxdq8JELfXWhBt+40FMXanCUJnIAxhDcuI/Lb9/G1AC0noFtX3+RaGqq/PDbb2LwvnayOyxNVw07/uezK76oEpkMp//zbVgDPc9HtD83SOH0WTdr8JELfXWhBh+50FcXavCNCz11oQYfudBXF2rwkQt9daEG37jQUxdqcJjOkQMmP3gvl//VDB+//TH+cfBNjOSaGH1xGzf87yHCY8cXjY1+4Q62/9fT5MIk5yc6MMaSm03R92+uEV65uuiu8ebg9Uz8UY7+luKJk7kwxbEn93L918exPzviXA2baauO23ehry7UsJmUrZ/ZbtU5ci701IUaNpPes8p2rZStn9kqV39y1TlyQMfTF2l9IsMPhm5iNgpIJwvs/m4Oe35w2djkcyd4+ocHOT/RwS1dg6STBVq/0kY0fG3R17F2dhZz5gL2L3o40HKF5uQsR17ro+sImFdOO1mDj1zoqws1+MiFvrpQg29c6KkLNfjIhb66UIOPXOirCzX4xoWeulCDy3RoJWDHxmm9UODIc3vY/hO49C8iDl4ZIZqdXTY2mpig+YJhaqSXJ5p7sUnL7itZbGHJLQStJZrOkRmc5W+fuI/MuYB0ApqG80TZrJM1+MiFvrpQg49c6KsLNfjGhZ66UIOPXOirCzX4yIW+ulCDb1zoqQs1uEwTOYDebWCh5xlo/T8/Jdd5D7M7WmkYzBAuOa422beDZNay7YUcyYkZpvubmdzVRPtz6cUnVCYCEq0tjO5qZPe3CzSdvMLo3dvBQLCtm3Bo2L0afORCX12owUcu9NWFGnzjQk9dqMFHLvTVhRp85EJfXajBNy701IUaHKZDK4F8bysAXc8MgY3Y/uNRpvoaMM2ZZWMLu3tJj0Q0nL9G9PxRml+4wNT2BKaledE4EwSYtlay2xM0PPIs4YnTNJ/PYUKwO3qcrMFHLvTVhRp85EJfXajBNy701IUafORCX12owUcu9NWFGnzjQk9dqMFlutiJ1IRuUuovZesn3RDcX3rP+kvZ+ks3BPeTLnYiIiIiIiJSZzSRExERERERiRld7KQk2beD7G07yW5P0XJ+ltQ//xybX35FHIDkdTuZuq2P6e4kjWMhTd96euUVG8Por78FDHS8PElw8gLh8DVna/CRC311oQYfudBXF2rwjQs9daEGH7nQVxdq8JELfXWhBt+40FMXanCVJnIA99zKube3kj00TTSZYOJCIx29d9L5wzMULi2+T0Vwy42c+HAXhT05oklD5myS1K776P/qS4Tj4/PjTDJJ0LeD1z64i8wDVxj+eQ/je1tpP3GA7icHKZw6414NPnKhry7U4CMX+upCDb5xoacu1OAjF/rqQg0+cqGvLtTgGxd66kINDtOhlcDQHS10vvMSn7n7O+zed4X8wSyXfikk3NG9bOzorZ28+90/5XfvfISBPUNM94f0v/8MpqsDzOvXBDANDeR3bePtH36Wzxz4v4R9M2TuHuLKvZbs/m1O1uAjF/rqQg0+cqGvLtTgGxd66kINPnKhry7U4CMX+upCDb5xoacu1OAyfSMHFNKG2TDgh6M3kk7macrMMDGVwljL0mt65jOGi9PtRNbQmCzQsD3L2Wud7E5NLx5oDFFDgp6GCf768n20tk1TCANMaAibls+fXajBRy701YUafORCX12owTcu9NSFGnzkQl9dqMFHLvTVhRp840JPXajBZVW7/YAx5jHgF1YZ8m5r7XfL/N1HgN8CbgZmgaeAB621P65CTWu6vGritpuYONDObHOCzNUCZ99vOfi7JwlHRsqOP/PgYTqPWWbaE4zvj7jhd54qOy65YzvHPrOHg58f5OJ7BkjkLd0/z2KefMHJGsp5xj7GKEMrPn+I+9lmdixbftGe4TwnmWIcQwKLJaRw2lq7b03/8BtQtsrWhb66UEM51cg2JCQgSUjhrdofu5ErVC9bYBL4FWXrRrbaHyvbpTYzW+Vanf1xNbh4+4G/A75a5ufC0oHGmC8AXwHeBDwKPA28E/iRMeZ9m1DbirI9CYYPWRKzEdt2jDP4oZtIXrez7NjZvjxj+xPMtgMGLv/2fQTbexd9bTvHJiyvvX+A1KRl/Hq49NZmzB3ls3KhhpX0MkAfu5f9pGlaNvYV+zxHeYZJxuliO+10EVIA2FvrXMGNvrpQw0qUrbKF5dkGBHPZan/sWK5QebZAC8rWuWy1P1a24Fa2LvTUhRpctRnfyO211p5Zw/gHgO8Bw8Bha+3x0vLDwGNAtrSu0QpqWtsnDuk0pr0N05QmGh7B9PXC2ATRtdGyV8VJ7t0N+QJYC6kk5AsULl2GKFyy4oDkrgEohNjp6eKd5WfzRGPjRNmsczWUM/dJ0lt5N02m+Q3HD9vL/Ix/JkUDb+YXyZhWAB63D5Mja4ExKswVlO16ayhH2SrbOeWyfdI+QkiBHNlZtD92IleoXrZTjJ8GBlC2TmSr/bGynVOLbJXr+mrYTJV+I7eV58h9qvT44NwkDsBa+6Qx5svAbwMfBf54swuJcjmYmZkrACYnX//vMgpnzi1fWG5sFFI4+xqYRPEFdG1kxbEu1FAN5yhGuZeD8zsfgKD4UhsBuqhRruBGX12ooRqUbd1mq/1xTHOFlbMFplG2sc1W+2Nli96zNavBZVtyRp8xpgl4R+nXb5YZMrfsvbWpiGJwc+Et/O/Vxi78WW3s3KcAa13vVtZQgdCGjHAFKB5CUMbctV9rlyu40VcXaqiAsq3rbLU/jmGuoGydrqEC2h8rW/SerX0NjtqMb+Q+aozpBiLgVeAha+3S6fGNQCNw1Vp7vsw6nis93rYJ9a3IpBoItnVRGLz8hmEmWlsxQQKbmyl+WrDa2Eym+JXw+OSKNzB0qYZyLnKavJ0FDBla6GWAtMksGpNlgoiIFI3LniuZu2xQTXMFN/rqQg3lKNsVxirbOdofO5YrKNuyYz3IVvvjFcYq2zlbkq0LPXWhBhdtxkTu00t+/7wx5nPW2s8tWLar9FhuEoe1dsoYMwp0GmNarbUTm1DnPJNMYhobMX29vPZrfez8yxns9DTRzMzyF0siINGQYvbNB8i3BjSfnSRx/CzR1FSZFRsSLS2Eb9rHxJ4mOp+9SnT2PDZfWHasrgs1rOY0Ly/6/TgvstceZJ+5eX5ZjuIxxeVO3C2xQM1yBTf66kINq1G2S1esbBfS/ti9XEHZLl6xP9lqf7x0xcp2iZpm60JPXajBZdWcyP0I+HPgx8Al4DrgAxQndp81xoxba79YGttSelztbMIpoANoBVZ9oRpjjqzw1PVrKXzkw29m5CBEKfjz93+Zf9/wm8x0WfZ/dYTopcVvvJl33cm59yTo3D3CyEgLyYvt9B7aTvtHcxQuXpp/USXSaeybbiD6b6Nc+H4zrfdf4eT7mkm+cBcDP8xinnjeuRrK6aSHAfbSTjeNNJEjyxXOc5qXOcVRkjbFLrMfYO6KSiSKV0RbyZpzBWWrbFfmQl9dqKGcrcxWuW5erqBsfc1W+2NlC3rPxilXV1TtHDlr7e9Za79mrT1lrZ221r5qrf1DYO4yqb9fOjfOOanpCJuAqMHyH778m2R3FUhOg8kXlo1tGJ0l6Jph/Fg3rc+mSU4apvNJ7Gx+0ThrLSYfMl1IkZqA6Ud6KcwGhGlLMLH8a14XaijnenMLfWY3GdNCYAKaTSt7zUFu5zAApzhKaN395MKFvrpQQznKVtm6yIWeulDDSpStn9nGOVdwo68u1FBOnLN1oacu1OCyTb9qpbX2EWPMM8DdwL0Uby1QuuQMZQ8ALpm7RusbfpK00iU7S59E3FzuuYUaRwq0H2+gcQIyl6YZtE30Pz6JvXh52dhgcobUkS56XiwQTIeM7Wsg85VOopFTi7/iDUPM9Cyvnezh5ofOMXFXP0EuTfuZApxYfkUdF2pYj26zgzbbyTgjjDFMF71zV1QiYtUd0ppzBWWrbFfmQl9dqGE9apGtcq19rqBsfc1W+2NlW4besw7nWmu1umrl3O0F+kqPc10qezc/Y0wzxa+NR2pxbPdMZxJjofX4BGP70vQ9mSU4eoZo7hKnC1w71EnPCwWSUyFRQ4KWSyGtT5zGFhZ/MmAaG4ma0zRdKr4pZ1oDuo/lyDx/ruz9KVyoYb2aSkfIzlL89CJdmpfn5s/FXcZQw1zBjb66UMN6KVtlO1+P9sexyBWULfiZrfbHynZhSeg963yutVSriVxn6XHubMNXgBmgxxhT7vqqd5YeX9zswgCSUxFNwyHB4DA2AcHzxwnHx8teFScKoOXIZVITsySzIc2nxggvXym73sRsga5jITbdQONESMOpq8Wr7Thaw3oVKF7dZ+4TpAytJEiQZ4acLbsTmju0tia5ght9daGG9VK2ynYB7Y9jkCsoW1+z1f5Y2S5Q02xd6KkLNbjM2E2+Z4Ixpgc4TfGr4OvmbjdgjHkYeDfwO9baLyz5my9SvEnpf7LWbviGh2u9c71pbATA5gskGlKrXqo0kU4TzeZJNKSwYbT6pUoTASaVnF/3alfBcaGG9Zi1MzzBw4SE3M975i+T+zP7OMMMcoDb50/ehfk711+jeCPLinIFZbveGtZD2SpbKOYKMMX4n6D9cc1rWK/1ZjvF+FHgUZRtzWtYD+2Ple2camarXNdXw2aa2x+vdBjsG6nKOXLGmPuAXuAfrH39jE1jzB7gaxQncd9ecs+4/0FxIvdpY8x3rLXHS39zGPi3FC+v+hfVqO+N2Lk7xgNRbvUg515AbzSuOCjEzqztheFCDUuN2iFmmaGHfowx88un7RQv8TQhIdvoW3Svk13sZ5hBTnOMbXYHGdMKzF+JqZMa5gpu9NWFGpZStqsNVrZLstX+eAtqKKea2VL8ZF/ZbkENS2l/vNpgZbuV2brQUxdqcFm1LnZyAPgKMGiMeY7ii2w3cBeQBo4AH1v4B9baR0vfvH0CeN4Y8z2gAXgnxWOAf8NaO1ql+mQDskxylGdoIE2r7SBFimmyTDBCREQzbdzMXYv+ptts5zp7A69xgqd4lG67nYho7t4oytURytZf1co2R3bufxySKFsnVDNbYC8Qomy3nPbH/lK2stmqNZH7CfAlilelfDPFTwymgOeBbwBfsnb5wb7W2k8aY54HPk5xAjdL8VCPz1lrf1yl2mSD2uliJ/sY4xrjjFBgloAkrXTQy052cj2BWX6vkxvNIVptB69xkmEukyBBQEBIeNpa+9AWbIosoWz9Va1sI8K5bN+u/bEbqpktxatH/4qy3XraH/tL2cpmq8pEzlp7DPitDf7tXwF/VY06pLqaTRs3zZ8Lvz79Zg/97Jn/vXQM8IqXYZLaUrb+qla2c+fITdox/Y++I6qZ7RTj5zSJc4P2x/5StrLZanXVShEREREREakSTeRERERERERiRhM5ERERERGRmNFETkREREREJGY0kRMREREREYkZTeRERERERERiRhM5ERERERGRmKnWDcHrlkk1EAzsACC6OkyUzYK1Fa83kcmQ6OkGY7CjY4SjYxWvEyDoaMc0N0MywGZzhFevVmW9PlK2/lK2flKu/lK2/lK2flKutaGJXAVMMkkwsINL7xoAoPfZdhJHTxFNTVW4YgMH9nD57naiJHQf6Sb502NEuVxl600EFG7Zy/ieNIW0oWWwQPqfRrCFQmXr9ZCy9Zey9ZNy9Zey9Zey9ZNyrR1N5CoQDPRx+YEB3vvvfgTA3zz6Ng58qRdOnK5ovSYIOPmhdt71wDN0prJ87f+9jf3TN8AzL1W03mTfdl79tSZufcsJ+pvG+f6ZA+x7qY/C2dcqWq+PlK2/lK2flKu/lK2/lK2flGvt6By5Cszs7WH4rnD+93ve8gphV0vlKw4CDt3/Km3J4icMTbsmuHpXa8Wrze/pJbl3klvbL9LdMMn9u06Ru74XEkHF6/aNsvWXsvWTcvWXsvWXsvWTcq0dTeRiwJjKjykuJ2GiTVmvrJ2y9Zey9ZNy9Zey9Zey9ZNy1UROREREREQkdjSR26BEaytT/Q10Drx+tZyuhiwjB1tIDvRvfL2ZDIXDt9DZkCUofSIw0D7G5C4IursqqvnqHRl62ibnf29MFLh8TyMmcP+r41pStv5Stn5Srv5Stv5Stn5SrrWlidwGJdpamexPcH//qfllHaksYwegMNC94fWaTBNX70jT0/D6C+rWjosUduegq6Oimkdvy7OnbXj+96YgT3jXBCbQy2AhZesvZesn5eovZesvZesn5VpbumrlRiUDohR0prLkohQAKRMSpi1RQ7DxGXIQUGgq/ufcehsTBRoaC5CqLK6guUDKROSjgJAEkTV0tGQh4f4LtaaUrb+UrZ+Uq7+Urb+UrZ+Ua01pIlehkXyGp6/sBuBg12VMaKqy3ku5dl4e7SWMEuxpv1aVdVoL56Y6OTXRTT4MaGvMYW116vWRsvWXsvWTcvWXsvWXsvWTcq0NTeQ2yOZmaDlv+e6jd7PvM88C8NzH76ZjzJIczbHh693M5ml5zfKTv7+NXf/rGNHkFKc/fBfRfjBToxXV3HC8iYnvDtD17DBNQ6Nk37yHoV8K6Ajdv09GLSlbfylbPylXfylbfylbPynX2jLWbs6lO11gjDnSTNvNh80vV3/liYCgrQWTTlMYvAxAsK0bwogom8XOzGxsvcYQtLdBqoFwaAisJehox6TThEPDFd1lPtjeCzMzRFPT2EKeRCZDoq2VwqXBDa9zrZ60jzDF+FFr7S3VWJ+yXUzZrpGyXbMn7SMATNqxqnwsqVwX03t2jZTtuihblO0aKNfF4pyrvpHbqCgkHB0DXr8qTzg0vPL4tbK2tN7XLf13Niq8fGXR79HUFNHUVMXr9Y6y9Zey9ZNy9Zey9Zey9ZNyrSn3z+ITERERERGRRTSRExERERERiRkdWhkziXQaUqkVn7fT0xUdJyxbR9n6S9n6Sbn6S9n6S9n6qV5z1UQuRoLuLo79wQ185PDj83e1X+rbf/yLbHv4BOHVqzWuTiqhbP2lbP2kXP2lbP2lbP1Uz7lqIhcj4cgYN//3KzzZecei5cO3tfH4g38CwDc63oFJBltRnlRA2fpL2fpJufpL2fpL2fqpnnPVRC5GgrYWjn+sj933nCfB67eNONRyhkZT+jo5HvcvlCWUrb+UrZ+Uq7+Urb+UrZ/qOVdN5GLE5gu0nIOTzf2LXpBnervguie2rjCpmLL1l7L1k3L1l7L1l7L1Uz3nWhcTuaCjHVINkIj3dNykGwly0DgULHqh5lJpzhcmAQgbIeruIIjKHyO8ZYYC2IRzTJWtA5TtqmKb7dDmHIKiXB2g9+yqlO1yytYBm5CtcnVAhbl6P5EzyYCZO2+g0BwQJTfwQjVgTfHRhFUvb13yGUPuX47xsf1PkVhyMuc3J94EwGyHZeRQB6mp9o3/QwbClMEmIDljWfAt9YZF32uAicrXs5Cy3QBlW3NxzTb6XkNlKyhDuW6A3rM1p2wXU7YbEINslesGOJirsbYKVTjKGDNOMmhNbe+uYB2WRMJijKVQ8O8kyXKMsTQ3zNBoQq7NZLC28k9q8peHoRBOWGvbqlCist0gZeuvamebvzyMSQZE0zNV+ahWuW6M3rP+Urb+cj1b5boxLubq+0RuEOgB8sDJLS6nFq4vPbq4rdcBWWvtjmqszBiTp3hD+5ersT7HuZwrKNtKuJxttXPV/tgdynbjXM4VtD+uRN1kW2fvWXA724py9XoiB2CMOQJgrb1lq2vZbNpWP9XTtkJ9bW89bSvU1/bW07ZC/WxvvWznnHra3nraVqiv7fV5WxNbXYCIiIiIiIisjyZyIiIiIiIiMaOJnIiIiIiISMxoIiciIiIiIhIzmsiJiIiIiIjEjPdXrRQREREREfGNvpETERERERGJGU3kREREREREYkYTORERERERkZjRRE5ERERERCRmNJETERERERGJGU3kREREREREYkYTORERERERkZjxciJnjGkyxnzWGPOqMSZnjLlojPlLY8zAVte2EcaYx4wxdpWfd63wdx8xxjxtjJk0xlwzxjxsjLmv1vVXk7Kd/ztl6zDlupiy9TNbn3IFZbuQsp3/O2XrMOUKya0uoNqMMWngB8BbgEvAt4A9wG8Av2qMeYu19tTWVViRvwMmyyy/sHSBMeYLwCeAaeARIA28E/hlY8wHrLUPbWahm0HZFinbWKnrXEHZgp/ZepwrKFtli7KNmfrN1Vrr1Q/wIGCBHwMtC5Z/qrT8sa2ucQPb9Fip9j1rHP9AafwQsH/B8sPADDACdGz1dilbZetrtspV2fqerW+5Kltlq2zjl61ytX5N5IAGYLQU0h1lnn+h9NxdW13rOrdrvS/Uh0vjP1nmuS+WnvuPW71dylbZ+pqtclW2PmfrY67KVtkq2/hlq1ytd+fIvRVoB05aa39W5vlvlh7fW7uSassY0wS8o/TrN8sMiWsPlK2yjdt2rYnHuYKy9TXbus4VlC3x2641U7ax26418TVX386Ru730+NwKz88tv60GtWyGjxpjuoEIeBV4yFp7bsmYG4FG4Kq19nyZdcS1B8pW2cZtu6C+cwVl62u2PucKyhaUrbKNl7rN1beJ3K7SY7mAFi7fXYNaNsOnl/z+eWPM56y1n1uwbNUeWGunjDGjQKcxptVaO7EZhW4CZats45htPecKytbXbH3OFZQtKFtQtnFSt7n6dmhlS+kxu8LzU6XH1hrUUk0/Av41cD2Qofipwn8BCsBnjTGfWDD2jXoA8eyDslW2cdom5VqkbIt8y9bHXEHZgrIFZRunbar7XH2byHnJWvt71tqvWWtPWWunrbWvWmv/EHhfacjvl479lZhRtn5Srv5Stv5Stv5Stn5Srv5N5ObuIZFZ4fnm0mMsvi59I9baR4BngA7g3tLiN+oBxLMPylbZxmmbyqqzXEHZ+ppt3eQKynaJOG7TipTtInHcprLqKVffJnJzJzbuXOH5ueVna1BLrRwvPfaVHlftgTGmmeILeyQux/+WKFtl60u29ZIrKFtfs623XEHZsmS5slW2rquLXH179wzCAAACYklEQVSbyL1Qerxzhefnlr9Yg1pqpbP0OHdc7ysUb2rYY4wZKDM+rj1Qtso2btu1knrJFZStr9nWW66gbFmyPG7btRplu3h53LZrJXWRq28TuSeAMeB6Y8yhMs9/oPT4D7UrafMYY3qAt5V+fQ7AWjsN/KC07INl/iyuPVC2yjZu27VMneUKytbXbOsmV1C2S8R1u8pStovEdbuWqatcN/Nu41vxAzxI8c7sTwDNC5Z/qrT8sa2ucZ3bcx/FkzaDJcv3AI+XtulbS557oLR8CNi/YPlhIAeMAB1bvW3KVtn6mK1yVbb1kK1PuSpbZats45etci3VvtUFbEKwaeCpUlAXga8v+P0KsG+ra1zn9nykVPsl4DvA35ReoNOl5S8BvWX+7gul56eAh4CHgTzFS7K+b6u3S9kqW1+zVa7Kth6y9SlXZatslW38slWupe3Z6gI2Kdwm4LPACYrHw14CvgLs3OraNrAtB4E/BZ4tvcnywCjwJMVPUJpW+duPULxqzxTFTxn+Ebhvq7dJ2Spbn7NVrsq2XrL1JVdlq2yVbfyyVa7FH1PaIBEREREREYkJ3y52IiIiIiIi4j1N5ERERERERGJGEzkREREREZGY0UROREREREQkZjSRExERERERiRlN5ERERERERGJGEzkREREREZGY0UROREREREQkZjSRExERERERiRlN5ERERERERGJGEzkREREREZGY0UROREREREQkZjSRExERERERiRlN5ERERERERGJGEzkREREREZGY0UROREREREQkZjSRExERERERiRlN5ERERERERGLm/wMGfTmaH5TtzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1200x600 with 14 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLOJWZ3ZM9hb"
      },
      "source": [
        "# PPO用ニューラルネットのモデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-EyRai1iARP"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self,nframes=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # 4x84x84 → 32x20x20 \n",
        "        self.conv1 = nn.Conv2d(in_channels=nframes, out_channels=64, kernel_size=8, stride=4)\n",
        "        # 32x20x20 →64x9x9\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2)\n",
        "        # 64x9x9 → 64x7x7 \n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        # 64x7x7 → FL \n",
        "        FL = 256\n",
        "        self.lin = nn.Linear(in_features=7 * 7 * 64, out_features=FL)\n",
        "        # FL → 4 actions 0-1 （行動決定）\n",
        "        self.pi_logits = nn.Linear(in_features=FL, out_features=4)\n",
        "        # 行動価値\n",
        "        self.value = nn.Linear(in_features=FL, out_features=1)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor):\n",
        "        h = F.relu(self.conv1(obs))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = h.reshape((-1, 7 * 7 * 64))\n",
        "\n",
        "        h = F.relu(self.lin(h))\n",
        "\n",
        "        pi = Categorical(logits=self.pi_logits(h))\n",
        "        value = self.value(h).reshape(-1)\n",
        "\n",
        "        return pi, value"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9F7bqjidwCf"
      },
      "source": [
        "# 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "tGVSB2NriARV",
        "scrolled": true,
        "outputId": "97f8f8f0-5065-4e5c-c95e-757282301cbf"
      },
      "source": [
        "model = Model(16)\n",
        "model.to(device)\n",
        "game = Game(0,16)\n",
        "obs = game.reset()\n",
        "a=0\n",
        "for i in range(200):\n",
        "  obs,r,_,_ = game.step(a)\n",
        "  pi,v = model.forward(torch.tensor(obs,dtype=torch.float32,device=device)/255)\n",
        "for i in range(10):\n",
        "  obs,r,_,_ = game.step(a)\n",
        "  pi,v = model.forward(torch.tensor(obs,dtype=torch.float32,device=device)/255)\n",
        "  a0 = pi.sample() # 方策関数によりアクションを決定\n",
        "  a = a0[0] # アクション番号の数値化\n",
        "  print(a)\n",
        "\n",
        "display(obs.shape) # 画面データのシェイプを表示\n",
        "display(a0)\n",
        "display(a) # 選ばれたアクション番号を表示\n",
        "print(\"初期は確率がほぼ等確率になっていることを確認\")\n",
        "for i in range(4):\n",
        "    print(i,pow(np.e,(pi.log_prob(torch.tensor(i,device=device))))) # \n",
        "display(v.detach()) # 状態価値を表示\n",
        "display(model) # モデルを表示"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(2, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(2, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1, 16, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([0], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor(0, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "初期は確率がほぼ等確率になっていることを確認\n",
            "0 tensor([0.2404], device='cuda:0', grad_fn=<PowBackward1>)\n",
            "1 tensor([0.2563], device='cuda:0', grad_fn=<PowBackward1>)\n",
            "2 tensor([0.2437], device='cuda:0', grad_fn=<PowBackward1>)\n",
            "3 tensor([0.2597], device='cuda:0', grad_fn=<PowBackward1>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([-0.0388], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(16, 64, kernel_size=(8, 8), stride=(4, 4))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (lin): Linear(in_features=3136, out_features=256, bias=True)\n",
              "  (pi_logits): Linear(in_features=256, out_features=4, bias=True)\n",
              "  (value): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvKriYliARb"
      },
      "source": [
        "# Multiprocessing Playloop\n",
        "# 学習のメインプログラム\n",
        "### 並列ゲームプレイヤのクラス定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghC4pGrBiARh"
      },
      "source": [
        "def playloop(agent: multiprocessing.connection.Connection,seed:int,k=8,skip=1,noop_max=30, mode = 0):\n",
        "\n",
        "    # create game\n",
        "    game = Game(seed=seed, k=k,skip=skip,noop_max=noop_max, mode = mode)\n",
        "    # AI player \n",
        "    while True:\n",
        "        cmd, action = agent.recv()\n",
        "        if cmd == \"step\":\n",
        "            agent.send(game.step(action))\n",
        "        elif cmd == \"reset\":\n",
        "            agent.send(game.reset())\n",
        "        elif cmd == \"close\":\n",
        "            agent.close()\n",
        "            break\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "class CoPlayer:\n",
        "    def __init__(self, seed, k=8,skip=1,noop_max=30,mode = 0):\n",
        "        self.child, parent = multiprocessing.Pipe()\n",
        "        self.process = multiprocessing.Process(target=playloop, args=(parent, seed, k,skip,noop_max,mode))\n",
        "        self.process.start()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQr3RqvxEoHA"
      },
      "source": [
        "### パイプ動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv7YYQpo6HGy",
        "outputId": "38863708-0daa-458d-e078-5814de48aef8"
      },
      "source": [
        "cop2 = CoPlayer(0,8)\n",
        "cop2.child.send((\"reset\",None))\n",
        "a = cop2.child.recv()\n",
        "cop2.child.send((\"step\",1))\n",
        "a2,b,c,d = cop2.child.recv()\n",
        "cop2.child.send((\"close\",None))\n",
        "a.shape,a2.shape,b,c,d"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 8, 84, 84), (1, 8, 84, 84), 0.0, False, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLo5NlOfLFDJ"
      },
      "source": [
        "### ログフォルダの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSlfu2Xn7b9"
      },
      "source": [
        "import os\n",
        "SAVEFOLDER = '/content/drive/MyDrive/M/ppo2'\n",
        "os.makedirs(SAVEFOLDER,exist_ok=True)\n",
        "modelPath = SAVEFOLDER+\"/model\"  # モデルの重みファイル名  (拡張子　.pt　が自動的に補われる）"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PrMOErZeo8U"
      },
      "source": [
        "#### ハイパーパラメータの（一部）\r\n",
        "ハイパーパラメータのうち、ネットワークに関するものは上に、一部は Main のパラメータに、一部は関数定義に埋め込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4FcgTbTkBBd"
      },
      "source": [
        "NCYCLES = 2000 # 学習サイクル数　（データ収集→学習　が1サイクル）\n",
        "\n",
        "END_GREEDY_Progress = 0.0 # 0.8  付加的な擾乱期間　開始から全体の 0.8\n",
        "GreedyEPS_START = 0.0 # 0.3 擾乱期間開始時の付加的擾乱\n",
        "GreedyEPS_END = 0.0 # 0.1 擾乱期間終了後の付加的擾乱\n",
        "\n",
        "END_LOSTLIFE_Penalty_Progress = 1.0 # 1.0  初期の仮ペナルティ適用期間　開始から終了までの期間に対する割合\n",
        "\n",
        "# Hyper Parameters\n",
        "GAMMA = 0.99 # 0.93\n",
        "LAMDA = 0.95 # 0.906\n",
        "EPOCHS =  4 # サンプル１セットを何度学習プロセスに通すか\n",
        "NPLAYERS = 8 # 並列実行する数game\n",
        "NBATCHES = 256 # １度に処理するデータ数\n",
        "NDIVIDE = 4 # バッチの分割数\n",
        "SEEDZero = random.randint(1,10000)\n",
        "LearningRate = 0.001 # 0.0015\n",
        "CLIPRANGE = 0.2 # ## Run it \n",
        "NFRAMES = 6\n",
        "W_VFLOSS = 0.6 # loss におけるvfloss の重み\n",
        "W_BONUS = 0.015 # loss における entropy bonus の重み　0.01"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrWOt3NiARi"
      },
      "source": [
        "class Main:\n",
        "    # mode 0 ：ライフが失われたらリセット、 mode 1：ライフが残っている場合は、画面を継続\n",
        "    def __init__(self,seed=SEEDZero,k=NFRAMES,skip=1,deadloss=38,noop_max=16,resume=False,ncycles=NCYCLES,mode = 0, lr=LearningRate,cr = CLIPRANGE, gamma=GAMMA,lamda=LAMDA,eb = W_BONUS):\n",
        "\n",
        "        self.lr = lr\n",
        "        self.cr = cr\n",
        "        self.gamma = gamma\n",
        "        self.lamda = lamda\n",
        "        self.eb = eb\n",
        "        self.k = k\n",
        "        self.ncycles = ncycles\n",
        "\n",
        "        self.lifes = 0 # 失った機体数 lost lifes\n",
        "        self.cycles = 0 # バッチ回数\n",
        "        self.deadloss = deadloss\n",
        "        self.mode = mode\n",
        "\n",
        "        self.progress = 0\n",
        "        \n",
        "        # 1サイクルに必要なサンプル数\n",
        "        self.batch_size = NPLAYERS * NBATCHES\n",
        "        # ミニバッチのサイズ\n",
        "        self.mini_batch_size = self.batch_size // NDIVIDE\n",
        "\n",
        "        # 初期化  \n",
        "        # CoPlayerの生成\n",
        "        self.coplayers = [CoPlayer(seed + i,k,skip,noop_max,mode) for i in range(NPLAYERS)]\n",
        "\n",
        "        # 観測情報の初期化　この部分を float や tensor にすると k が４に制限されてしまうので int で\n",
        "        self.obs = np.zeros((NPLAYERS, k, 84, 84), dtype=np.uint8)\n",
        "        for player in self.coplayers:\n",
        "            player.child.send((\"reset\", None))\n",
        "        for i, player in enumerate(self.coplayers):\n",
        "            self.obs[i] = player.child.recv()\n",
        "\n",
        "        # model for sampling\n",
        "        self.model = model = Model(k).to(device)\n",
        "        if resume: # 学習済み重みがある場合\n",
        "          shutil.copy( modelPath+'.pt', modelPath+'.bak.pt')\n",
        "          if torch.cuda.is_available():\n",
        "            self.model.load_state_dict(torch.load(modelPath+'.pt'))\n",
        "          else: #  gpu ありを前提としているが、cpu で続きを計算したい場合\n",
        "            self.model.load_state_dict(torch.load(modelPath+'.pt', map_location=torch.device('cpu')))\n",
        "\n",
        "        # optimizer\n",
        "        # lr = LearningRate\n",
        "        optimizers = {}\n",
        "        # optimizers['SGD'] = optim.SGD(model.parameters(), lr)\n",
        "        # optimizers['Adagrad'] = optim.Adagrad(model.parameters(), lr)\n",
        "        # optimizers['RMSprop'] = optim.RMSprop(model.parameters(), lr)\n",
        "        # optimizers['Adadelta'] = optim.Adadelta(model.parameters(), lr)\n",
        "        # optimizers['Adam'] = optim.Adam(model.parameters(), lr)\n",
        "        optimizers['AdamW'] = optim.AdamW(model.parameters(), lr)\n",
        "        self.optimizer = optimizers['AdamW']\n",
        "\n",
        "    @staticmethod\n",
        "    def _toTT(obs: np.ndarray) -> torch.Tensor:\n",
        "        return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize(adv: torch.Tensor):\n",
        "        return (adv - adv.mean()) / (adv.std() + 1e-8)\n",
        "\n",
        "    def sample(self) -> (Dict[str, torch.Tensor], List):\n",
        "        # 学習データの記憶域確保\n",
        "        rewards = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        actions = np.zeros((NPLAYERS, NBATCHES), dtype=np.int32)\n",
        "        done = np.zeros((NPLAYERS, NBATCHES), dtype=np.bool)\n",
        "        obs = np.zeros((NPLAYERS, NBATCHES, self.k, 84, 84), dtype=np.float32)\n",
        "        log_pis = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        values = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        \n",
        "        # 画像データの初期化\n",
        "        for t in progress_bar(range(NBATCHES), parent=self.mpbar):\n",
        "            with torch.no_grad(): # 傾きを固定して実行\n",
        "                obs[:, t] = self.obs\n",
        "                pi, v = self.model(self._toTT(self.obs))\n",
        "                values[:, t] = v.cpu().numpy()\n",
        "                a0 = pi.sample()\n",
        "                \n",
        "                # epsiron greedy action selection\n",
        "                if self.progress >= END_GREEDY_Progress:\n",
        "                    g_eps = GreedyEPS_END\n",
        "                else:\n",
        "                    g_eps = GreedyEPS_START + self.progress * (END_GREEDY_Progress- GreedyEPS_START)/END_GREEDY_Progress\n",
        "                for i in range(NPLAYERS):\n",
        "                    if torch.rand(1) <= g_eps: \n",
        "                        a0[i] = torch.randint(0,4,(1,))\n",
        "                a =a0.cpu().numpy()\n",
        "                actions[:, t] = a\n",
        "                log_pis[:, t] = pi.log_prob(a0).cpu().numpy()\n",
        "                \n",
        "            for w, player in enumerate(self.coplayers):\n",
        "                player.child.send((\"step\", actions[w, t]))\n",
        " \n",
        "            for w, player in enumerate(self.coplayers):\n",
        "                self.obs[w], rewards[w, t], done[w, t], info  =  player.child.recv()\n",
        "\n",
        "                if info : # info \n",
        "                    if self.progress >= END_LOSTLIFE_Penalty_Progress:\n",
        "                       dlrate = 0\n",
        "                    else:\n",
        "                       dlrate = 1 - self.progress/END_LOSTLIFE_Penalty_Progress \n",
        "                    rewards[w, t] -=  dlrate * self.deadloss\n",
        "                    self.lifes += 1\n",
        "                    wandb.log({'reward':info['reward'],'lengt':info['length']})\n",
        "                    wandb.log({'lifes':self.lifes,'cycles':self.cycles})\n",
        "             \n",
        "        # calculate advantages\n",
        "        advantages = self._calc_advantages(done, rewards, values)\n",
        "        samples = {\n",
        "            'obs': obs,\n",
        "            'actions': actions,\n",
        "            'values': values,\n",
        "            'log_pis': log_pis,\n",
        "            'advantages': advantages\n",
        "        }\n",
        "\n",
        "        samples_flat = {}\n",
        "        for k, v in samples.items():\n",
        "            v = v.reshape(v.shape[0] * v.shape[1], *v.shape[2:])\n",
        "            if k == 'obs':\n",
        "                samples_flat[k] = self._toTT(v)\n",
        "            else:\n",
        "                samples_flat[k] = torch.tensor(v, device=device)\n",
        "        return samples_flat, rewards[rewards>0].mean()\n",
        "\n",
        "    def _calc_advantages(self, done: np.ndarray, rewards: np.ndarray, values: torch.Tensor) -> np.ndarray:\n",
        "        advantages = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        last_advantage = 0\n",
        "        _, last_value = self.model(self._toTT(self.obs))\n",
        "        last_value = last_value.cpu().data.numpy()\n",
        "\n",
        "        for t in reversed(range(NBATCHES)):\n",
        "            mask = 1 - done[:, t]\n",
        "            last_value = last_value * mask\n",
        "            last_advantage = last_advantage * mask\n",
        "            #delta = rewards[:, t] + GAMMA * last_value - values[:, t]\n",
        "            #last_advantage = delta + GAMMA * LAMDA * last_advantage\n",
        "            delta = rewards[:, t] + self.gamma * last_value - values[:, t]\n",
        "            last_advantage = delta + self.gamma * self.lamda * last_advantage\n",
        "            advantages[:, t] = last_advantage\n",
        "            last_value = values[:, t]\n",
        "\n",
        "        return advantages\n",
        "    \n",
        "    # 1サイクルの学習\n",
        "    def train(self, samples: Dict[str, torch.Tensor], learning_rate: float, clip_range: float):\n",
        "\n",
        "        for _ in range(EPOCHS):\n",
        "            # 並べ替え用の数列\n",
        "            indexes = torch.randperm(self.batch_size)\n",
        "\n",
        "            # ミニバッチ単位で処理\n",
        "            for start in range(0, self.batch_size, self.mini_batch_size):\n",
        "                # get mini batch\n",
        "                end = start + self.mini_batch_size\n",
        "                mini_batch_indexes = indexes[start: end]\n",
        "                mini_batch = {}\n",
        "                for k, v in samples.items():\n",
        "                    mini_batch[k] = v[mini_batch_indexes]\n",
        "\n",
        "                # train\n",
        "                loss = self._calc_loss(clip_range=clip_range,\n",
        "                                       samples=mini_batch)\n",
        "\n",
        "                # compute gradients\n",
        "                for pg in self.optimizer.param_groups:\n",
        "                    pg['lr'] = learning_rate\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n",
        "                self.optimizer.step()\n",
        "\n",
        "    def _calc_loss(self, samples: Dict[str, torch.Tensor], clip_range: float) -> torch.Tensor:\n",
        "        sampled_return = samples['values'] + samples['advantages']\n",
        "        sampled_normalized_advantage = self._normalize(samples['advantages'])\n",
        "        pi, value = self.model(samples['obs'])\n",
        "\n",
        "        # #### Policy\n",
        "        log_pi = pi.log_prob(samples['actions'])\n",
        "\n",
        "        ratio = torch.exp(log_pi - samples['log_pis'])\n",
        "\n",
        "        clipped_ratio = ratio.clamp(min=1.0 - clip_range,\n",
        "                                    max=1.0 + clip_range)\n",
        "        policy_reward = torch.min(ratio * sampled_normalized_advantage,\n",
        "                                  clipped_ratio * sampled_normalized_advantage)\n",
        "        policy_reward = policy_reward.mean()\n",
        "\n",
        "        # #### Entropy Bonus\n",
        "        entropy_bonus = pi.entropy()\n",
        "        entropy_bonus = entropy_bonus.mean()\n",
        "\n",
        "        # #### Value\n",
        "        clipped_value = samples['values'] + (value - samples['values']).clamp(min=-clip_range,\n",
        "                                                                              max=clip_range)\n",
        "        vf_loss = torch.max((value - sampled_return) ** 2, (clipped_value - sampled_return) ** 2)\n",
        "        vf_loss = 0.5 * vf_loss.mean()\n",
        "        loss = -(policy_reward - W_VFLOSS* vf_loss + self.eb * entropy_bonus)\n",
        "\n",
        "        # for monitoring\n",
        "        approx_kl_divergence = .5 * ((samples['log_pis'] - log_pi) ** 2).mean()\n",
        "        clip_fraction = (abs((ratio - 1.0)) > clip_range).to(torch.float).mean()\n",
        "        \n",
        "        wandb.log({'policy_reward': policy_reward,\n",
        "                     'vf_loss': vf_loss,\n",
        "                     'entropy_bonus': entropy_bonus,\n",
        "                     'kl_div': approx_kl_divergence,\n",
        "                     'clip_fraction': clip_fraction})        \n",
        "        return loss\n",
        "\n",
        "    def run_training_loop(self):\n",
        "\n",
        "        ### Run training loop\n",
        "        self.mpbar = master_bar(range(self.ncycles))\n",
        "        for cycle in self.mpbar:\n",
        "            self.cycles = cycle \n",
        "            self.progress = progress = cycle / self.ncycles\n",
        "\n",
        "            # decreasing `learning_rate` and `clip_range` \n",
        "            #learning_rate = LearningRate * (1 - progress)\n",
        "            learning_rate = self.lr * (1 - 0.3*progress)\n",
        "            clip_range = self.cr * (1 - 0.2*progress)\n",
        "            samples,mrewards = self.sample()\n",
        "            # train the model\n",
        "            self.train(samples, learning_rate, clip_range)\n",
        "\n",
        "            # write summary info to the writer, and log to the screen\n",
        "            if (cycle + 1) % 10 == 0:\n",
        "                #torch.save(self.model.state_dict(),modelPath+'.pt' )SAVEFOLDER+\"/model\"\n",
        "                torch.save(self.model.state_dict(),SAVEFOLDER+\"/model\"+'.pt' )\n",
        "            if (cycle + 1) % 250 == 0:\n",
        "                torch.save(self.model.state_dict(),SAVEFOLDER+\"/model\"+'{}'.format(cycle+1)+'.pt')\n",
        "        torch.save(self.model.state_dict(),modelPath+'.pt')\n",
        "        return mrewards\n",
        "\n",
        "    def destroy(self):\n",
        "\n",
        "        for player in self.coplayers:\n",
        "            player.child.send((\"close\", None))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywW3eB4vLOa0"
      },
      "source": [
        "## W and B\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "JmoHAp4qiAQ3",
        "scrolled": true,
        "outputId": "e9c59ca8-50e1-477b-a2a1-513595dd616b"
      },
      "source": [
        "# Inside my model training code \n",
        "!export WANDB_NOTEBOOK_NAME=\"PPO.ipynb\"\n",
        "import wandb\n",
        "PROJECTNAME='PPOPPPS'\n",
        "wandb.init(project=PROJECTNAME)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">crisp-glitter-37</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/aquapathos/PPOPPPS\" target=\"_blank\">https://wandb.ai/aquapathos/PPOPPPS</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/aquapathos/PPOPPPS/runs/134tp2d1\" target=\"_blank\">https://wandb.ai/aquapathos/PPOPPPS/runs/134tp2d1</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210104_123910-134tp2d1</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f16dcb28278>"
            ],
            "text/html": [
              "<h1>Run(134tp2d1)</h1><p></p><iframe src=\"https://wandb.ai/aquapathos/PPOPPPS/runs/134tp2d1\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_-yArl4PRu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "559f9b3e-8a39-406f-df9a-39a5a0d35097"
      },
      "source": [
        "# 学習１ターン目  mode 0, dedloss ありで\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\n",
        "print(LearningRate,CLIPRANGE)\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=3,deadloss=50,noop_max=16,resume=False,ncycles=NCYCLES,mode=0)\n",
        "m.run_training_loop()\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='723' class='' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      36.15% [723/2000 41:15<1:12:53]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='73' class='' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      28.52% [73/256 00:00<00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ5bnYIF7Y63"
      },
      "source": [
        "# 学習2ターン目  mode 3, dedloss ありで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "print(LearningRate,CLIPRANGE)\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=3,deadloss=50,noop_max=16,resume=True,ncycles=NCYCLES,mode=3,lr=LearningRate,cr=CLIPRANGE)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aoJrrKsppIq"
      },
      "source": [
        "# 学習3ターン目  mode 3, dedloss なしで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "LearningRate *= 0.7\r\n",
        "CLIPRANGE *= 0.8\r\n",
        "print(LearningRate,CLIPRANGE)\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=3,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=3,lr=LearningRate,cr=CLIPRANGE)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv2x8qlWsPLb"
      },
      "source": [
        "# 学習4ターン目  mode 3, dedloss なしで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "LearningRate *= 0.7\r\n",
        "CLIPRANGE *= 0.8\r\n",
        "print(LearningRate,CLIPRANGE)\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=3,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=3,lr=LearningRate,cr=CLIPRANGE)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtsOWy83j5W"
      },
      "source": [
        "![rewards](https://user-images.githubusercontent.com/5820803/103320826-404a2a80-4a7a-11eb-9bb6-9dd04cef52d0.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Upl2kkiARk"
      },
      "source": [
        "# torch.save(model.state_dict(),'ppomodel')\n",
        "# model.load_state_dict(torch.load('ppomodel'))\n",
        "# torch.save(model.state_dict(),'ppomodel{}'.format(100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwx6KcNdA12"
      },
      "source": [
        "# [Optuna](https://optuna.org/)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPP6e08dOYI"
      },
      "source": [
        "!pip install optuna > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNoP7bO0dANJ"
      },
      "source": [
        "import optuna\r\n",
        "\r\n",
        "def objective(trial):\r\n",
        "    # Categorical parameter\r\n",
        "    # optimizer = trial.suggest_categorical('k', [2,4,6,8,10,14,16])\r\n",
        "\r\n",
        "    # Int parameter\r\n",
        "    # num_layers = trial.suggest_int('deladloss', 1, 51)\r\n",
        "\r\n",
        "    # Loguniform parameter\r\n",
        "    # gamma = trial.suggest_loguniform('gamma', 0.90, 0.97)\r\n",
        "    eb = trial.suggest_loguniform('eb',0.006,0.1)\r\n",
        "\r\n",
        "    m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=False,lr=0.0015,eb=eb)\r\n",
        "    mrewards = m.run_training_loop()\r\n",
        "    m.destroy()\r\n",
        "\r\n",
        "    return -mrewards\r\n",
        "\r\n",
        "study = optuna.create_study()\r\n",
        "study.optimize(objective, n_trials=10)\r\n",
        "study.best_params  # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFxQSkkh9nlQ"
      },
      "source": [
        "# Demoモード\r\n",
        "\r\n",
        "Colab では表示できません"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50QeBOYDgwWj"
      },
      "source": [
        "random.seed(datetime.now())\r\n",
        "DEFAULTSEED = random.randint(1, 10000)\r\n",
        "import time\r\n",
        "\r\n",
        "model = Model(NFRAMES).to(device)\r\n",
        "# model.load_state_dict(torch.load(SAVEFOLDER+\"/model\" ))\r\n",
        "model.load_state_dict(torch.load(SAVEFOLDER+\"/model.pt\", map_location=torch.device('cpu')))\r\n",
        "game = Game(seed=DEFAULTSEED, k=NFRAMES,skip=2,noop_max=0,demo=True)\r\n",
        "\r\n",
        "def _toTT(obs: np.ndarray) -> torch.Tensor:\r\n",
        "    return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0    \r\n",
        "\r\n",
        "for i in range(4):\r\n",
        "    print(i,end='')\r\n",
        "    observation = game.reset() \r\n",
        "    r = 0\r\n",
        "    lives = 3\r\n",
        "    img = game.render(mode='rgb_array') \r\n",
        "    cv2.imshow(\"Space Invader\",cv2.resize(img[:,:,::-1],(320,420)))\r\n",
        "    if i==0 :\r\n",
        "        cv2.waitKey(0)\r\n",
        "    while True:\r\n",
        "        #time.sleep(0.02)\r\n",
        "        # game.render()\r\n",
        "        img = game.render(mode='rgb_array')     \r\n",
        "        cv2.imshow(\"Space Invader\",cv2.resize(img[:,:,::-1],(320,420)))\r\n",
        "        cv2.waitKey(1)\r\n",
        "        time.sleep(0.01)\r\n",
        "        pi, v = model(_toTT(observation))\r\n",
        "        action = pi.sample().cpu().numpy()[0] # 方策関数によりアクションを決定\r\n",
        "        observation, reward, done, info = game.step(action) \r\n",
        "        r += reward\r\n",
        "        if done:\r\n",
        "          print(r,info)\r\n",
        "          break;\r\n",
        "cv2.waitKey(1)\r\n",
        "cv2.destroyAllWindows()\r\n",
        "game.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTHbhmTRz9IK"
      },
      "source": [
        "game.close()\r\n",
        "cv2.waitKey(1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}