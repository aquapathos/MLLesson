{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9a73619f2144e8f9ef80d826997969d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de44bb7c449d4e3eac396e0eac3fab1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bac53e5f38494602886ce90b71703e15",
              "IPY_MODEL_7e3cdb922bd348248698c475599b28ab"
            ]
          }
        },
        "de44bb7c449d4e3eac396e0eac3fab1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bac53e5f38494602886ce90b71703e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_eaf0ca94d4e3454e93d8f346576fd0de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_349a4d1b06fa4fbfa76f26cdf04d3380"
          }
        },
        "7e3cdb922bd348248698c475599b28ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b77deb2fd935495b9a29a1563c71bae2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d2f72c8a01b40d5b088764ce37badbe"
          }
        },
        "eaf0ca94d4e3454e93d8f346576fd0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "349a4d1b06fa4fbfa76f26cdf04d3380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b77deb2fd935495b9a29a1563c71bae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d2f72c8a01b40d5b088764ce37badbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/MLLesson/blob/master/PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CS72K-uiAQn"
      },
      "source": [
        "# AtariスペースインベーダのPPO による強化学習の実装\n",
        "\n",
        "参考\n",
        "\n",
        "- https://github.com/vpj/rl_samples\n",
        "http://blog.varunajayasiri.com/ml/ppo_pytorch.html\n",
        "\n",
        "ほぼそのままです。違いはクラウドログサービスを WandB に変更してあることと、そのままだと過学習のせいか得点が伸びずに戦略が固まってしまうようなので、εグリーディを pytorch だよりとは別に設定できるようにした点ぐらいです。\n",
        "\n",
        "#### 他に参考にしたサイト\n",
        "\n",
        "- [PythonでPPOを実装してみた](https://qiita.com/oki_uta_aiota/items/a15ba5de6ed3c1268ed3#%E5%85%A8%E4%BD%93%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S2e1GxIKGiA",
        "outputId": "d3c8e21f-32f2-4672-b001-b256bb906902"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(time.time())\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(repr(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device(type='cuda', index=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7B5y3RLEPsY",
        "outputId": "00e101d5-b127-4522-82b5-a6a1895b5e0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ndL3LBK3Vg"
      },
      "source": [
        "# 外部ライブラリの追加"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7cJQgKWihEN"
      },
      "source": [
        "!pip install pfrl > /dev/null\n",
        "!pip install wandb > /dev/null\n",
        "!pip install fastprogress > /dev/null\n",
        "#!pip install gym[atari] > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avyWPx9-iAQ-"
      },
      "source": [
        "import multiprocessing\n",
        "import multiprocessing.connection\n",
        "from typing import Dict, List\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "\n",
        "import gym\n",
        "from gym import ObservationWrapper\n",
        "from gym.spaces import Box\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.distributions import Categorical\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from pfrl.wrappers.atari_wrappers import FrameStack,NoopResetEnv,MaxAndSkipEnv\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvyoQhmZLybp"
      },
      "source": [
        "# ラッパー定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq2fQjdZiARA"
      },
      "source": [
        "class myCrop(ObservationWrapper):\n",
        "    def __init__(self, env, tmgn=0, bmgn=0,lmgn=0,rmgn=0,igcolors=[],bgcolor=[0,0,0]):\n",
        "        super(myCrop, self).__init__(env)\n",
        "        self.tmgn, self.bmgn = tmgn, bmgn\n",
        "        self.lmgn, self.rmgn = lmgn, rmgn\n",
        "        self.igcolors, self.bgcolors = igcolors, bgcolor\n",
        "        self.observation_space = Box(low=0, high=255, shape=(84,84), dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        img_mask = np.zeros(obs.shape[:2],np.uint8)\n",
        "        for color in self.igcolors:\n",
        "            bgrLower = np.array(color)    \n",
        "            bgrUpper = np.array(color)\n",
        "            tmask = cv2.inRange(obs, bgrLower, bgrUpper) \n",
        "            img_mask = cv2.bitwise_or(img_mask,tmask)\n",
        "        obs = cv2.bitwise_and(obs,obs,mask=255-img_mask) # 元画像とマスクを合成\n",
        "        RIGHT=obs.shape[1]-self.rmgn\n",
        "        BOTTOM=obs.shape[0]-self.bmgn\n",
        "        obs = obs[self.tmgn:BOTTOM,self.lmgn:RIGHT]\n",
        "        obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
        "        observation = cv2.resize(obs, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        return observation\n",
        "\n",
        "class myFrameStack(FrameStack):\n",
        "    def __init__(self, env, k=8, mode=0,demo=False):\n",
        "        super(myFrameStack, self).__init__(env, k=k, channel_order=\"chw\")\n",
        "        self.lives = 0\n",
        "        self.lsumrewards = 0\n",
        "        self.localsteps = 0\n",
        "        self.demo = demo\n",
        "        self.mode = mode\n",
        "    def reset(self):\n",
        "        ob = self.env.reset()\n",
        "        return self._reset(ob)\n",
        "    def _reset(self,ob):\n",
        "        for _ in range(self.k):\n",
        "          self.frames.append(ob)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        self.lsumrewards = 0\n",
        "        self.localsteps = 0\n",
        "        return  np.array([list(self.frames)])\n",
        "    def step(self, action):\n",
        "        self.localsteps += 1  \n",
        "        ob, reward, done1, info = self.env.step(action)\n",
        "        self.lsumrewards += reward\n",
        "        self.frames.append(ob)\n",
        "        returnobs = np.array([list(self.frames)])\n",
        "        episode_info = None\n",
        "        if self.demo:\n",
        "            return returnobs,rewad,done1,info\n",
        "        # 残機数確認\n",
        "        else: # if train mode\n",
        "            lives = self.env.unwrapped.ale.lives()\n",
        "            if done1 or lives < self.lives: # １機死んだら終了とする\n",
        "                done = True\n",
        "                episode_info = {\"reward\": self.lsumrewards, \"length\": self.localsteps}\n",
        "                if done1 or self.mode == 0: \n",
        "                  self.reset() \n",
        "                else: # mode 1 ライフが減っただけの場合はシーンは継続\n",
        "                  self._reset(ob)\n",
        "            else:\n",
        "                done = False\n",
        "            return returnobs, reward, done, episode_info\n",
        "\n",
        "def mkenv(envname,k=8,skip=2,tmgn=0,bmgn=0,lmgn=0,rmgn=0,igcolors=[],noop_max=30, mode = 0, demo=False):\n",
        "  env=gym.make(envname)\n",
        "  if noop_max > 0:\n",
        "      env = NoopResetEnv(env, noop_max=noop_max)\n",
        "  if skip > 1:\n",
        "      env = MaxAndSkipEnv(env, skip=skip)\n",
        "  env=myCrop(env, tmgn=tmgn, bmgn=bmgn, lmgn=lmgn, rmgn=rmgn, igcolors=igcolors)\n",
        "  env=myFrameStack(env,k=k,mode=mode,demo=demo)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWIH0JlWiARD"
      },
      "source": [
        "# Game Environment の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc2-DseiARG"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "random.seed(datetime.now())\n",
        "DEFAULTSEED = random.randint(1, 10000)\n",
        "def Game(seed=DEFAULTSEED,k=8,skip=2,noop_max=30, mode = 0):\n",
        "    ENV_NAME = 'SpaceInvadersNoFrameskip-v4'\n",
        "    Tmgn=20\n",
        "    Bmgn=12\n",
        "    Lmgn=8\n",
        "    Rmgn=8\n",
        "    #NOCOLOR=[[162,134,56]]  # 背景と同一視するカラー\n",
        "    NOCOLOR=[]\n",
        "\n",
        "    env = mkenv(ENV_NAME,k,skip,Tmgn,Bmgn,Lmgn,Rmgn,NOCOLOR,noop_max=noop_max, mode = mode)\n",
        "    env.seed(seed)\n",
        "    return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhWKKV7miARI"
      },
      "source": [
        "### 補足\n",
        "**k** : 過去何フレーム分の画面をデータとするか  \n",
        "**skip** : 何フレームおきにサンプリングするか  \n",
        "**Tmgn,Bmgn,Lmgn,Rmgn** カットする余白量  \n",
        "**NOCOLOR** 黒に置き換える色をRGB指定。複数指定可能  \n",
        "上の設定はインベーダ決め打ち\n",
        "\n",
        "## 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZisujiNyiARJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "outputId": "35eb3294-edd5-495f-ad7e-993c429bf4a4"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "DEFAULTSEED = random.seed(datetime.now())\n",
        "\n",
        "# 原画像が表示できるかテスト\n",
        "game = Game(DEFAULTSEED,7)\n",
        "orgimg = game.render(mode='rgb_array')\n",
        "display(Image.fromarray(orgimg))\n",
        "display(orgimg.shape)\n",
        "\n",
        "# リセット画像の確認\n",
        "plt.figure(figsize=(8,4),dpi=150)\n",
        "imgs = game.reset()\n",
        "imgs = imgs[0]\n",
        "for i,img in enumerate(imgs):\n",
        "    plt.subplot(2,8,i+1)\n",
        "    plt.imshow(img)\n",
        "# ステップ画像の確認\n",
        "for _ in range(60):\n",
        "  imgs,r,d,i= game.step(game.action_space.sample()) \n",
        "imgs = imgs[0]\n",
        "for i,img in enumerate(imgs):\n",
        "    plt.subplot(2,8,i+9)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# Check types\n",
        "display(imgs.shape,imgs[0,0,0],imgs[0,40,40],type(imgs[0,0,0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAADn0lEQVR4nO3dsa7TVhgHcF/EM3QqDJ0qVV2YeIcuFUwsPEjUscqDsMPWd2BiqZA6dejlQRiCbq3cOD4mx/6Ov/P7DYhEf4xPPn9x7OM4wwAAAAAAe3A3fvDizxez/+DTH59WW5lza6/Pu+PL2czbw8fvXv5Sa6zP3Xxk2tICtLYBLbW0AC1sQJMdPFWYqA5eY33GBZgqTFQH11qfah1cUoDWNqCllhaghQ1IB3+jgy/QwXWfX4MO/kYHX6CD6z6/BsfBMxwHz3AcXJ4HAAAAAGCR4/GZfB5nw5sdbW/5fTsN72GQha9OP/ndGw+1ZLS95WPdNB88djbUw+FevgVPqizlNNrTIE9/Xt+0e8sHqtPBj4d3fYvuLR+oTgeTXGuHJa3lA1Xo4IuHDVfG3FseAAAA2Moqs0klJ2Z7y0epOZs09VA+ULXJhoetuHBz7i0fpcJb9NT2OzXy3vK719rJ/dbysZ7WWtDhcD++zkG+ESb8mdPaW2Jr+Vg6ODkFBgAAAPjfxbN0s6f6+snHciYruWoFPjv5Lt+IavPBw/Kh9pbfsYcps8K5s97ySRwX3nWmt3wIH7KSU2DKtPaptbX8jj3eFV3fOfWWBwAAALbiHh0b5aO4R8cW+UDVbic8FN/ivrd8LLf03yIfqM5b9NnwZkfbWz6D1qbnWstHMeFPgdY+tbaWD6SDmXNx+y05zOgkDwAAAGzFFR0b5aO4omOLfKCaV3QMw3A43JdfEdFJPpbJhuRq3oRlWL4h95bfq9M4T1+TLRlzb/ndGw+y/AXqJx/IPjg5BU6u5q0MxxcalhxKdpUHAAAA9mXp8X5v+RCu6NgiH6jyFR3Xn+wzH8vP6myU37fW3hJbywcyXUiB1q6gaC2/b629mq3lY3mLZk5rn1dbywMAAAAAAAAAAAAAAPSq2q+u3OKv1z8//P239/9YfkW+fJZcfIHHm//jh5Z/o/gCsyoFTk6Bk1Pg5BQ4OQVOToGTCy7wxaPGioeSe1/+7XRwcgqcnAInp8DJKXBylX8B/PuM51DX+Ai69+XfQgcDAAAAAA1o4rtJUd4dX85m3h4+brAm63EuOrmuO3jKuLN1ME1rYj44Ssk+eO90cHL2wRfYB7Mb9sHJ6eDkZvbBv7/5YZv1YCWTBa5Y2v9++XEYhuefv9Ra4H69+vWnYRg+/P3vZv/jUz2am31wcgqcnAInd2cfnJsOTk6Bk1Pg5BQ4OQVOToGTU+DkFDi5r/CCTwE5labXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=160x210 at 0x7F32726DEC88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(210, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(7, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "numpy.uint8"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 14 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLOJWZ3ZM9hb"
      },
      "source": [
        "# PPO用ニューラルネットのモデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-EyRai1iARP"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self,nframes=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # 4x84x84 → 32x20x20 \n",
        "        self.conv1 = nn.Conv2d(in_channels=nframes, out_channels=64, kernel_size=8, stride=4)\n",
        "        # 32x20x20 →64x9x9\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2)\n",
        "        # 64x9x9 → 64x7x7 \n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        # 64x7x7 → FL \n",
        "        FL = 64\n",
        "        self.lin = nn.Linear(in_features=7 * 7 * 64, out_features=FL)\n",
        "        # FL → 4 actions 0-1 （行動決定）\n",
        "        self.pi_logits = nn.Linear(in_features=FL, out_features=4)\n",
        "        # 行動価値\n",
        "        self.value = nn.Linear(in_features=FL, out_features=1)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor):\n",
        "        h = F.relu(self.conv1(obs))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = h.reshape((-1, 7 * 7 * 64))\n",
        "\n",
        "        h = F.relu(self.lin(h))\n",
        "\n",
        "        pi = Categorical(logits=self.pi_logits(h))\n",
        "        value = self.value(h).reshape(-1)\n",
        "\n",
        "        return pi, value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9F7bqjidwCf"
      },
      "source": [
        "# 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "tGVSB2NriARV",
        "scrolled": true,
        "outputId": "389ff40a-ba44-4055-88d9-3b83963eea92"
      },
      "source": [
        "model = Model(16)\n",
        "model.to(device)\n",
        "game = Game(0,16)\n",
        "obs = game.reset()\n",
        "a=0\n",
        "for i in range(200):\n",
        "  obs,r,_,_ = game.step(a)\n",
        "  pi,v = model.forward(torch.tensor(obs,dtype=torch.float32,device=device)/255)\n",
        "for i in range(10):\n",
        "  obs,r,_,_ = game.step(a)\n",
        "  pi,v = model.forward(torch.tensor(obs,dtype=torch.float32,device=device)/255)\n",
        "  a0 = pi.sample() # 方策関数によりアクションを決定\n",
        "  a = a0[0] # アクション番号の数値化\n",
        "  print(a)\n",
        "\n",
        "display(obs.shape) # 画面データのシェイプを表示\n",
        "display(a0)\n",
        "display(a) # 選ばれたアクション番号を表示\n",
        "print(\"初期は確率がほぼ等確率になっていることを確認\")\n",
        "for i in range(4):\n",
        "    print(i,pow(np.e,(pi.log_prob(torch.tensor(i,device=device))))) # \n",
        "display(v.detach()) # 状態価値を表示\n",
        "display(model) # モデルを表示"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2, device='cuda:0')\n",
            "tensor(2, device='cuda:0')\n",
            "tensor(2, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1, 16, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([1], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor(1, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "初期は確率が等確率になっていることを確認\n",
            "0 tensor([0.2304], device='cuda:0', grad_fn=<PowBackward1>)\n",
            "1 tensor([0.2461], device='cuda:0', grad_fn=<PowBackward1>)\n",
            "2 tensor([0.2605], device='cuda:0', grad_fn=<PowBackward1>)\n",
            "3 tensor([0.2629], device='cuda:0', grad_fn=<PowBackward1>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([-0.0542], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(16, 64, kernel_size=(8, 8), stride=(4, 4))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (lin): Linear(in_features=3136, out_features=64, bias=True)\n",
              "  (pi_logits): Linear(in_features=64, out_features=4, bias=True)\n",
              "  (value): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvKriYliARb"
      },
      "source": [
        "# Multiprocessing Playloop\n",
        "# 学習のメインプログラム\n",
        "### 並列ゲームプレイヤのクラス定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghC4pGrBiARh"
      },
      "source": [
        "def playloop(agent: multiprocessing.connection.Connection,seed:int,k=8,skip=2,noop_max=30, mode = 0):\n",
        "\n",
        "    # create game\n",
        "    game = Game(seed=seed, k=k,skip=skip,noop_max=noop_max, mode = mode)\n",
        "    # AI player \n",
        "    while True:\n",
        "        cmd, action = agent.recv()\n",
        "        if cmd == \"step\":\n",
        "            agent.send(game.step(action))\n",
        "        elif cmd == \"reset\":\n",
        "            agent.send(game.reset())\n",
        "        elif cmd == \"close\":\n",
        "            agent.close()\n",
        "            break\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "class CoPlayer:\n",
        "    def __init__(self, seed, k=8,skip=2,noop_max=30,mode = 0):\n",
        "        self.child, parent = multiprocessing.Pipe()\n",
        "        self.process = multiprocessing.Process(target=playloop, args=(parent, seed, k,skip,noop_max,mode))\n",
        "        self.process.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQr3RqvxEoHA"
      },
      "source": [
        "### パイプ動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv7YYQpo6HGy",
        "outputId": "26384fe7-0a5d-4e6f-b7d5-c434a315f819"
      },
      "source": [
        "cop2 = CoPlayer(0,8)\n",
        "cop2.child.send((\"reset\",None))\n",
        "a = cop2.child.recv()\n",
        "cop2.child.send((\"step\",1))\n",
        "a2,b,c,d = cop2.child.recv()\n",
        "cop2.child.send((\"close\",None))\n",
        "a.shape,a2.shape,b,c,d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 8, 84, 84), (1, 8, 84, 84), 0.0, False, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLo5NlOfLFDJ"
      },
      "source": [
        "### ログフォルダの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSlfu2Xn7b9"
      },
      "source": [
        "import os\n",
        "SAVEFOLDER = '/content/drive/MyDrive/M/ppo'\n",
        "os.makedirs(SAVEFOLDER,exist_ok=True)\n",
        "modelPath = SAVEFOLDER+\"/model\"  # モデルの重みファイル名  (拡張子　.pt　が自動的に補われる）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PrMOErZeo8U"
      },
      "source": [
        "#### ハイパーパラメータの（一部）\r\n",
        "ハイパーパラメータのうち、ネットワークに関するものは上に、一部は Main のパラメータに、一部は関数定義に埋め込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4FcgTbTkBBd"
      },
      "source": [
        "NCYCLES = 2000 # 学習サイクル数　（データ収集→学習　が1サイクル）\n",
        "\n",
        "END_GREEDY_Progress = 0.0 # 0.8  付加的な擾乱期間　開始から全体の 0.8\n",
        "GreedyEPS_START = 0.0 # 0.3 擾乱期間開始時の付加的擾乱\n",
        "GreedyEPS_END = 0.0 # 0.1 擾乱期間終了後の付加的擾乱\n",
        "\n",
        "END_LOSTLIFE_Penalty_Progress = 1.0 # 1.0  初期の仮ペナルティ適用期間　開始から終了までの期間に対する割合\n",
        "\n",
        "# Hyper Parameters\n",
        "GAMMA = 0.93 # 0.99\n",
        "LAMDA = 0.90 # 0.906\n",
        "EPOCHS =  4 # サンプル１セットを何度学習プロセスに通すか\n",
        "NPLAYERS = 8 # 並列実行する数game\n",
        "NBATCHES = 256 # １度に処理するデータ数\n",
        "NDIVIDE = 4 # バッチの分割数\n",
        "SEEDZero = random.randint(1,10000)\n",
        "LearningRate = 0.0015\n",
        "NFRAMES = 6\n",
        "W_VFLOSS = 0.5 # loss におけるvfloss の重み\n",
        "W_BONUS = 0.088 # loss における entropy bonus の重み　0.01\n",
        "CLIPRANGE = 0.2 # ## Run it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrWOt3NiARi"
      },
      "source": [
        "class Main:\n",
        "    # mode 0 ：ライフが失われたらリセット、 mode 1：ライフが残っている場合は、画面を継続\n",
        "    def __init__(self,seed=SEEDZero,k=NFRAMES,skip=2,deadloss=38,noop_max=16,resume=False,ncycles=NCYCLES,mode = 0, lr=LearningRate,gamma=GAMMA,lamda=LAMDA,eb = W_BONUS):\n",
        "\n",
        "        self.lr = lr\n",
        "        self.gamma = gamma\n",
        "        self.lamda = lamda\n",
        "        self.eb = eb\n",
        "        self.k = k\n",
        "        self.ncycles = ncycles\n",
        "\n",
        "        self.lifes = 0 # 失った機体数 lost lifes\n",
        "        self.cycles = 0 # バッチ回数\n",
        "        self.deadloss = deadloss\n",
        "        self.mode = mode\n",
        "\n",
        "        self.progress = 0\n",
        "        \n",
        "        # 1サイクルに必要なサンプル数\n",
        "        self.batch_size = NPLAYERS * NBATCHES\n",
        "        # ミニバッチのサイズ\n",
        "        self.mini_batch_size = self.batch_size // NDIVIDE\n",
        "\n",
        "        # 初期化  \n",
        "        # CoPlayerの生成\n",
        "        self.coplayers = [CoPlayer(seed + i,k,skip,noop_max,mode) for i in range(NPLAYERS)]\n",
        "\n",
        "        # 観測情報の初期化　この部分を float や tensor にすると k が４に制限されてしまうので int で\n",
        "        self.obs = np.zeros((NPLAYERS, k, 84, 84), dtype=np.uint8)\n",
        "        for player in self.coplayers:\n",
        "            player.child.send((\"reset\", None))\n",
        "        for i, player in enumerate(self.coplayers):\n",
        "            self.obs[i] = player.child.recv()\n",
        "\n",
        "        # model for sampling\n",
        "        self.model = model = Model(k).to(device)\n",
        "        if resume: # 学習済み重みがある場合\n",
        "          shutil.copy( modelPath+'.pt', modelPath+'.bak.pt')\n",
        "          if torch.cuda.is_available():\n",
        "            self.model.load_state_dict(torch.load(modelPath+'.pt'))\n",
        "          else: #  gpu ありを前提としているが、cpu で続きを計算したい場合\n",
        "            self.model.load_state_dict(torch.load(modelPath+'.pt', map_location=torch.device('cpu')))\n",
        "\n",
        "        # optimizer\n",
        "        # lr = LearningRate\n",
        "        optimizers = {}\n",
        "        # optimizers['SGD'] = optim.SGD(model.parameters(), lr)\n",
        "        # optimizers['Adagrad'] = optim.Adagrad(model.parameters(), lr)\n",
        "        # optimizers['RMSprop'] = optim.RMSprop(model.parameters(), lr)\n",
        "        # optimizers['Adadelta'] = optim.Adadelta(model.parameters(), lr)\n",
        "        # optimizers['Adam'] = optim.Adam(model.parameters(), lr)\n",
        "        optimizers['AdamW'] = optim.AdamW(model.parameters(), lr)\n",
        "        self.optimizer = optimizers['AdamW']\n",
        "\n",
        "    @staticmethod\n",
        "    def _toTT(obs: np.ndarray) -> torch.Tensor:\n",
        "        return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize(adv: torch.Tensor):\n",
        "        return (adv - adv.mean()) / (adv.std() + 1e-8)\n",
        "\n",
        "    def sample(self) -> (Dict[str, torch.Tensor], List):\n",
        "        # 学習データの記憶域確保\n",
        "        rewards = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        actions = np.zeros((NPLAYERS, NBATCHES), dtype=np.int32)\n",
        "        done = np.zeros((NPLAYERS, NBATCHES), dtype=np.bool)\n",
        "        obs = np.zeros((NPLAYERS, NBATCHES, self.k, 84, 84), dtype=np.float32)\n",
        "        log_pis = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        values = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        \n",
        "        # 画像データの初期化\n",
        "        for t in progress_bar(range(NBATCHES), parent=self.mpbar):\n",
        "            with torch.no_grad(): # 傾きを固定して実行\n",
        "                obs[:, t] = self.obs\n",
        "                pi, v = self.model(self._toTT(self.obs))\n",
        "                values[:, t] = v.cpu().numpy()\n",
        "                a0 = pi.sample()\n",
        "                \n",
        "                # epsiron greedy action selection\n",
        "                if self.progress >= END_GREEDY_Progress:\n",
        "                    g_eps = GreedyEPS_END\n",
        "                else:\n",
        "                    g_eps = GreedyEPS_START + self.progress * (END_GREEDY_Progress- GreedyEPS_START)/END_GREEDY_Progress\n",
        "                for i in range(NPLAYERS):\n",
        "                    if torch.rand(1) <= g_eps: \n",
        "                        a0[i] = torch.randint(0,4,(1,))\n",
        "                a =a0.cpu().numpy()\n",
        "                actions[:, t] = a\n",
        "                log_pis[:, t] = pi.log_prob(a0).cpu().numpy()\n",
        "                \n",
        "            for w, player in enumerate(self.coplayers):\n",
        "                player.child.send((\"step\", actions[w, t]))\n",
        " \n",
        "            for w, player in enumerate(self.coplayers):\n",
        "                self.obs[w], rewards[w, t], done[w, t], info  =  player.child.recv()\n",
        "\n",
        "                if info : # info \n",
        "                    if self.progress >= END_LOSTLIFE_Penalty_Progress:\n",
        "                       dlrate = 0\n",
        "                    else:\n",
        "                       dlrate = 1 - self.progress/END_LOSTLIFE_Penalty_Progress \n",
        "                    rewards[w, t] -=  dlrate * self.deadloss\n",
        "                    self.lifes += 1\n",
        "                    wandb.log({'reward':info['reward'],'lengt':info['length']})\n",
        "                    wandb.log({'lifes':self.lifes,'cycles':self.cycles})\n",
        "             \n",
        "        # calculate advantages\n",
        "        advantages = self._calc_advantages(done, rewards, values)\n",
        "        samples = {\n",
        "            'obs': obs,\n",
        "            'actions': actions,\n",
        "            'values': values,\n",
        "            'log_pis': log_pis,\n",
        "            'advantages': advantages\n",
        "        }\n",
        "\n",
        "        samples_flat = {}\n",
        "        for k, v in samples.items():\n",
        "            v = v.reshape(v.shape[0] * v.shape[1], *v.shape[2:])\n",
        "            if k == 'obs':\n",
        "                samples_flat[k] = self._toTT(v)\n",
        "            else:\n",
        "                samples_flat[k] = torch.tensor(v, device=device)\n",
        "        return samples_flat, rewards[rewards>0].mean()\n",
        "\n",
        "    def _calc_advantages(self, done: np.ndarray, rewards: np.ndarray, values: torch.Tensor) -> np.ndarray:\n",
        "        advantages = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        last_advantage = 0\n",
        "        _, last_value = self.model(self._toTT(self.obs))\n",
        "        last_value = last_value.cpu().data.numpy()\n",
        "\n",
        "        for t in reversed(range(NBATCHES)):\n",
        "            mask = 1 - done[:, t]\n",
        "            last_value = last_value * mask\n",
        "            last_advantage = last_advantage * mask\n",
        "            #delta = rewards[:, t] + GAMMA * last_value - values[:, t]\n",
        "            #last_advantage = delta + GAMMA * LAMDA * last_advantage\n",
        "            delta = rewards[:, t] + self.gamma * last_value - values[:, t]\n",
        "            last_advantage = delta + self.gamma * self.lamda * last_advantage\n",
        "            advantages[:, t] = last_advantage\n",
        "            last_value = values[:, t]\n",
        "\n",
        "        return advantages\n",
        "    \n",
        "    # 1サイクルの学習\n",
        "    def train(self, samples: Dict[str, torch.Tensor], learning_rate: float, clip_range: float):\n",
        "\n",
        "        for _ in range(EPOCHS):\n",
        "            # 並べ替え用の数列\n",
        "            indexes = torch.randperm(self.batch_size)\n",
        "\n",
        "            # ミニバッチ単位で処理\n",
        "            for start in range(0, self.batch_size, self.mini_batch_size):\n",
        "                # get mini batch\n",
        "                end = start + self.mini_batch_size\n",
        "                mini_batch_indexes = indexes[start: end]\n",
        "                mini_batch = {}\n",
        "                for k, v in samples.items():\n",
        "                    mini_batch[k] = v[mini_batch_indexes]\n",
        "\n",
        "                # train\n",
        "                loss = self._calc_loss(clip_range=clip_range,\n",
        "                                       samples=mini_batch)\n",
        "\n",
        "                # compute gradients\n",
        "                for pg in self.optimizer.param_groups:\n",
        "                    pg['lr'] = learning_rate\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n",
        "                self.optimizer.step()\n",
        "\n",
        "    def _calc_loss(self, samples: Dict[str, torch.Tensor], clip_range: float) -> torch.Tensor:\n",
        "        sampled_return = samples['values'] + samples['advantages']\n",
        "        sampled_normalized_advantage = self._normalize(samples['advantages'])\n",
        "        pi, value = self.model(samples['obs'])\n",
        "\n",
        "        # #### Policy\n",
        "        log_pi = pi.log_prob(samples['actions'])\n",
        "\n",
        "        ratio = torch.exp(log_pi - samples['log_pis'])\n",
        "\n",
        "        clipped_ratio = ratio.clamp(min=1.0 - clip_range,\n",
        "                                    max=1.0 + clip_range)\n",
        "        policy_reward = torch.min(ratio * sampled_normalized_advantage,\n",
        "                                  clipped_ratio * sampled_normalized_advantage)\n",
        "        policy_reward = policy_reward.mean()\n",
        "\n",
        "        # #### Entropy Bonus\n",
        "        entropy_bonus = pi.entropy()\n",
        "        entropy_bonus = entropy_bonus.mean()\n",
        "\n",
        "        # #### Value\n",
        "        clipped_value = samples['values'] + (value - samples['values']).clamp(min=-clip_range,\n",
        "                                                                              max=clip_range)\n",
        "        vf_loss = torch.max((value - sampled_return) ** 2, (clipped_value - sampled_return) ** 2)\n",
        "        vf_loss = 0.5 * vf_loss.mean()\n",
        "        loss = -(policy_reward - W_VFLOSS* vf_loss + self.eb * entropy_bonus)\n",
        "\n",
        "        # for monitoring\n",
        "        approx_kl_divergence = .5 * ((samples['log_pis'] - log_pi) ** 2).mean()\n",
        "        clip_fraction = (abs((ratio - 1.0)) > clip_range).to(torch.float).mean()\n",
        "        \n",
        "        wandb.log({'policy_reward': policy_reward,\n",
        "                     'vf_loss': vf_loss,\n",
        "                     'entropy_bonus': entropy_bonus,\n",
        "                     'kl_div': approx_kl_divergence,\n",
        "                     'clip_fraction': clip_fraction})        \n",
        "        return loss\n",
        "\n",
        "    def run_training_loop(self):\n",
        "\n",
        "        ### Run training loop\n",
        "        self.mpbar = master_bar(range(self.ncycles))\n",
        "        for cycle in self.mpbar:\n",
        "            self.cycles = cycle \n",
        "            self.progress = progress = cycle / self.ncycles\n",
        "\n",
        "            # decreasing `learning_rate` and `clip_range` \n",
        "            #learning_rate = LearningRate * (1 - progress)\n",
        "            learning_rate = self.lr * (1 - progress)\n",
        "            clip_range = CLIPRANGE * (1 - progress)\n",
        "            samples,mrewards = self.sample()\n",
        "            # train the model\n",
        "            self.train(samples, learning_rate, clip_range)\n",
        "\n",
        "            # write summary info to the writer, and log to the screen\n",
        "            if (cycle + 1) % 10 == 0:\n",
        "                #torch.save(self.model.state_dict(),modelPath+'.pt' )SAVEFOLDER+\"/model\"\n",
        "                torch.save(self.model.state_dict(),SAVEFOLDER+\"/model\"+'.pt' )\n",
        "            if (cycle + 1) % 250 == 0:\n",
        "                torch.save(self.model.state_dict(),SAVEFOLDER+\"/model\"+'{}'.format(cycle+1)+'.pt')\n",
        "        torch.save(self.model.state_dict(),modelPath+'.pt')\n",
        "        return mrewards\n",
        "\n",
        "    def destroy(self):\n",
        "\n",
        "        for player in self.coplayers:\n",
        "            player.child.send((\"close\", None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywW3eB4vLOa0"
      },
      "source": [
        "## W and B\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a9a73619f2144e8f9ef80d826997969d",
            "de44bb7c449d4e3eac396e0eac3fab1b",
            "bac53e5f38494602886ce90b71703e15",
            "7e3cdb922bd348248698c475599b28ab",
            "eaf0ca94d4e3454e93d8f346576fd0de",
            "349a4d1b06fa4fbfa76f26cdf04d3380",
            "b77deb2fd935495b9a29a1563c71bae2",
            "6d2f72c8a01b40d5b088764ce37badbe"
          ]
        },
        "id": "JmoHAp4qiAQ3",
        "scrolled": true,
        "outputId": "a987b535-2169-4678-91ad-b5899f6ad7d9"
      },
      "source": [
        "# Inside my model training code \n",
        "!export WANDB_NOTEBOOK_NAME=\"PPO.ipynb\"\n",
        "import wandb\n",
        "PROJECTNAME='PPO'\n",
        "wandb.init(project=PROJECTNAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2020d57a) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 488<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9a73619f2144e8f9ef80d826997969d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20201229_171701-2020d57a/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20201229_171701-2020d57a/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>policy_reward</td><td>0.00041</td></tr><tr><td>vf_loss</td><td>2.4991</td></tr><tr><td>entropy_bonus</td><td>1.3791</td></tr><tr><td>kl_div</td><td>2e-05</td></tr><tr><td>clip_fraction</td><td>0.13672</td></tr><tr><td>_step</td><td>1047</td></tr><tr><td>_runtime</td><td>380</td></tr><tr><td>_timestamp</td><td>1609262601</td></tr><tr><td>reward</td><td>120.0</td></tr><tr><td>lengt</td><td>939</td></tr><tr><td>lifes</td><td>112</td></tr><tr><td>cycles</td><td>19</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>policy_reward</td><td>▅▄█▅▆▂▅▇▅▆▅▅▄▅▅▄▄▅▅▅█▄▅▅▅▄▁▅▆█▆▄▅▅▅▅▆▅▅▅</td></tr><tr><td>vf_loss</td><td>▁▂▂▂█▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▄▁▁█▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>entropy_bonus</td><td>████▆▄▄▄▄▄▁▁▄▆▅▅▅▆▆▆▅▄▇▇▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>kl_div</td><td>▁▂▃▂▂█▅▄▂▂▂▂▂▂▁▁▁▁▁▁█▂▂▁▂▂▃▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>clip_fraction</td><td>▁▁▂▁▂█▆▅▁▁▃▃▃▅▂▂▃▂▂▁▆▁▁▁▂▁▃▁▁▃▃▁▁▂▂▂▂▅▂▅</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>reward</td><td>▂▂▃▁▂▂▂▄▂▁▃▂▁▃▃█▃▁▂▁▂▂▁▁▂▁▂▃▂▁▃▁▁▂▆▁▁▂▁▄</td></tr><tr><td>lengt</td><td>▃▃▆▃▃▃▅▅▂▂▃▅▃▃▃█▃▃▂▁▂▃▁▁▂▃▂▃▃▁▂▁▂▃▆▂▂▃▃█</td></tr><tr><td>lifes</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>cycles</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇██▁▁▁▂▂▂▃▃▃▄▄▅▅▅▅▆▆▆▇▇██</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">radiant-vortex-51</strong>: <a href=\"https://wandb.ai/aquapathos/PPO/runs/2020d57a\" target=\"_blank\">https://wandb.ai/aquapathos/PPO/runs/2020d57a</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2020d57a). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">vague-pine-52</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/aquapathos/PPO\" target=\"_blank\">https://wandb.ai/aquapathos/PPO</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/aquapathos/PPO/runs/11pmv40s\" target=\"_blank\">https://wandb.ai/aquapathos/PPO/runs/11pmv40s</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20201229_172355-11pmv40s</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f3271ffde80>"
            ],
            "text/html": [
              "<h1>Run(11pmv40s)</h1><p></p><iframe src=\"https://wandb.ai/aquapathos/PPO/runs/11pmv40s\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xN_-yArl4PRu",
        "outputId": "61eafd3d-9376-4047-96be-c0762b01ba0d"
      },
      "source": [
        "# 学習１ターン目  mode 0, dedloss ありで\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=50,noop_max=16,resume=False,ncycles=NCYCLES,mode=0)\n",
        "m.run_training_loop()\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L0jrraj4giX4",
        "outputId": "e75b8cb3-5138-4bf7-e01c-42c52881343e"
      },
      "source": [
        "# 学習２ターン目　mode 1, dedloss なしで\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=1)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-aoJrrKsppIq",
        "outputId": "74b28bff-dbb0-41d1-8bf1-10b8372b0199"
      },
      "source": [
        "# 学習１ターン目  mode 0, dedloss ありで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=0)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1231' class='' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      61.55% [1231/2000 1:01:15<38:16]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='60' class='' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      23.44% [60/256 00:00<00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHqW8fou3VjS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtsOWy83j5W"
      },
      "source": [
        "![rewards](https://user-images.githubusercontent.com/5820803/103320826-404a2a80-4a7a-11eb-9bb6-9dd04cef52d0.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Upl2kkiARk"
      },
      "source": [
        "# torch.save(model.state_dict(),'ppomodel')\n",
        "# model.load_state_dict(torch.load('ppomodel'))\n",
        "# torch.save(model.state_dict(),'ppomodel{}'.format(100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwx6KcNdA12"
      },
      "source": [
        "# [Optuna](https://optuna.org/)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPP6e08dOYI"
      },
      "source": [
        "!pip install optuna > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNoP7bO0dANJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "dca7b01d-53b5-4836-b558-7b2a1dfca6eb"
      },
      "source": [
        "import optuna\r\n",
        "\r\n",
        "def objective(trial):\r\n",
        "    # Categorical parameter\r\n",
        "    # optimizer = trial.suggest_categorical('k', [2,4,6,8,10,14,16])\r\n",
        "\r\n",
        "    # Int parameter\r\n",
        "    # num_layers = trial.suggest_int('deladloss', 1, 51)\r\n",
        "\r\n",
        "    # Loguniform parameter\r\n",
        "    # gamma = trial.suggest_loguniform('gamma', 0.90, 0.97)\r\n",
        "    eb = trial.suggest_loguniform('eb',0.006,0.1)\r\n",
        "\r\n",
        "    m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=False,lr=0.0015,eb=eb)\r\n",
        "    mrewards = m.run_training_loop()\r\n",
        "    m.destroy()\r\n",
        "\r\n",
        "    return -mrewards\r\n",
        "\r\n",
        "study = optuna.create_study()\r\n",
        "study.optimize(objective, n_trials=10)\r\n",
        "study.best_params  # "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:12:37,595]\u001b[0m A new study created in memory with name: no-name-944a7419-505a-45cd-85d9-47787ba97ef2\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:20:01,548]\u001b[0m Trial 0 finished with value: -22.70833396911621 and parameters: {'eb': 0.009226583067767354}. Best is trial 0 with value: -22.70833396911621.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:27:25,885]\u001b[0m Trial 1 finished with value: -13.214285850524902 and parameters: {'eb': 0.02505062922916771}. Best is trial 0 with value: -22.70833396911621.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:34:49,843]\u001b[0m Trial 2 finished with value: -13.69565200805664 and parameters: {'eb': 0.008589591819676763}. Best is trial 0 with value: -22.70833396911621.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:42:15,990]\u001b[0m Trial 3 finished with value: -25.625 and parameters: {'eb': 0.0877108482599416}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:49:39,463]\u001b[0m Trial 4 finished with value: -10.384614944458008 and parameters: {'eb': 0.00732262468678601}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:57:05,027]\u001b[0m Trial 5 finished with value: -12.741935729980469 and parameters: {'eb': 0.007252702219857107}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:04:29,513]\u001b[0m Trial 6 finished with value: -12.5 and parameters: {'eb': 0.015636227168278966}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:11:53,689]\u001b[0m Trial 7 finished with value: -11.25 and parameters: {'eb': 0.008056487110270742}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:19:20,786]\u001b[0m Trial 8 finished with value: -9.615385055541992 and parameters: {'eb': 0.030985104016693958}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:26:45,818]\u001b[0m Trial 9 finished with value: -12.291666984558105 and parameters: {'eb': 0.03374553985680278}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eb': 0.0877108482599416}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFxQSkkh9nlQ"
      },
      "source": [
        "# Demoモード\r\n",
        "\r\n",
        "Colab では表示できません"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50QeBOYDgwWj"
      },
      "source": [
        "random.seed(datetime.now())\r\n",
        "DEFAULTSEED = random.randint(1, 10000)\r\n",
        "import time\r\n",
        "\r\n",
        "model = Model(NFRAMES).to(device)\r\n",
        "model.load_state_dict(torch.load(SAVEFOLDER+\"/model\" ))\r\n",
        "game = Game(seed=DEFAULTSEED, k=NFRAMES,skip=2,noop_max=0,demo=True)\r\n",
        "\r\n",
        "def _toTT(obs: np.ndarray) -> torch.Tensor:\r\n",
        "    return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0    \r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    print(i,end='')\r\n",
        "    observation = game.reset()  \r\n",
        "    while True:\r\n",
        "        time.sleep(0.02)\r\n",
        "        game.render()\r\n",
        "        pi, v = model(_toTT(observation))\r\n",
        "        action = pi.sample().cpu().numpy()[0] # 方策関数によりアクションを決定\r\n",
        "        observation, reward, done, info = game.step(action) \r\n",
        "        if done: \r\n",
        "          break;\r\n",
        "        \r\n",
        "game.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq_ns9qe51Dd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}