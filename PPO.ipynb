{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/MLLesson/blob/master/PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CS72K-uiAQn"
      },
      "source": [
        "# AtariスペースインベーダのPPO による強化学習の実装\n",
        "\n",
        "参考\n",
        "\n",
        "- https://github.com/vpj/rl_samples\n",
        "http://blog.varunajayasiri.com/ml/ppo_pytorch.html\n",
        "\n",
        "ほぼそのままです。違いはクラウドログサービスを WandB に変更してあることと、そのままだと過学習のせいか得点が伸びずに戦略が固まってしまうようなので、εグリーディを pytorch だよりとは別に設定できるようにした点ぐらいです。\n",
        "\n",
        "#### 他に参考にしたサイト\n",
        "\n",
        "- [PythonでPPOを実装してみた](https://qiita.com/oki_uta_aiota/items/a15ba5de6ed3c1268ed3#%E5%85%A8%E4%BD%93%E3%81%AE%E3%82%B3%E3%83%BC%E3%83%89)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S2e1GxIKGiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da55396f-cf9a-4af3-9a2a-c38ff8153db6"
      },
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(time.time())\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(repr(device))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device(type='cpu')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7B5y3RLEPsY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fb2f18d-cf45-4621-b14e-80a8ba97fc1a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ndL3LBK3Vg"
      },
      "source": [
        "# 外部ライブラリの追加"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7cJQgKWihEN"
      },
      "source": [
        "!pip install pfrl > /dev/null\n",
        "!pip install wandb > /dev/null\n",
        "!pip install fastprogress > /dev/null\n",
        "#!pip install gym[atari] > /dev/null"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avyWPx9-iAQ-"
      },
      "source": [
        "import multiprocessing\n",
        "import multiprocessing.connection\n",
        "from typing import Dict, List\n",
        "from fastprogress.fastprogress import master_bar, progress_bar\n",
        "\n",
        "import gym\n",
        "from gym import ObservationWrapper\n",
        "from gym.spaces import Box\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.distributions import Categorical\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from pfrl.wrappers.atari_wrappers import FrameStack,NoopResetEnv,MaxAndSkipEnv\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvyoQhmZLybp"
      },
      "source": [
        "# ラッパー定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq2fQjdZiARA"
      },
      "source": [
        "class myCrop(ObservationWrapper):\n",
        "    def __init__(self, env, tmgn=0, bmgn=0,lmgn=0,rmgn=0,igcolors=[],bgcolor=[0,0,0]):\n",
        "        super(myCrop, self).__init__(env)\n",
        "        self.tmgn, self.bmgn = tmgn, bmgn\n",
        "        self.lmgn, self.rmgn = lmgn, rmgn\n",
        "        self.igcolors, self.bgcolors = igcolors, bgcolor\n",
        "        self.observation_space = Box(low=0, high=255, shape=(84,84), dtype=np.uint8)\n",
        "    def observation(self, obs):\n",
        "        img_mask = np.zeros(obs.shape[:2],np.uint8)\n",
        "        for color in self.igcolors:\n",
        "            bgrLower = np.array(color)    \n",
        "            bgrUpper = np.array(color)\n",
        "            tmask = cv2.inRange(obs, bgrLower, bgrUpper) \n",
        "            img_mask = cv2.bitwise_or(img_mask,tmask)\n",
        "        obs = cv2.bitwise_and(obs,obs,mask=255-img_mask) # 元画像とマスクを合成\n",
        "        RIGHT=obs.shape[1]-self.rmgn\n",
        "        BOTTOM=obs.shape[0]-self.bmgn\n",
        "        obs = obs[self.tmgn:BOTTOM,self.lmgn:RIGHT]\n",
        "        obs = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
        "        observation = cv2.resize(obs, (84, 84), interpolation=cv2.INTER_AREA)\n",
        "        return observation\n",
        "\n",
        "class myFrameStack(FrameStack):\n",
        "    def __init__(self, env, k=8, mode=0,demo=False):\n",
        "        super(myFrameStack, self).__init__(env, k=k, channel_order=\"chw\")\n",
        "        self.lives = 0\n",
        "        self.lsumrewards = 0\n",
        "        self.localsteps = 0\n",
        "        self.demo = demo\n",
        "        self.mode = mode\n",
        "    def reset(self):\n",
        "        ob = self.env.reset()\n",
        "        return self._reset(ob)\n",
        "    def _reset(self,ob):\n",
        "        for _ in range(self.k):\n",
        "          self.frames.append(ob)\n",
        "        self.lives = self.env.unwrapped.ale.lives()\n",
        "        self.lsumrewards = 0\n",
        "        self.localsteps = 0\n",
        "        return  np.array([list(self.frames)])\n",
        "    def step(self, action):\n",
        "        self.localsteps += 1  \n",
        "        ob, reward, done1, info = self.env.step(action)\n",
        "        self.lsumrewards += reward\n",
        "        self.frames.append(ob)\n",
        "        returnobs = np.array([list(self.frames)])\n",
        "        episode_info = None\n",
        "        if self.demo:\n",
        "            return returnobs,rewad,done1,info\n",
        "        # 残機数確認\n",
        "        else: # if train mode\n",
        "            lives = self.env.unwrapped.ale.lives()\n",
        "            if done1 or lives < self.lives: # １機死んだら終了とする\n",
        "                done = True\n",
        "                episode_info = {\"reward\": self.lsumrewards, \"length\": self.localsteps}\n",
        "                if done1 or self.mode == 0: \n",
        "                  self.reset() \n",
        "                else: # mode 1 ライフが減っただけの場合はシーンは継続\n",
        "                  self._reset(ob)\n",
        "            else:\n",
        "                done = False\n",
        "            return returnobs, reward, done, episode_info\n",
        "\n",
        "def mkenv(envname,k=8,skip=2,tmgn=0,bmgn=0,lmgn=0,rmgn=0,igcolors=[],noop_max=30, mode = 0, demo=False):\n",
        "  env=gym.make(envname)\n",
        "  if noop_max > 0:\n",
        "      env = NoopResetEnv(env, noop_max=noop_max)\n",
        "  if skip > 1:\n",
        "      env = MaxAndSkipEnv(env, skip=skip)\n",
        "  env=myCrop(env, tmgn=tmgn, bmgn=bmgn, lmgn=lmgn, rmgn=rmgn, igcolors=igcolors)\n",
        "  env=myFrameStack(env,k=k,mode=mode,demo=demo)\n",
        "  return env"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWIH0JlWiARD"
      },
      "source": [
        "# Game Environment の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc2-DseiARG"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "random.seed(datetime.now())\n",
        "DEFAULTSEED = random.randint(1, 10000)\n",
        "def Game(seed=DEFAULTSEED,k=8,skip=2,noop_max=30, mode = 0):\n",
        "    ENV_NAME = 'SpaceInvadersNoFrameskip-v4'\n",
        "    Tmgn=20\n",
        "    Bmgn=12\n",
        "    Lmgn=8\n",
        "    Rmgn=8\n",
        "    #NOCOLOR=[[162,134,56]]  # 背景と同一視するカラー\n",
        "    NOCOLOR=[]\n",
        "\n",
        "    env = mkenv(ENV_NAME,k,skip,Tmgn,Bmgn,Lmgn,Rmgn,NOCOLOR,noop_max=noop_max, mode = mode)\n",
        "    env.seed(seed)\n",
        "    return env"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhWKKV7miARI"
      },
      "source": [
        "### 補足\n",
        "**k** : 過去何フレーム分の画面をデータとするか  \n",
        "**skip** : 何フレームおきにサンプリングするか  \n",
        "**Tmgn,Bmgn,Lmgn,Rmgn** カットする余白量  \n",
        "**NOCOLOR** 黒に置き換える色をRGB指定。複数指定可能  \n",
        "上の設定はインベーダ決め打ち\n",
        "\n",
        "## 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZisujiNyiARJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "a6a29731-ea78-4542-b7af-597def2239da"
      },
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "DEFAULTSEED = random.seed(datetime.now())\n",
        "\n",
        "# 原画像が表示できるかテスト\n",
        "game = Game(DEFAULTSEED,7)\n",
        "orgimg = game.render(mode='rgb_array')\n",
        "display(Image.fromarray(orgimg))\n",
        "display(orgimg.shape)\n",
        "\n",
        "# リセット画像の確認\n",
        "plt.figure(figsize=(8,4),dpi=150)\n",
        "imgs = game.reset()\n",
        "imgs = imgs[0]\n",
        "for i,img in enumerate(imgs):\n",
        "    plt.subplot(2,8,i+1)\n",
        "    plt.imshow(img)\n",
        "# ステップ画像の確認\n",
        "for _ in range(60):\n",
        "  imgs,r,d,i= game.step(game.action_space.sample()) \n",
        "imgs = imgs[0]\n",
        "for i,img in enumerate(imgs):\n",
        "    plt.subplot(2,8,i+9)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# Check types\n",
        "display(imgs.shape,imgs[0,0,0],imgs[0,40,40],type(imgs[0,0,0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAADn0lEQVR4nO3dsa7TVhgHcF/EM3QqDJ0qVV2YeIcuFUwsPEjUscqDsMPWd2BiqZA6dejlQRiCbq3cOD4mx/6Ov/P7DYhEf4xPPn9x7OM4wwAAAAAAe3A3fvDizxez/+DTH59WW5lza6/Pu+PL2czbw8fvXv5Sa6zP3Xxk2tICtLYBLbW0AC1sQJMdPFWYqA5eY33GBZgqTFQH11qfah1cUoDWNqCllhaghQ1IB3+jgy/QwXWfX4MO/kYHX6CD6z6/BsfBMxwHz3AcXJ4HAAAAAGCR4/GZfB5nw5sdbW/5fTsN72GQha9OP/ndGw+1ZLS95WPdNB88djbUw+FevgVPqizlNNrTIE9/Xt+0e8sHqtPBj4d3fYvuLR+oTgeTXGuHJa3lA1Xo4IuHDVfG3FseAAAA2Moqs0klJ2Z7y0epOZs09VA+ULXJhoetuHBz7i0fpcJb9NT2OzXy3vK719rJ/dbysZ7WWtDhcD++zkG+ESb8mdPaW2Jr+Vg6ODkFBgAAAPjfxbN0s6f6+snHciYruWoFPjv5Lt+IavPBw/Kh9pbfsYcps8K5s97ySRwX3nWmt3wIH7KSU2DKtPaptbX8jj3eFV3fOfWWBwAAALbiHh0b5aO4R8cW+UDVbic8FN/ivrd8LLf03yIfqM5b9NnwZkfbWz6D1qbnWstHMeFPgdY+tbaWD6SDmXNx+y05zOgkDwAAAGzFFR0b5aO4omOLfKCaV3QMw3A43JdfEdFJPpbJhuRq3oRlWL4h95bfq9M4T1+TLRlzb/ndGw+y/AXqJx/IPjg5BU6u5q0MxxcalhxKdpUHAAAA9mXp8X5v+RCu6NgiH6jyFR3Xn+wzH8vP6myU37fW3hJbywcyXUiB1q6gaC2/b629mq3lY3mLZk5rn1dbywMAAAAAAAAAAAAAAPSq2q+u3OKv1z8//P239/9YfkW+fJZcfIHHm//jh5Z/o/gCsyoFTk6Bk1Pg5BQ4OQVOToGTCy7wxaPGioeSe1/+7XRwcgqcnAInp8DJKXBylX8B/PuM51DX+Ai69+XfQgcDAAAAAA1o4rtJUd4dX85m3h4+brAm63EuOrmuO3jKuLN1ME1rYj44Ssk+eO90cHL2wRfYB7Mb9sHJ6eDkZvbBv7/5YZv1YCWTBa5Y2v9++XEYhuefv9Ra4H69+vWnYRg+/P3vZv/jUz2am31wcgqcnAInd2cfnJsOTk6Bk1Pg5BQ4OQVOToGTU+DkFDi5r/CCTwE5labXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=160x210 at 0x7F87DB7905F8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(210, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(7, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "numpy.uint8"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 14 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLOJWZ3ZM9hb"
      },
      "source": [
        "# PPO用ニューラルネットのモデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-EyRai1iARP"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self,nframes=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # 4x84x84 → 32x20x20 \n",
        "        self.conv1 = nn.Conv2d(in_channels=nframes, out_channels=64, kernel_size=8, stride=4)\n",
        "        # 32x20x20 →64x9x9\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2)\n",
        "        # 64x9x9 → 64x7x7 \n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        # 64x7x7 → FL \n",
        "        FL = 256\n",
        "        self.lin = nn.Linear(in_features=7 * 7 * 64, out_features=FL)\n",
        "        # FL → 4 actions 0-1 （行動決定）\n",
        "        self.pi_logits = nn.Linear(in_features=FL, out_features=4)\n",
        "        # 行動価値\n",
        "        self.value = nn.Linear(in_features=FL, out_features=1)\n",
        "\n",
        "    def forward(self, obs: torch.Tensor):\n",
        "        h = F.relu(self.conv1(obs))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = h.reshape((-1, 7 * 7 * 64))\n",
        "\n",
        "        h = F.relu(self.lin(h))\n",
        "\n",
        "        pi = Categorical(logits=self.pi_logits(h))\n",
        "        value = self.value(h).reshape(-1)\n",
        "\n",
        "        return pi, value"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9F7bqjidwCf"
      },
      "source": [
        "# 動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "tGVSB2NriARV",
        "scrolled": true,
        "outputId": "bdeb7f5f-aca4-4900-fa78-d9c0c32eb43a"
      },
      "source": [
        "model = Model(16)\n",
        "model.to(device)\n",
        "game = Game(0,16)\n",
        "obs = game.reset()\n",
        "a=0\n",
        "for i in range(200):\n",
        "  obs,r,_,_ = game.step(a)\n",
        "  pi,v = model.forward(torch.tensor(obs,dtype=torch.float32,device=device)/255)\n",
        "for i in range(10):\n",
        "  obs,r,_,_ = game.step(a)\n",
        "  pi,v = model.forward(torch.tensor(obs,dtype=torch.float32,device=device)/255)\n",
        "  a0 = pi.sample() # 方策関数によりアクションを決定\n",
        "  a = a0[0] # アクション番号の数値化\n",
        "  print(a)\n",
        "\n",
        "display(obs.shape) # 画面データのシェイプを表示\n",
        "display(a0)\n",
        "display(a) # 選ばれたアクション番号を表示\n",
        "print(\"初期は確率がほぼ等確率になっていることを確認\")\n",
        "for i in range(4):\n",
        "    print(i,pow(np.e,(pi.log_prob(torch.tensor(i,device=device))))) # \n",
        "display(v.detach()) # 状態価値を表示\n",
        "display(model) # モデルを表示"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n",
            "tensor(2)\n",
            "tensor(3)\n",
            "tensor(2)\n",
            "tensor(3)\n",
            "tensor(0)\n",
            "tensor(1)\n",
            "tensor(0)\n",
            "tensor(1)\n",
            "tensor(0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1, 16, 84, 84)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "初期は確率がほぼ等確率になっていることを確認\n",
            "0 tensor([0.2552], grad_fn=<PowBackward1>)\n",
            "1 tensor([0.2456], grad_fn=<PowBackward1>)\n",
            "2 tensor([0.2510], grad_fn=<PowBackward1>)\n",
            "3 tensor([0.2483], grad_fn=<PowBackward1>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([-0.0280])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(16, 64, kernel_size=(8, 8), stride=(4, 4))\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (lin): Linear(in_features=3136, out_features=256, bias=True)\n",
              "  (pi_logits): Linear(in_features=256, out_features=4, bias=True)\n",
              "  (value): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvKriYliARb"
      },
      "source": [
        "# Multiprocessing Playloop\n",
        "# 学習のメインプログラム\n",
        "### 並列ゲームプレイヤのクラス定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghC4pGrBiARh"
      },
      "source": [
        "def playloop(agent: multiprocessing.connection.Connection,seed:int,k=8,skip=2,noop_max=30, mode = 0):\n",
        "\n",
        "    # create game\n",
        "    game = Game(seed=seed, k=k,skip=skip,noop_max=noop_max, mode = mode)\n",
        "    # AI player \n",
        "    while True:\n",
        "        cmd, action = agent.recv()\n",
        "        if cmd == \"step\":\n",
        "            agent.send(game.step(action))\n",
        "        elif cmd == \"reset\":\n",
        "            agent.send(game.reset())\n",
        "        elif cmd == \"close\":\n",
        "            agent.close()\n",
        "            break\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "class CoPlayer:\n",
        "    def __init__(self, seed, k=8,skip=2,noop_max=30,mode = 0):\n",
        "        self.child, parent = multiprocessing.Pipe()\n",
        "        self.process = multiprocessing.Process(target=playloop, args=(parent, seed, k,skip,noop_max,mode))\n",
        "        self.process.start()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQr3RqvxEoHA"
      },
      "source": [
        "### パイプ動作確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv7YYQpo6HGy",
        "outputId": "79329f9e-6930-4f36-9461-ff5cab94e79b"
      },
      "source": [
        "cop2 = CoPlayer(0,8)\n",
        "cop2.child.send((\"reset\",None))\n",
        "a = cop2.child.recv()\n",
        "cop2.child.send((\"step\",1))\n",
        "a2,b,c,d = cop2.child.recv()\n",
        "cop2.child.send((\"close\",None))\n",
        "a.shape,a2.shape,b,c,d"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 8, 84, 84), (1, 8, 84, 84), 0.0, False, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLo5NlOfLFDJ"
      },
      "source": [
        "### ログフォルダの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSlfu2Xn7b9"
      },
      "source": [
        "import os\n",
        "SAVEFOLDER = '/content/drive/MyDrive/M/ppo'\n",
        "os.makedirs(SAVEFOLDER,exist_ok=True)\n",
        "modelPath = SAVEFOLDER+\"/model\"  # モデルの重みファイル名  (拡張子　.pt　が自動的に補われる）"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PrMOErZeo8U"
      },
      "source": [
        "#### ハイパーパラメータの（一部）\r\n",
        "ハイパーパラメータのうち、ネットワークに関するものは上に、一部は Main のパラメータに、一部は関数定義に埋め込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4FcgTbTkBBd"
      },
      "source": [
        "NCYCLES = 2000 # 学習サイクル数　（データ収集→学習　が1サイクル）\n",
        "\n",
        "END_GREEDY_Progress = 0.0 # 0.8  付加的な擾乱期間　開始から全体の 0.8\n",
        "GreedyEPS_START = 0.0 # 0.3 擾乱期間開始時の付加的擾乱\n",
        "GreedyEPS_END = 0.0 # 0.1 擾乱期間終了後の付加的擾乱\n",
        "\n",
        "END_LOSTLIFE_Penalty_Progress = 1.0 # 1.0  初期の仮ペナルティ適用期間　開始から終了までの期間に対する割合\n",
        "\n",
        "# Hyper Parameters\n",
        "GAMMA = 0.99 # 0.93\n",
        "LAMDA = 0.95 # 0.906\n",
        "EPOCHS =  4 # サンプル１セットを何度学習プロセスに通すか\n",
        "NPLAYERS = 8 # 並列実行する数game\n",
        "NBATCHES = 256 # １度に処理するデータ数\n",
        "NDIVIDE = 4 # バッチの分割数\n",
        "SEEDZero = random.randint(1,10000)\n",
        "LearningRate = 0.0015\n",
        "NFRAMES = 6\n",
        "W_VFLOSS = 0.6 # loss におけるvfloss の重み\n",
        "W_BONUS = 0.005 # loss における entropy bonus の重み　0.088\n",
        "CLIPRANGE = 0.2 # ## Run it"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrWOt3NiARi"
      },
      "source": [
        "class Main:\n",
        "    # mode 0 ：ライフが失われたらリセット、 mode 1：ライフが残っている場合は、画面を継続\n",
        "    def __init__(self,seed=SEEDZero,k=NFRAMES,skip=2,deadloss=38,noop_max=16,resume=False,ncycles=NCYCLES,mode = 0, lr=LearningRate,cr = CLIPRANGE, gamma=GAMMA,lamda=LAMDA,eb = W_BONUS):\n",
        "\n",
        "        self.lr = lr\n",
        "        self.cr = cr\n",
        "        self.gamma = gamma\n",
        "        self.lamda = lamda\n",
        "        self.eb = eb\n",
        "        self.k = k\n",
        "        self.ncycles = ncycles\n",
        "\n",
        "        self.lifes = 0 # 失った機体数 lost lifes\n",
        "        self.cycles = 0 # バッチ回数\n",
        "        self.deadloss = deadloss\n",
        "        self.mode = mode\n",
        "\n",
        "        self.progress = 0\n",
        "        \n",
        "        # 1サイクルに必要なサンプル数\n",
        "        self.batch_size = NPLAYERS * NBATCHES\n",
        "        # ミニバッチのサイズ\n",
        "        self.mini_batch_size = self.batch_size // NDIVIDE\n",
        "\n",
        "        # 初期化  \n",
        "        # CoPlayerの生成\n",
        "        self.coplayers = [CoPlayer(seed + i,k,skip,noop_max,mode) for i in range(NPLAYERS)]\n",
        "\n",
        "        # 観測情報の初期化　この部分を float や tensor にすると k が４に制限されてしまうので int で\n",
        "        self.obs = np.zeros((NPLAYERS, k, 84, 84), dtype=np.uint8)\n",
        "        for player in self.coplayers:\n",
        "            player.child.send((\"reset\", None))\n",
        "        for i, player in enumerate(self.coplayers):\n",
        "            self.obs[i] = player.child.recv()\n",
        "\n",
        "        # model for sampling\n",
        "        self.model = model = Model(k).to(device)\n",
        "        if resume: # 学習済み重みがある場合\n",
        "          shutil.copy( modelPath+'.pt', modelPath+'.bak.pt')\n",
        "          if torch.cuda.is_available():\n",
        "            self.model.load_state_dict(torch.load(modelPath+'.pt'))\n",
        "          else: #  gpu ありを前提としているが、cpu で続きを計算したい場合\n",
        "            self.model.load_state_dict(torch.load(modelPath+'.pt', map_location=torch.device('cpu')))\n",
        "\n",
        "        # optimizer\n",
        "        # lr = LearningRate\n",
        "        optimizers = {}\n",
        "        # optimizers['SGD'] = optim.SGD(model.parameters(), lr)\n",
        "        # optimizers['Adagrad'] = optim.Adagrad(model.parameters(), lr)\n",
        "        # optimizers['RMSprop'] = optim.RMSprop(model.parameters(), lr)\n",
        "        # optimizers['Adadelta'] = optim.Adadelta(model.parameters(), lr)\n",
        "        # optimizers['Adam'] = optim.Adam(model.parameters(), lr)\n",
        "        optimizers['AdamW'] = optim.AdamW(model.parameters(), lr)\n",
        "        self.optimizer = optimizers['AdamW']\n",
        "\n",
        "    @staticmethod\n",
        "    def _toTT(obs: np.ndarray) -> torch.Tensor:\n",
        "        return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize(adv: torch.Tensor):\n",
        "        return (adv - adv.mean()) / (adv.std() + 1e-8)\n",
        "\n",
        "    def sample(self) -> (Dict[str, torch.Tensor], List):\n",
        "        # 学習データの記憶域確保\n",
        "        rewards = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        actions = np.zeros((NPLAYERS, NBATCHES), dtype=np.int32)\n",
        "        done = np.zeros((NPLAYERS, NBATCHES), dtype=np.bool)\n",
        "        obs = np.zeros((NPLAYERS, NBATCHES, self.k, 84, 84), dtype=np.float32)\n",
        "        log_pis = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        values = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        \n",
        "        # 画像データの初期化\n",
        "        for t in progress_bar(range(NBATCHES), parent=self.mpbar):\n",
        "            with torch.no_grad(): # 傾きを固定して実行\n",
        "                obs[:, t] = self.obs\n",
        "                pi, v = self.model(self._toTT(self.obs))\n",
        "                values[:, t] = v.cpu().numpy()\n",
        "                a0 = pi.sample()\n",
        "                \n",
        "                # epsiron greedy action selection\n",
        "                if self.progress >= END_GREEDY_Progress:\n",
        "                    g_eps = GreedyEPS_END\n",
        "                else:\n",
        "                    g_eps = GreedyEPS_START + self.progress * (END_GREEDY_Progress- GreedyEPS_START)/END_GREEDY_Progress\n",
        "                for i in range(NPLAYERS):\n",
        "                    if torch.rand(1) <= g_eps: \n",
        "                        a0[i] = torch.randint(0,4,(1,))\n",
        "                a =a0.cpu().numpy()\n",
        "                actions[:, t] = a\n",
        "                log_pis[:, t] = pi.log_prob(a0).cpu().numpy()\n",
        "                \n",
        "            for w, player in enumerate(self.coplayers):\n",
        "                player.child.send((\"step\", actions[w, t]))\n",
        " \n",
        "            for w, player in enumerate(self.coplayers):\n",
        "                self.obs[w], rewards[w, t], done[w, t], info  =  player.child.recv()\n",
        "\n",
        "                if info : # info \n",
        "                    if self.progress >= END_LOSTLIFE_Penalty_Progress:\n",
        "                       dlrate = 0\n",
        "                    else:\n",
        "                       dlrate = 1 - self.progress/END_LOSTLIFE_Penalty_Progress \n",
        "                    rewards[w, t] -=  dlrate * self.deadloss\n",
        "                    self.lifes += 1\n",
        "                    wandb.log({'reward':info['reward'],'lengt':info['length']})\n",
        "                    wandb.log({'lifes':self.lifes,'cycles':self.cycles})\n",
        "             \n",
        "        # calculate advantages\n",
        "        advantages = self._calc_advantages(done, rewards, values)\n",
        "        samples = {\n",
        "            'obs': obs,\n",
        "            'actions': actions,\n",
        "            'values': values,\n",
        "            'log_pis': log_pis,\n",
        "            'advantages': advantages\n",
        "        }\n",
        "\n",
        "        samples_flat = {}\n",
        "        for k, v in samples.items():\n",
        "            v = v.reshape(v.shape[0] * v.shape[1], *v.shape[2:])\n",
        "            if k == 'obs':\n",
        "                samples_flat[k] = self._toTT(v)\n",
        "            else:\n",
        "                samples_flat[k] = torch.tensor(v, device=device)\n",
        "        return samples_flat, rewards[rewards>0].mean()\n",
        "\n",
        "    def _calc_advantages(self, done: np.ndarray, rewards: np.ndarray, values: torch.Tensor) -> np.ndarray:\n",
        "        advantages = np.zeros((NPLAYERS, NBATCHES), dtype=np.float32)\n",
        "        last_advantage = 0\n",
        "        _, last_value = self.model(self._toTT(self.obs))\n",
        "        last_value = last_value.cpu().data.numpy()\n",
        "\n",
        "        for t in reversed(range(NBATCHES)):\n",
        "            mask = 1 - done[:, t]\n",
        "            last_value = last_value * mask\n",
        "            last_advantage = last_advantage * mask\n",
        "            #delta = rewards[:, t] + GAMMA * last_value - values[:, t]\n",
        "            #last_advantage = delta + GAMMA * LAMDA * last_advantage\n",
        "            delta = rewards[:, t] + self.gamma * last_value - values[:, t]\n",
        "            last_advantage = delta + self.gamma * self.lamda * last_advantage\n",
        "            advantages[:, t] = last_advantage\n",
        "            last_value = values[:, t]\n",
        "\n",
        "        return advantages\n",
        "    \n",
        "    # 1サイクルの学習\n",
        "    def train(self, samples: Dict[str, torch.Tensor], learning_rate: float, clip_range: float):\n",
        "\n",
        "        for _ in range(EPOCHS):\n",
        "            # 並べ替え用の数列\n",
        "            indexes = torch.randperm(self.batch_size)\n",
        "\n",
        "            # ミニバッチ単位で処理\n",
        "            for start in range(0, self.batch_size, self.mini_batch_size):\n",
        "                # get mini batch\n",
        "                end = start + self.mini_batch_size\n",
        "                mini_batch_indexes = indexes[start: end]\n",
        "                mini_batch = {}\n",
        "                for k, v in samples.items():\n",
        "                    mini_batch[k] = v[mini_batch_indexes]\n",
        "\n",
        "                # train\n",
        "                loss = self._calc_loss(clip_range=clip_range,\n",
        "                                       samples=mini_batch)\n",
        "\n",
        "                # compute gradients\n",
        "                for pg in self.optimizer.param_groups:\n",
        "                    pg['lr'] = learning_rate\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5)\n",
        "                self.optimizer.step()\n",
        "\n",
        "    def _calc_loss(self, samples: Dict[str, torch.Tensor], clip_range: float) -> torch.Tensor:\n",
        "        sampled_return = samples['values'] + samples['advantages']\n",
        "        sampled_normalized_advantage = self._normalize(samples['advantages'])\n",
        "        pi, value = self.model(samples['obs'])\n",
        "\n",
        "        # #### Policy\n",
        "        log_pi = pi.log_prob(samples['actions'])\n",
        "\n",
        "        ratio = torch.exp(log_pi - samples['log_pis'])\n",
        "\n",
        "        clipped_ratio = ratio.clamp(min=1.0 - clip_range,\n",
        "                                    max=1.0 + clip_range)\n",
        "        policy_reward = torch.min(ratio * sampled_normalized_advantage,\n",
        "                                  clipped_ratio * sampled_normalized_advantage)\n",
        "        policy_reward = policy_reward.mean()\n",
        "\n",
        "        # #### Entropy Bonus\n",
        "        entropy_bonus = pi.entropy()\n",
        "        entropy_bonus = entropy_bonus.mean()\n",
        "\n",
        "        # #### Value\n",
        "        clipped_value = samples['values'] + (value - samples['values']).clamp(min=-clip_range,\n",
        "                                                                              max=clip_range)\n",
        "        vf_loss = torch.max((value - sampled_return) ** 2, (clipped_value - sampled_return) ** 2)\n",
        "        vf_loss = 0.5 * vf_loss.mean()\n",
        "        loss = -(policy_reward - W_VFLOSS* vf_loss + self.eb * entropy_bonus)\n",
        "\n",
        "        # for monitoring\n",
        "        approx_kl_divergence = .5 * ((samples['log_pis'] - log_pi) ** 2).mean()\n",
        "        clip_fraction = (abs((ratio - 1.0)) > clip_range).to(torch.float).mean()\n",
        "        \n",
        "        wandb.log({'policy_reward': policy_reward,\n",
        "                     'vf_loss': vf_loss,\n",
        "                     'entropy_bonus': entropy_bonus,\n",
        "                     'kl_div': approx_kl_divergence,\n",
        "                     'clip_fraction': clip_fraction})        \n",
        "        return loss\n",
        "\n",
        "    def run_training_loop(self):\n",
        "\n",
        "        ### Run training loop\n",
        "        self.mpbar = master_bar(range(self.ncycles))\n",
        "        for cycle in self.mpbar:\n",
        "            self.cycles = cycle \n",
        "            self.progress = progress = cycle / self.ncycles\n",
        "\n",
        "            # decreasing `learning_rate` and `clip_range` \n",
        "            #learning_rate = LearningRate * (1 - progress)\n",
        "            learning_rate = self.lr * (1 - 0.5*progress)\n",
        "            clip_range = self.cr * (1 - 0.5*progress)\n",
        "            samples,mrewards = self.sample()\n",
        "            # train the model\n",
        "            self.train(samples, learning_rate, clip_range)\n",
        "\n",
        "            # write summary info to the writer, and log to the screen\n",
        "            if (cycle + 1) % 10 == 0:\n",
        "                #torch.save(self.model.state_dict(),modelPath+'.pt' )SAVEFOLDER+\"/model\"\n",
        "                torch.save(self.model.state_dict(),SAVEFOLDER+\"/model\"+'.pt' )\n",
        "            if (cycle + 1) % 250 == 0:\n",
        "                torch.save(self.model.state_dict(),SAVEFOLDER+\"/model\"+'{}'.format(cycle+2001)+'.pt')\n",
        "        torch.save(self.model.state_dict(),modelPath+'.pt')\n",
        "        return mrewards\n",
        "\n",
        "    def destroy(self):\n",
        "\n",
        "        for player in self.coplayers:\n",
        "            player.child.send((\"close\", None))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywW3eB4vLOa0"
      },
      "source": [
        "## W and B\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "JmoHAp4qiAQ3",
        "scrolled": true,
        "outputId": "38140eb5-b193-46b7-b2b9-eec2b30ffbd2"
      },
      "source": [
        "# Inside my model training code \n",
        "!export WANDB_NOTEBOOK_NAME=\"PPO.ipynb\"\n",
        "import wandb\n",
        "PROJECTNAME='PPO'\n",
        "wandb.init(project=PROJECTNAME)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maquapathos\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.12<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lemon-sky-83</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/aquapathos/PPO\" target=\"_blank\">https://wandb.ai/aquapathos/PPO</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/aquapathos/PPO/runs/175yll7b\" target=\"_blank\">https://wandb.ai/aquapathos/PPO/runs/175yll7b</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210101_115841-175yll7b</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f87d38d7cf8>"
            ],
            "text/html": [
              "<h1>Run(175yll7b)</h1><p></p><iframe src=\"https://wandb.ai/aquapathos/PPO/runs/175yll7b\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_-yArl4PRu"
      },
      "source": [
        "# 学習１ターン目  mode 0, dedloss ありで\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=50,noop_max=16,resume=False,ncycles=NCYCLES,mode=0)\n",
        "m.run_training_loop()\n",
        "m.destroy()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0jrraj4giX4"
      },
      "source": [
        "# 学習2ターン目  mode 0, dedloss ありで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "LearningRate /= 2\r\n",
        "CLIPRANGE /= 2\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=0,lr=LearningRate,cr=CLIPRANGE)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aoJrrKsppIq"
      },
      "source": [
        "# 学習2ターン目  mode 0, dedloss ありで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "LearningRate /= 2\r\n",
        "CLIPRANGE /= 2\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=0,lr=LearningRate,cr=CLIPRANGE)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv2x8qlWsPLb"
      },
      "source": [
        "# 学習3ターン目  mode 0, dedloss ありで\r\n",
        "# 初期のペナルティを deadloss とし、徐々に下げて終了時は０とする。　続きの場合は resume = True\r\n",
        "LearningRate /= 2\r\n",
        "CLIPRANGE /= 2\r\n",
        "m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=True,ncycles=NCYCLES,mode=0,lr=LearningRate,cr=CLIPRANGE)\r\n",
        "m.run_training_loop()\r\n",
        "m.destroy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEtsOWy83j5W"
      },
      "source": [
        "![rewards](https://user-images.githubusercontent.com/5820803/103320826-404a2a80-4a7a-11eb-9bb6-9dd04cef52d0.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Upl2kkiARk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a368ac6d-5a71-4961-a495-054bcec220d1"
      },
      "source": [
        "# torch.save(model.state_dict(),'ppomodel')\n",
        "# model.load_state_dict(torch.load('ppomodel'))\n",
        "# torch.save(model.state_dict(),'ppomodel{}'.format(100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `https://user-images.githubusercontent.com/5820803/103320826-404a2a80-4a7a-11eb-9bb6-9dd04cef52d0.png'\n",
            "/bin/bash: -c: line 0: `[rewards](https://user-images.githubusercontent.com/5820803/103320826-404a2a80-4a7a-11eb-9bb6-9dd04cef52d0.png)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwx6KcNdA12"
      },
      "source": [
        "# [Optuna](https://optuna.org/)\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPP6e08dOYI"
      },
      "source": [
        "!pip install optuna > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNoP7bO0dANJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "dca7b01d-53b5-4836-b558-7b2a1dfca6eb"
      },
      "source": [
        "import optuna\r\n",
        "\r\n",
        "def objective(trial):\r\n",
        "    # Categorical parameter\r\n",
        "    # optimizer = trial.suggest_categorical('k', [2,4,6,8,10,14,16])\r\n",
        "\r\n",
        "    # Int parameter\r\n",
        "    # num_layers = trial.suggest_int('deladloss', 1, 51)\r\n",
        "\r\n",
        "    # Loguniform parameter\r\n",
        "    # gamma = trial.suggest_loguniform('gamma', 0.90, 0.97)\r\n",
        "    eb = trial.suggest_loguniform('eb',0.006,0.1)\r\n",
        "\r\n",
        "    m = Main(SEEDZero,k=NFRAMES,skip=2,deadloss=0,noop_max=16,resume=False,lr=0.0015,eb=eb)\r\n",
        "    mrewards = m.run_training_loop()\r\n",
        "    m.destroy()\r\n",
        "\r\n",
        "    return -mrewards\r\n",
        "\r\n",
        "study = optuna.create_study()\r\n",
        "study.optimize(objective, n_trials=10)\r\n",
        "study.best_params  # "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:12:37,595]\u001b[0m A new study created in memory with name: no-name-944a7419-505a-45cd-85d9-47787ba97ef2\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:20:01,548]\u001b[0m Trial 0 finished with value: -22.70833396911621 and parameters: {'eb': 0.009226583067767354}. Best is trial 0 with value: -22.70833396911621.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:27:25,885]\u001b[0m Trial 1 finished with value: -13.214285850524902 and parameters: {'eb': 0.02505062922916771}. Best is trial 0 with value: -22.70833396911621.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:34:49,843]\u001b[0m Trial 2 finished with value: -13.69565200805664 and parameters: {'eb': 0.008589591819676763}. Best is trial 0 with value: -22.70833396911621.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:42:15,990]\u001b[0m Trial 3 finished with value: -25.625 and parameters: {'eb': 0.0877108482599416}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:49:39,463]\u001b[0m Trial 4 finished with value: -10.384614944458008 and parameters: {'eb': 0.00732262468678601}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 13:57:05,027]\u001b[0m Trial 5 finished with value: -12.741935729980469 and parameters: {'eb': 0.007252702219857107}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:04:29,513]\u001b[0m Trial 6 finished with value: -12.5 and parameters: {'eb': 0.015636227168278966}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:11:53,689]\u001b[0m Trial 7 finished with value: -11.25 and parameters: {'eb': 0.008056487110270742}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:19:20,786]\u001b[0m Trial 8 finished with value: -9.615385055541992 and parameters: {'eb': 0.030985104016693958}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-29 14:26:45,818]\u001b[0m Trial 9 finished with value: -12.291666984558105 and parameters: {'eb': 0.03374553985680278}. Best is trial 3 with value: -25.625.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eb': 0.0877108482599416}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFxQSkkh9nlQ"
      },
      "source": [
        "# Demoモード\r\n",
        "\r\n",
        "Colab では表示できません"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50QeBOYDgwWj"
      },
      "source": [
        "random.seed(datetime.now())\r\n",
        "DEFAULTSEED = random.randint(1, 10000)\r\n",
        "import time\r\n",
        "\r\n",
        "model = Model(NFRAMES).to(device)\r\n",
        "model.load_state_dict(torch.load(SAVEFOLDER+\"/model\" ))\r\n",
        "game = Game(seed=DEFAULTSEED, k=NFRAMES,skip=2,noop_max=0,demo=True)\r\n",
        "\r\n",
        "def _toTT(obs: np.ndarray) -> torch.Tensor:\r\n",
        "    return torch.tensor(obs, dtype=torch.float32, device=device) / 255.0    \r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    print(i,end='')\r\n",
        "    observation = game.reset()  \r\n",
        "    while True:\r\n",
        "        time.sleep(0.02)\r\n",
        "        game.render()\r\n",
        "        pi, v = model(_toTT(observation))\r\n",
        "        action = pi.sample().cpu().numpy()[0] # 方策関数によりアクションを決定\r\n",
        "        observation, reward, done, info = game.step(action) \r\n",
        "        if done: \r\n",
        "          break;\r\n",
        "        \r\n",
        "game.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq_ns9qe51Dd"
      },
      "source": [
        "!mv model.pt /content/drive/MyDrive/M/ppo"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTHbhmTRz9IK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}