{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ATARI",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPulyslYdRlZgA6MSmvkMPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/MLLesson/blob/master/ATARI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6LyDjpW_l1C"
      },
      "source": [
        "# 準備\n",
        "- [pfrl](https://github.com/pfnet/pfrl)　[(GitHub)](https://github.com/pfnet/pfrl)\n",
        "\n",
        "[atari wrapper](https://github.com/pfnet/pfrl/blob/master/pfrl/wrappers/atari_wrappers.py)を使うために導入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBuz0JVs_kui",
        "outputId": "cf51ff4d-d2bb-4e55-c3ea-f9953be9b872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!apt-get update && apt-get install -qq  xvfb   < /dev/null > /dev/null\n",
        "!pip install pfrl > /dev/null\n",
        "!pip install gym-notebook-wrapper > /dev/null"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Co\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Co\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 43.1 kB/88.7 k\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [3 InRelease 43.1 kB/88.7 k\r                                                                               \r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,162 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,114 kB]\n",
            "Fetched 4,528 kB in 2s (2,079 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJc3fQQYXe3U"
      },
      "source": [
        "# 注意　\n",
        "ENV_NAMEとしては、名前に **NoFrameskip** を含むものを選ぶこと\n",
        "\n",
        "- [OpenAI Gym の Atari Environment の命名規則と罠について](https://qiita.com/keisuke-nakata/items/141fc53f419b102d942c)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvtNhCWSIUEs",
        "outputId": "8c910c18-cd5f-4957-c280-cb47d82c7f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "ENV_NAME = 'BreakoutNoFrameskip-v0'\n",
        "env=make_atari(ENV_NAME)\n",
        "frame0 = env.reset()\n",
        "cv2_imshow(frame0[:,:,::-1])\n",
        "print(frame0.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACu0lEQVR4nO3dsW0TYRiA4QS5RkxARcEIEQNYLpjGEzCBx0AMQGGloEQZBlEgRJEiygL+IZZ9d/bL85Sn090vvfl8v+SzcnMDAMDZ3c55s91u989zttvtbOcfa+rrj+51yjVfnWMxXK7VUjeec1Jfcv6xzjWpUzPBcYtN8LUbfSpc2mSb4DgTfITRdE7xjD8XExy32AQf+1c/9flLXXNqJhjgYt1e43OFl/MMjhM4TuA4geMEjhM4TuA4geMEjhM4TuA4geMEjhM4bvjKzqW9/snfjb72NcFxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3PDF94fNZs51cKLvg+MmOE7gOIHjBI4TOG64i35692vOdTARExwncJzAcQLHCRw33EX/fP1nznUwERMcJ3CcwHECxwkcN95Fv3+ccx2c6sfhwyY4TuA4geMEjhM4briL/vz0ds51cKL14LgJjhM4TuA4geMEjhvuoh+/fJpxGZxsffj3hSY4TuA4geMEjhM4briL/ra/m3MdnOjj2j+n/C8JHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3Orrm99Lr+E6PGw2R51/t99PtJKDPtzfHzxuguMEjhM4brX0Aq7GzM/UczHBcSY44ko/YAAAAAAAAFjUMyEkRxlHStXAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=160x210 at 0x7F33CCE32C50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(210, 160, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPJUfRAZY7XY"
      },
      "source": [
        "env=make_atari('BreakoutNoFrameskip-v0')　で (210,160,3) 形式の観測データが得られることがわかる。\n",
        "\n",
        "なお、make_atari は4フレームおきに画像を取得する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "378p6xMpMZZS",
        "outputId": "abdccb3b-eca2-4954-f63b-613201ddd60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "ENV_NAME = 'BreakoutNoFrameskip-v0'\n",
        "env=make_atari(ENV_NAME)\n",
        "env = wrap_deepmind(env)\n",
        "canvas = np.zeros((84,4*84))\n",
        "for i in range(4):\n",
        "  canvas[:,84*i:84*i+84] = np.transpose(env.reset(),(0,1,2))[i]\n",
        "cv2_imshow(canvas)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAABUCAAAAADxZTCnAAACMklEQVR4nO2dT2oTcRiGn0l/WiE4YEElUk8QcOMq4ErEnKAn6A1ygpwgtygInqDoviC4EvECAyUFicTG0rSkLjoTKwkpE1+w5Huf1Udm5pnhmQz5T8CYu0y2eFPep6C1NSj226NJnh+9b+9PTxrP6M3X6HYnIxge3Nhor3N4uGI3cZxpqXdAPwf4eNTtApwM8v5fKww/w+mKA4vrXB70Fr6OofWq+LLOtpvuXB60RxOAN50cgCe9xs3FzzvwoO6RBHFmu3V3aFaSDf73EWwYjdtXMXVwUDEOKsZBxSSA4YXMd+9pOUR1JoCDQibdrV6kRXX6khfjoGIcVIyDinFQMQ4qxkHFOKiYBLAzlfl25kNQZwJ4q5Per4aoTl/yYhLAw0utL7IzAWzJnH9UUZ3XZ2rJ1x3+maDOBJDppHNTVKcflMQkgFx3lq6qN8CjOn0PFZMATq9kvmy7HKI6E8C58LlYdaBRnddBhZ/8VUNUZwI4nsikzcflENXpByUxCeDTsczXelEOUZ0JYDySSZvVENXpS16Mg4pxUDEOKsZBxTioGAcV46BiHFSMg4pxUDEOKsZBxTioGAcV46BiHFSMg4pxUDEOKsZBxTioGAcV46BiHFSMg4pxUDEOKsZBxTioGAcV46BiHFSMg4pxUDEOKiZNgZq/zsva5VD8WFg2+wlsB3amM2BWT9p4XQ4fFqWX34FHgZ3r/DHA7F05jNfYeNOd2Uvg2y/dHgEiO40xxpg7w2+CGAln6NBnYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=336x84 at 0x7F33CC7F0128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH2-ItnCtI6L",
        "outputId": "264ec6a7-c5ec-4307-fce5-a2c582ddbb49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "env.action_space.n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Yn2QkVhVZQ"
      },
      "source": [
        "make_atari した env を wrap_deepmind() に通すことで、\n",
        "- グレイ変換\n",
        "- 84x84 にリサイズ\n",
        "- ４ステップ分（4フレームごとに取り出したフレームを４つ）をひとまとめにして、\n",
        "4チャネル×84×84というサイズのでータを観測データとして出力\n",
        "\n",
        "してくれる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mvC62qZNoZS"
      },
      "source": [
        "import pfrl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import gym\n",
        "import numpy\n",
        "from pfrl import nn as pnn\n",
        "from pfrl.initializers import init_chainer_default"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPV_CtjbRQpq",
        "outputId": "169bc719-335e-46ac-8b01-f66273069758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "ENV_NAME = 'BreakoutNoFrameskip-v0'\n",
        "\n",
        "env=make_atari(ENV_NAME,max_frames = None)\n",
        "print('observation space:', env.observation_space)\n",
        "env.seed(np.random.seed())\n",
        "env = wrap_deepmind(env,episode_life=False,\n",
        "            clip_rewards=True,\n",
        "            scale = True,\n",
        "            flicker=False,\n",
        "            frame_stack=True,)\n",
        "\n",
        "print('observation space:', env.observation_space)\n",
        "print('action space:', env.action_space)\n",
        "obs = env.reset()\n",
        "action = env.action_space.sample()\n",
        "obs, r, done, info = env.step(action)\n",
        "n_actions = env.action_space.n\n",
        "print('next observation:', obs)\n",
        "print('reward:', r)\n",
        "print('done:', done)\n",
        "print('info:', info)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "observation space: Box(210, 160, 3)\n",
            "observation space: Box(4, 84, 84)\n",
            "action space: Discrete(4)\n",
            "next observation: <pfrl.wrappers.atari_wrappers.LazyFrames object at 0x7f33cc7f0080>\n",
            "reward: 0.0\n",
            "done: False\n",
            "info: {'ale.lives': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwwlVQp-kvI4"
      },
      "source": [
        "# DoubleDQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dnEZ8PTRTdG"
      },
      "source": [
        "\n",
        "func = nn.Sequential(\n",
        "    nn.Conv2d(4,32,8,4),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(32,64,4,2),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(64,64,3,1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.Flatten(),    \n",
        "    nn.Linear(7 * 7 * 64, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, n_actions),\n",
        "    pfrl.q_functions.DiscreteActionValueHead(),\n",
        ")\n",
        "\n",
        "func_S=nn.Sequential(\n",
        "    nn.Conv2d(4,16,8,4),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16,32,4,2),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    nn.Flatten(),    \n",
        "    nn.Linear(32*9*9, n_actions),\n",
        "    pfrl.q_functions.DiscreteActionValueHead(),\n",
        ")\n",
        "\n",
        "# オプティマイザー\n",
        "optimizer_A = torch.optim.Adam(func.parameters(), eps=1e-2)\n",
        "\n",
        "optimizer_R = pfrl.optimizers.RMSpropEpsInsideSqrt(\n",
        "        func.parameters(),\n",
        "        lr=0.01,\n",
        "        alpha=0.95,\n",
        "        momentum=0.0,\n",
        "        eps=1e-2,\n",
        "        centered=True,\n",
        "    )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lnn4e_mSlBg"
      },
      "source": [
        "gamma = 0.9\n",
        "replay_buffer_size = 10 ** 3\n",
        "gpu = 0  # 0番のGPU   -1 gpu を使わない\n",
        "\n",
        "constantepsiron = 0.3 # .ConstantEpsilonGreedy用\n",
        "final_epsilon = 0.1 # LinearDecayEpsilonGreedy用\n",
        "final_exploration_frames = 1e5  # 100000 ε=0.1になるまでのステップ数\n",
        "\n",
        "explorer1 = pfrl.explorers.ConstantEpsilonGreedy(\n",
        "    epsilon=constantepsiron, random_action_func=env.action_space.sample)\n",
        "replay_buffer = pfrl.replay_buffers.ReplayBuffer(capacity=replay_buffer_size)\n",
        "\n",
        "explorer2 = pfrl.explorers.LinearDecayEpsilonGreedy(\n",
        "            start_epsilon = 1.0, \n",
        "            end_epsilon = final_epsilon,\n",
        "            decay_steps = final_exploration_frames,\n",
        "            random_action_func = lambda: np.random.randint(n_actions))\n",
        "\n",
        "def phi(x):\n",
        "    return np.asarray(np.array(x), dtype=np.float32) \n",
        "\n",
        "agent = pfrl.agents.DoubleDQN(\n",
        "    func_S,\n",
        "    optimizer_R,\n",
        "    replay_buffer,\n",
        "    gamma,\n",
        "    explorer = explorer2,\n",
        "    replay_start_size=500,\n",
        "    update_interval=1,\n",
        "    target_update_interval=100,\n",
        "    phi=phi,\n",
        "    gpu=gpu,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ2Flhwi4Js0"
      },
      "source": [
        "# 学習の実行\n",
        "1エピソード当たりの最高ステップ数を1000として、300エピソード学習させてみる\n",
        "\n",
        "まず、func_S と optimizer_R の組み合わせで試す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_m91xWXLGv",
        "outputId": "59defcfd-2f38-4f99-cc20-8e4297b16357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "source": [
        "%time\n",
        "n_episodes = 300\n",
        "max_episode_len = 1000\n",
        "for i in range(1, n_episodes + 1):\n",
        "    obs = env.reset()\n",
        "    R = 0  # return (sum of rewards)\n",
        "    t = 0  # time step\n",
        "    while True:\n",
        "        # Uncomment to watch the behavior in a GUI window\n",
        "        # env.render()\n",
        "        action = agent.act(obs)\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        R += reward\n",
        "        t += 1\n",
        "        reset = t == max_episode_len\n",
        "        agent.observe(obs, reward, done, reset)\n",
        "        if done or reset:\n",
        "            break\n",
        "    if i % 10 == 0:\n",
        "        print('episode:', i, 'R:', R)\n",
        "    if i % 50 == 0:\n",
        "        print('statistics:', agent.get_statistics())\n",
        "print('Finished.')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
            "Wall time: 5.01 µs\n",
            "episode: 10 R: 0.0\n",
            "episode: 20 R: 1.0\n",
            "episode: 30 R: 2.0\n",
            "episode: 40 R: 0.0\n",
            "episode: 50 R: 0.0\n",
            "statistics: [('average_q', 0.2491998), ('average_loss', 0.033368001002818344), ('cumulative_steps', 72859), ('n_updates', 72360), ('rlen', 1000)]\n",
            "episode: 60 R: 3.0\n",
            "episode: 70 R: 1.0\n",
            "episode: 80 R: 5.0\n",
            "episode: 90 R: 5.0\n",
            "episode: 100 R: 0.0\n",
            "statistics: [('average_q', 0.28363454), ('average_loss', 0.032040671207942066), ('cumulative_steps', 84291), ('n_updates', 83792), ('rlen', 1000)]\n",
            "episode: 110 R: 1.0\n",
            "episode: 120 R: 4.0\n",
            "episode: 130 R: 1.0\n",
            "episode: 140 R: 0.0\n",
            "episode: 150 R: 2.0\n",
            "statistics: [('average_q', 0.32046252), ('average_loss', 0.02005550486035645), ('cumulative_steps', 97193), ('n_updates', 96694), ('rlen', 1000)]\n",
            "episode: 160 R: 2.0\n",
            "episode: 170 R: 4.0\n",
            "episode: 180 R: 0.0\n",
            "episode: 190 R: 2.0\n",
            "episode: 200 R: 4.0\n",
            "statistics: [('average_q', 0.33060864), ('average_loss', 0.013072890529292636), ('cumulative_steps', 114332), ('n_updates', 113833), ('rlen', 1000)]\n",
            "episode: 210 R: 2.0\n",
            "episode: 220 R: 0.0\n",
            "episode: 230 R: 0.0\n",
            "episode: 240 R: 0.0\n",
            "episode: 250 R: 0.0\n",
            "statistics: [('average_q', 0.35180297), ('average_loss', 0.0073391731880838055), ('cumulative_steps', 131222), ('n_updates', 130723), ('rlen', 1000)]\n",
            "episode: 260 R: 1.0\n",
            "episode: 270 R: 4.0\n",
            "episode: 280 R: 0.0\n",
            "episode: 290 R: 4.0\n",
            "episode: 300 R: 4.0\n",
            "statistics: [('average_q', 0.3143906), ('average_loss', 0.01302896038920153), ('cumulative_steps', 150755), ('n_updates', 150256), ('rlen', 1000)]\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUxvMxtQ5HyV"
      },
      "source": [
        "# 評価モード\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdNP9QD9Drrc",
        "outputId": "5f49b2d0-92da-4534-bf04-cfe19d7195b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "with agent.eval_mode():\n",
        "    for i in range(10):\n",
        "        obs = env.reset()\n",
        "        R = 0\n",
        "        t = 0\n",
        "        while True:\n",
        "            # Uncomment to watch the behavior in a GUI window\n",
        "            # env.render()\n",
        "            action = agent.act(obs)\n",
        "            obs, r, done, _ = env.step(action)\n",
        "            R += r\n",
        "            t += 1\n",
        "            reset = t == max_episode_len\n",
        "            agent.observe(obs, r, done, reset)\n",
        "            if done or reset:\n",
        "                break\n",
        "        print('evaluation episode:', i, 'R:', R)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluation episode: 0 R: 0.0\n",
            "evaluation episode: 1 R: 0.0\n",
            "evaluation episode: 2 R: 0.0\n",
            "evaluation episode: 3 R: 0.0\n",
            "evaluation episode: 4 R: 0.0\n",
            "evaluation episode: 5 R: 0.0\n",
            "evaluation episode: 6 R: 0.0\n",
            "evaluation episode: 7 R: 0.0\n",
            "evaluation episode: 8 R: 0.0\n",
            "evaluation episode: 9 R: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMz3SosbFFvr"
      },
      "source": [
        "with agent.eval_mode():\n",
        "    for i in range(10):\n",
        "        obs = env.reset()\n",
        "        R = 0\n",
        "        t = 0\n",
        "        while True:\n",
        "            # Uncomment to watch the behavior in a GUI window\n",
        "            # env.render()\n",
        "            action = agent.act(obs)\n",
        "            obs, r, done, _ = env.step(action)\n",
        "            R += r\n",
        "            t += 1\n",
        "            reset = t == max_episode_len\n",
        "            agent.observe(obs, r, done, reset)\n",
        "            if done or reset:\n",
        "                break\n",
        "        print('evaluation episode:', i, 'R:', R)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K38JarLZFLLB",
        "outputId": "f9473cd4-1357-476e-f878-2d47a31b60ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "agent.save('/content/drive/My Drive/agent')\n",
        "\n",
        "# 読み出しは、\n",
        "# agent.load('/content/drive/My Drive/agent')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjaU9ZYtJZ_2"
      },
      "source": [
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
        "\n",
        "# 本番　func と optimizer_Aの組み合わせ\n",
        "agent_S = pfrl.agents.DoubleDQN(\n",
        "    func,\n",
        "    optimizer_A,\n",
        "    replay_buffer,\n",
        "    gamma,\n",
        "    explorer = explorer2,\n",
        "    replay_start_size=500,\n",
        "    update_interval=1,\n",
        "    target_update_interval=100,\n",
        "    phi=phi,\n",
        "    gpu=gpu,\n",
        ")\n",
        "\n",
        "pfrl.experiments.train_agent_with_evaluation(\n",
        "    agent,\n",
        "    env,\n",
        "    steps=2000,           # Train the agent for 2000 steps\n",
        "    eval_n_steps=None,       # We evaluate for episodes, not time\n",
        "    eval_n_episodes=10,       # 10 episodes are sampled for each evaluation\n",
        "    train_max_episode_len=200,  # Maximum length of each episode\n",
        "    eval_interval=1000,   # Evaluate the agent after every 1000 steps\n",
        "    outdir='/content/drive/My Drive/agent',      # Save everything to 'result' directory\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}