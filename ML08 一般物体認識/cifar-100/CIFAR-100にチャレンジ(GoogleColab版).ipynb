{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "CIFAR-100にチャレンジ(GoogleColab版).ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dgFhEWbx9eq",
        "colab_type": "text"
      },
      "source": [
        "# 準備\n",
        "## 準備1. Google Drive 上に入出力用フォルダを作成\n",
        "\n",
        "Google Drive を開き、  <font color='red' >**CIFAR100** </font>という名のフォルダを作りましょう。\n",
        "\n",
        "Google Colaboratory は一時的に貸し出された仮想マシン上でプログラムを実行します。作成したプログラムは自分の Google Drive の Colab Notebooks 上に保存されて残りますが、データファイルは消されてしまいます。\n",
        "\n",
        "もしデータファイルや実行結果を残しておきたければ、\n",
        "1. 消える前にローカルPCにダウンロードしておく\n",
        "2. Google Drive に保存しておく\n",
        "のどちらかです。\n",
        "\n",
        "このプログラムでは大きなデータファイルをダウンロードして使いますが、大学のPCにダウンロードするより Google のクラウドマシン上でダウンロードし、Google Drive上に保存するほうが高速です。\n",
        "\n",
        "## 準備１  chainer のインストール\n",
        "\n",
        "このプログラムを実行するには以下の科学系ライブラリが必要です。\n",
        "\n",
        "- numpy\n",
        "- PIL\n",
        "- pandas\n",
        "- matplotlib\n",
        "- pickle\n",
        "- sklearn\n",
        "- jupyter notebook \n",
        "- chainer\n",
        "\n",
        "chainer 以外は Anaconda に標準で入っています。これを見ている時点で jupyter は動いているわけですし、おそらく他のライブラリは導入済みのはずですので、 chainer だけ追加で導入すれば OK です。\n",
        "\n",
        "### chainer のインストール\n",
        "\n",
        "Windowsの場合は、スタートメニューから **Anaconda Prompt** を起動して下さい。おそらくcommand prompt でも大丈夫です。Mac や Linux の場合はターミナルです。\n",
        "\n",
        "> ` pip install chainer `\n",
        "\n",
        "を実行するだけで、chainer のインストールが進むはずです。インストールが始まらないとしたら python の環境ができていないということです。\n",
        "\n",
        "自分のパソコンで実行したい人は Anaconda を導入しましょう。簡単に導入できます。ググって下さい。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKyXNnY57eRw",
        "colab_type": "text"
      },
      "source": [
        "## 準備２　Google Drive をマウント\n",
        "自分の Google Drive をマウントしてプログラムからアクセスできるようにしましょう。\n",
        "\n",
        "セルを実行するとリンクが表示されますので、アクセスを許可してください。認証コードが表示されたらコピーし、ボックス内に貼り付けて Enter してください。\n",
        "\n",
        "暫く待つと、左のファイルツリーに \"**gdrive/My Drive**\"　というフォルダが現れます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cttl6_Fj6jb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Drive にマウントする\n",
        "from google import colab\n",
        "colab.drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TNTVpi_7Z5o",
        "colab_type": "text"
      },
      "source": [
        "## 準備２  ◯CIFAR-100画像データベースのダウンロード\n",
        "\n",
        "- [The CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "上記リンクをたどると、[CIFAR-100 python version](https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz) というダウンロードリンクが見つかります。\n",
        "\n",
        "下のセルは、このデータファイルをダウンロードして解凍するプログラムです。実行すると、 cifar-100-python というフォルダに\n",
        "\n",
        "- train 訓練用データ 50000画像\n",
        "- test  テスト用データ 10000画像\n",
        "\n",
        "が現れます。解凍には少し時間がかかります。左に cifar-100-python のフォルダが現れたら解凍完了です。\n",
        "\n",
        "これらは、28x28 ピクセルの小さなカラー画像が集まったファイルで、ダブルクリックしても画像は表示されませんので注意してください。\n",
        "\n",
        "cifar-100-python フォルダはセッション終了後に削除されてしまうので、プログラムの最後の行で、google drive にコピーしています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P_RHOJSu9QA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR-100 のデータをダウンロードし、Google Drive に保存\n",
        "import urllib.request\n",
        "import os\n",
        "url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
        "filename = os.path.basename(url)\n",
        "# CIFAR-100-python データのダウンロード\n",
        "urllib.request.urlretrieve(url,filename)\n",
        "# 解凍 して Google Drive の CIFAR100 フォルダに保存\n",
        "!tar zxvf cifar-100-python.tar.gz\n",
        "!cp cifar-100-python/* 'gdrive/My Drive/CIFAR100'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU3rJ3_L9rGD",
        "colab_type": "text"
      },
      "source": [
        "# 訓練データとテストデータのpython データへの復元\n",
        "train と test はpythonの変数の状態をそのままデータファイルとして保存する pickle という形式で外部ファイル化したものです。これを unpickle することで、変数に戻します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3toOXTcx9es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "trainDB = unpickle(\"gdrive/My Drive/CIFAR100/train\")\n",
        "testDB = unpickle(\"gdrive/My Drive/CIFAR100/test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDBL5h3n-46d",
        "colab_type": "text"
      },
      "source": [
        "trainDB は５００００、testDB は 10000の画像データに加えて、正解ラベルなどがパッケージされた構造体変数です。プログラムではそれをバラバラに取り出す必要があります。そのためのキーを確認します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svXJrQiV9ydf",
        "colab_type": "text"
      },
      "source": [
        "## キーの確認\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ipEQ5mGx9ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDB.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAULTHie_ron",
        "colab_type": "text"
      },
      "source": [
        "## data というキーに記録されている情報のうち、最初のものを表示してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5jq72b0x9ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainDB[b'data'][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7oYIEz2_-2j",
        "colab_type": "text"
      },
      "source": [
        "# 画像として表示するための関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBlvL4NHx9e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (カラー, たて、よこ)　形式のデータを PIL 画像に変換\n",
        "def blob2img(blob):\n",
        "    return Image.fromarray(np.dstack(blob))\n",
        "\n",
        "# 　3072次元ベクトルを(3,32,32)構造にリシェイプ\n",
        "def flat2image(flat):\n",
        "    return blob2img(flat.reshape((3,32,32)))\n",
        "\n",
        "# データ・セットの i 番目のデータを取り出して画像化\n",
        "def getimage(data,i):\n",
        "    return blob2img(data[b'data'][i].reshape((3,32,32)))\n",
        "\n",
        "# データ・セットの start 番目から最大100画像分を表示\n",
        "def showimage(data, start=0):\n",
        "    canvas = Image.new('RGB',(350,350),(255,255,255))\n",
        "    dsize = len(data[list(data.keys())[0]]) # 格納されているデータ数\n",
        "    end = start + 100\n",
        "    if start + 100 > dsize:\n",
        "        end = dsize\n",
        "    for i in range(10):\n",
        "        for j in range(10):\n",
        "            n = start+i*10+j\n",
        "            if n >= end:\n",
        "                break\n",
        "            else:\n",
        "                canvas.paste(getimage(data,start+i*10+j),(35*j,35*i))\n",
        "    return canvas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inLDWywZx9e2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showimage(testDB,324) # テスト画像の324番目から100枚表示"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7q-Kmdkx9e4",
        "colab_type": "text"
      },
      "source": [
        "CIFAR-100 画像データベースの画像は0〜9の大分類番号と0~99の詳細分類番号がつけられています。カテゴリ番号と日本語の意味の対応表を用意しました。　⇒ **taxonomy.txt**\n",
        "\n",
        "全カテゴリの表を一番下につけてあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho4JFeCDAejT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# taxonomy.txt のダウンロード\n",
        "url = \"https://raw.githubusercontent.com/iciromaco/MLLesson/master/ML08%20%E4%B8%80%E8%88%AC%E7%89%A9%E4%BD%93%E8%AA%8D%E8%AD%98/cifar-100/taxonomy.txt\"\n",
        "filename = os.path.basename(url)\n",
        "# taxonomy.txt データのダウンロード\n",
        "urllib.request.urlretrieve(url,\"/content/\"+filename)\n",
        "!cp taxonomy.txt 'gdrive/My Drive/CIFAR100'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KSuUWqXx9e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  カテゴリ表の表示\n",
        "taxonomy = pd.read_csv(\"taxonomy.txt\", header=0)\n",
        "taxonomy = taxonomy.drop('id',axis=1)\n",
        "taxonomy.head(10)  # 上から８つ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIcOWGgVx9e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 名称からid を調べる関数\n",
        "def word2fcat(word):\n",
        "    return taxonomy[taxonomy['fword']==word]['fcat'].iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kURmpa4jx9e8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2fcat('芝刈り機')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z-6ob6Wx9e-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 詳細名 cat の画像データのみを全て抽出する関数\n",
        "def getCat(data,cat):\n",
        "    flabels = data[b'fine_labels']\n",
        "    images = data[b'data']\n",
        "    extract = []\n",
        "    id = word2fcat(cat)\n",
        "    for fl, img in zip(flabels,images):\n",
        "        if fl == id :\n",
        "            extract.append(img)  \n",
        "    return extract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "EK3rZQeyx9fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# blobs画像データを start 番から npic 枚表示する関数\n",
        "def showBimages(blobs, start=0, npic=100):  # start番目からnpic枚表示\n",
        "    dsize = len(blobs)\n",
        "    limit = start + npic\n",
        "    if limit > dsize:\n",
        "        limit = dsize\n",
        "        npic = limit - start\n",
        "    rows  =  (npic-1)//10+1\n",
        "    print(npic,\"枚\")\n",
        "    canvas =  Image.new('RGB',(350,35*rows),(255,255,255))\n",
        "    n = start\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while n < limit:\n",
        "        canvas.paste(flat2image(blobs[start+i*10+j]),(35*j,35*i))\n",
        "        j +=1\n",
        "        if j == 10:\n",
        "            i, j = i+1,0\n",
        "        n +=1\n",
        "    return canvas\n",
        "\n",
        "# showBimages(getCat(test,'カワウソ'))\n",
        "# showBimages(getCat(test,'イルカ'))\n",
        "# showBimages(getCat(test,'クジラ'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4AN17Rwx9fD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ｓhowBimages(getCat(testDB,'芝刈り機'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ6Y22X0x9fE",
        "colab_type": "text"
      },
      "source": [
        "# ３カテゴリー識別問題◯\n",
        "\n",
        "チューリップ100枚，ヒマワリ100枚,バラ100枚を選び，計300枚を比を保ったまシャッフルして150枚を訓練に使い，150枚で認識率を出すことにする．\n",
        "\n",
        "下では testデータから 150枚抜き出しているが、train からでもいい。\n",
        "train にはデータが50000枚分もあるので抽出に時間がかかる。\n",
        "test は１万枚なので train から抜き出すより早いが、100カテゴリ100枚ずつしか無い。\n",
        "\n",
        "つまり、testから特定のカテゴリの画像100枚抜き出すということは全部ぬきだぬきだすことになる.\n",
        "\n",
        "◯付きは読むだけでなく必ず実践しましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vIJLYWSx9fF",
        "colab_type": "text"
      },
      "source": [
        "# 1. 識別対象カテゴリーのデータの抽出◯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adbJAjYix9fG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "turip = getCat(testDB,'チューリップ')[0:100]\n",
        "sunflower = getCat(testDB,'ヒマワリ')[0:100]\n",
        "rose = getCat(testDB,'バラ')[0:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emBH6ZC-x9fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showBimages(turip)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6HMFPRzx9fK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showBimages(sunflower)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PF-efuTx9fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showBimages(rose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIFyU-A_x9fO",
        "colab_type": "text"
      },
      "source": [
        "# 2. 学習実験用のデータ作成◯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlnIDE23D4xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseX = np.array(turip+sunflower+rose) # チューリップ、ヒマワリ、バラをひとつにまとめたデータ\n",
        "basey = np.array([0]*100+[1]*100+[2]*100).astype(np.int32) # 正解ラベル\n",
        "baseX.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "3xc1jDQ4x9fQ",
        "colab_type": "text"
      },
      "source": [
        "300はデータ数、3072は次元数＝32ｘ32ｘ3色\n",
        "\n",
        "baseX が画像の配列  個々の画像は全データを１列に並べた３０７２次元ベクトルとして表されている\n",
        "basey がラベル（詳細カテゴリID)の配列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLseNtuLx9fR",
        "colab_type": "text"
      },
      "source": [
        "# 3. 識別実験"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-4uNfRDx9fS",
        "colab_type": "text"
      },
      "source": [
        "# 3.1 ロジスティック回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53lhTlhdx9fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y  = baseX, basey\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import StratifiedShuffleSplit \n",
        "clfLog = linear_model.LogisticRegression(solver='liblinear',multi_class='ovr')\n",
        "\n",
        "#　訓練用と検証用に半々にシャッフル分割\n",
        "ss = StratifiedShuffleSplit(n_splits=10, \n",
        "                  train_size=0.5, \n",
        "                  test_size=0.5)\n",
        "print(\"検証データに対する正答率\")\n",
        "for train_index, test_index in ss.split(X, y):\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    clfLog.fit(X_train, y_train) # 訓練データとその正解ラベルを教師データとして学習を実行する\n",
        "    print(\" {:5.4f}\".format(clfLog.score(X_test, y_test))) # 検証データに対する正解率を算出\n",
        "    # print(clfLog.score(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwG7Nk6Nx9fU",
        "colab_type": "text"
      },
      "source": [
        "ランダムに半分を訓練に使い、残りを検証に使う、という検証方法で10回\n",
        "5~6割の正答率（訓練例の方はおそらく100％）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvj4m_Pyx9fV",
        "colab_type": "text"
      },
      "source": [
        "# 3.2 線形SVM　サポートベクターマシン"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLwVXWxlx9fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y  = baseX, basey\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "clfSVM = svm.LinearSVC(max_iter=2000)\n",
        "\n",
        "ss =  StratifiedShuffleSplit(n_splits=10, train_size=0.5, test_size=0.5) # 10分割して\n",
        "\n",
        "print(\"検証データに対する正答率\")\n",
        "for train_index, test_index in ss.split(X, y):\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    clfSVM.fit(X_train, y_train)\n",
        "    print(\"{:5.4f}\".format(clfSVM.score(X_test, y_test))) # 検証データの正解率\n",
        "    # print(clfSVM.score(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HOTLiRNx9fZ",
        "colab_type": "text"
      },
      "source": [
        "SVMも正解率は５〜６割\n",
        "\n",
        "# 誤認識画像の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIukjAE6x9fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y  = baseX, basey\n",
        "pred = clfSVM.predict(X)\n",
        "print(pred)\n",
        "errimg = []\n",
        "for i in range(300):\n",
        "    if pred[i] !=y[i] :\n",
        "        errimg.append(X[i])\n",
        "showBimages(errimg,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFmH1o5Yx9f3",
        "colab_type": "text"
      },
      "source": [
        "# 3.3 CNN ◯\n",
        "### 準備１　reshape ◯\n",
        "ここまでは、画像データを1次元的に展開して扱ってきたが、CNN では画像を\n",
        "\n",
        "　（チャネル, 高さ, 幅）\n",
        " \n",
        " という形式で入力データとしなければならない。そこでまず、reshape する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "MSu8yKw_x9f4",
        "colab_type": "text"
      },
      "source": [
        "### 準備２ 平均値を引く ◯\n",
        "データ全体のRGBそれぞれの平均値を求めて各データから引いて平均が０になるようにする。\n",
        "必然ではないが、そうした方が収束が早いらしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dxM1k78Bx9f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y  = baseX, basey\n",
        "X_ = X.copy().reshape((300,3,32,32)).astype(np.float32)\n",
        "mean = np.average(np.average(np.average(X_,axis=0),axis=1),axis=1) # RGB それぞれの平均\n",
        "print(\"RGB平均値\",mean)\n",
        "X_[:,0,:,:]=X_[:,0,:,:]-mean[0]\n",
        "X_[:,1,:,:]=X_[:,1,:,:]-mean[1]\n",
        "X_[:,2,:,:]=X_[:,2,:,:]-mean[2] \n",
        "X_ = X_/127.0  # -1〜+1 で表現\n",
        "y = y.astype(np.int32)\n",
        "Pdata = [(x,label) for x,label in zip(X_,y)] # データとラベルのペアデータ\n",
        "baseX_ = X_ # 分離データ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFZ04Bwqx9f6",
        "colab_type": "text"
      },
      "source": [
        "## 準備３ ディープラーニング用のライブラリのインポート◯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWJZSru8x9f6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import chainer\n",
        "from chainer import Variable\n",
        "import chainer.links as L\n",
        "import chainer.functions as F\n",
        "from chainer import optimizers\n",
        "from chainer import training\n",
        "from chainer.datasets import tuple_dataset\n",
        "from chainer.iterators import SerialIterator\n",
        "from chainer import training\n",
        "from chainer.training import trainer, extensions\n",
        "from chainer.dataset import concat_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z88DDRE9x9f8",
        "colab_type": "text"
      },
      "source": [
        "## 3.3.1 典型的なCNN◯\n",
        "\n",
        "1. ３ｘ３畳み込み　32チャネル 　  -> 32x32x32チャネル\n",
        "2. max pooling 2x2 -> 16x16x32チャネル\n",
        "3. ３ｘ３畳み込み　32チャネル　 -> 16x16x32チャネル\n",
        "4. max pooling 2x2 -> 8x8x32チャネル\n",
        "5. 2048ノード全結合  -> 2048ノード\n",
        "6. 1024ノード全結合  -> 1024ノード\n",
        "7. 3ノード全結合 -> 3ノード\n",
        "8.　Softmax 出力\n",
        "\n",
        "畳み込み層と全結合層の活性化関数としては ReLU関数を用いる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq-rm7s0x9f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet(chainer.Chain):\n",
        "    def __init__(self):\n",
        "        super(MyNet,self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv1 = L.Convolution2D(3,32,3,1,1)\n",
        "            self.conv2 = L.Convolution2D(32,32,3,1,1)\n",
        "            self.l1 = L.Linear(2048,1024)\n",
        "            self.l2 = L.Linear(1024,3)\n",
        "\n",
        "    def __call__(self,x):\n",
        "        h = Variable(x)\n",
        "        h = F.relu(self.conv1(h))\n",
        "        h = F.max_pooling_2d(h,2,2)\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.max_pooling_2d(h,2,2)\n",
        "        h = F.dropout(F.relu(self.l1(h)))\n",
        "        if chainer.config.train:\n",
        "            return self.l2(h)\n",
        "        return F.softmax(self.l2(h))\n",
        "    \n",
        "model = MyNet()\n",
        "# model = L.Classifier(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EphFJS_Fx9f-",
        "colab_type": "text"
      },
      "source": [
        "# 訓練例を準備◯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7mc90Jx9f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データをシャッフルして半分をて訓練用、半分をテスト用に分ける\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "ss =  StratifiedShuffleSplit(n_splits=1, train_size=0.5, test_size=0.5) \n",
        "for g1, g2 in ss.split(Pdata, basey):\n",
        "    train = [Pdata[x] for x in g1]\n",
        "    test = [Pdata[x] for x in g2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDTj7cECx9gA",
        "colab_type": "text"
      },
      "source": [
        "# 訓練ループの定義◯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "D7zXKFVgx9gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainloop(model, max_epoch=10, batchsize =10,traintimes = 0):\n",
        "    # batchsize = 10  # バッチサイズ　　データセットをこのサイズに分割し、少しずつ学習する\n",
        "    # max_epoch = 10 #  全訓練データを何回学習するか\n",
        "\n",
        "    train_iter = SerialIterator(train, batch_size=batchsize, shuffle=True)\n",
        "    test_iter = SerialIterator(test, batch_size=batchsize,repeat=False, shuffle=False)\n",
        "\n",
        "    # chainer には典型的な設定で繰り返しトレーニングする trainer という仕組みが用意されている\n",
        "    # updater = training.StandardUpdater(train_iter, optimizer)\n",
        "    # trainer = training.Trainer(updater, (2, 'epoch'), out='result')\n",
        "    # 今回は使わないで自分で定義することにする。\n",
        "\n",
        "    print('epoc   train_loss      train_accuracy      test_loss      test_accuracy')\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    rec =[]\n",
        "    \n",
        "    while train_iter.epoch < max_epoch:\n",
        "\n",
        "        #  --  ここから訓練のフェーズ\n",
        "        train_batch = train_iter.next()  # バッチ単位で例を取り出す\n",
        "        X, y = concat_examples(train_batch)  # データとラベルに分離\n",
        "    \n",
        "        pred = model(X)  # 現時点での出力を求める\n",
        "        loss = F.softmax_cross_entropy(pred, y)  # 現出力と理想出力の交差エントロピーを計算\n",
        "        \n",
        "        train_losses.append(float(loss.data))\n",
        "        train_accuracies.append(float(F.accuracy(pred, y).data))\n",
        "    \n",
        "        model.cleargrads() # 微係数データを初期化\n",
        "        loss.backward() # 誤差を逆伝搬する。\n",
        "    \n",
        "        optimizer.update()  # 　誤差が減るように重みを更新\n",
        "        #  --  訓練のフェーズここまで\n",
        "    \n",
        "        if train_iter.is_new_epoch:   # max_epoch ごとに評価\n",
        "            traintimes += 1\n",
        "            test_losses = []\n",
        "            test_accuracies = []\n",
        "            while True:\n",
        "                test_batch = test_iter.next() # テストデータからバッチ単位分取り出す\n",
        "                X, y = concat_examples(test_batch)  #データとラベルに分離\n",
        "\n",
        "                pred = model(X) # 出力を求める\n",
        "                loss = F.softmax_cross_entropy(pred, y) # 交差エントロピーを計算\n",
        "                test_losses.append(float(loss.data))\n",
        "\n",
        "                # 認識率を計算する\n",
        "                accuracy = F.accuracy(pred, y)\n",
        "                test_accuracies.append(float(accuracy.data))\n",
        "\n",
        "                if test_iter.is_new_epoch:\n",
        "                    test_iter.reset()\n",
        "                    break\n",
        "                        \n",
        "            trm = np.mean(train_losses)\n",
        "            tra = np.mean(train_accuracies)\n",
        "            tem = np.mean(test_losses)\n",
        "            tea = np.mean(test_accuracies)\n",
        "            print(' {:03d}      {:.04f}           {:.04f}'.format(\n",
        "                  train_iter.epoch,trm, tra),end=\"\")\n",
        "            train_loss,  train_accuracies= [], []    \n",
        "            print('                 {:.04f}          {:.04f}'.format(\n",
        "                 tem, tea))\n",
        "            rec.append([train_iter.epoch,trm,tra,tem,tea])\n",
        "    return rec\n",
        "\n",
        "# 誤差の総和（loss）と正解率（accuracy）の学習曲線\n",
        "def showlgraph(rec,showlimit=5):\n",
        "    df = pd.DataFrame(rec,columns=['epoc','train_loss','train_accuracy','test_loss','test_accuracy'])\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.ylim(bottom=0,top=df.max()[1:].max()*1.05)\n",
        "    plt.plot(df['epoc'],df['train_loss'],label='train_loss')\n",
        "    plt.plot(df['epoc'],df['test_loss'],label='test_loss')\n",
        "    plt.plot(df['epoc'],df['train_accuracy'],label='train_accuracy')\n",
        "    plt.plot(df['epoc'],df['test_accuracy'],label='test_accuracy')\n",
        "    plt.title(\"loss & accuracy\")\n",
        "    plt.xlabel(\"epocs\")\n",
        "    plt.legend() \n",
        "    plt.savefig(\"graph.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp50vx5-x9gB",
        "colab_type": "text"
      },
      "source": [
        "# オプティマイザーを作成し、訓練実行◯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M694byuKx9gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyNet() # オプティマイザーを変えるなら model を再定義すべき\n",
        "\n",
        "optimizer = optimizers.Adam()\n",
        "# optimizer = optimizers.AdaGrad()\n",
        "# optimizer = optimizers.SGD()\n",
        "optimizer.setup(model)\n",
        "\n",
        "rec = trainloop(model = model, max_epoch=10, batchsize =10,traintimes = 0)\n",
        "showlgraph(rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1k5VVj5x9gD",
        "colab_type": "text"
      },
      "source": [
        "訓練データの accuracy （正答率）がほぼ１になるのは当然で、大事なのはtest データの方の正答率（test_accuracy)です。選ばれたデータと乱数次第で、だいたい６〜７割の正答率が出ます"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgBYxkq1x9gE",
        "colab_type": "text"
      },
      "source": [
        "# ☆誤り事例を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYKJqAt_x9gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predall  = np.argmax(model(baseX_).data,axis=1)\n",
        "print(predall)\n",
        "errimg = []\n",
        "for i in range(300):\n",
        "    if predall[i] !=basey[i] :\n",
        "        errimg.append(baseX[i])\n",
        "showBimages(errimg,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o8IKATlx9gF",
        "colab_type": "text"
      },
      "source": [
        "# 3.3.2 ３層バックプロパゲーションネット"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7WyMFwVx9gG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet2(chainer.Chain):\n",
        "    def __init__(self):\n",
        "        super(MyNet2,self).__init__()\n",
        "        with self.init_scope():\n",
        "            # self.conv1 = L.Convolution2D(3,32,3,1,1)\n",
        "            self.l1 = L.Linear(3072,32)\n",
        "            self.l2 = L.Linear(32,16)\n",
        "            self.l3 = L.Linear(16,3)\n",
        "\n",
        "    def __call__(self,x):\n",
        "        h = Variable(x)\n",
        "        # h = F.relu(self.conv1(h))\n",
        "        # h = F.max_pooling_2d(h,2,2)\n",
        "        h = F.relu(self.l1(h))\n",
        "        h = F.relu(self.l2(h))\n",
        "        if chainer.config.train:\n",
        "            return self.l3(h)\n",
        "        return F.softmax(self.l3(h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1vojch7x9gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = MyNet2()\n",
        "\n",
        "optimizer = optimizers.Adam()\n",
        "optimizer.setup(model2)\n",
        "\n",
        "rec =trainloop(model = model2, max_epoch=10, batchsize =10,traintimes = 0)\n",
        "showlgraph(rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9qyXKNVx9gI",
        "colab_type": "text"
      },
      "source": [
        "ノード数が中間層１６と少なく設定してあるので、学習は短時間で済みます。\n",
        "６割前半〜運が良ければ７割弱程度の正答率が出ます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWe97nfZx9gJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predall  = np.argmax(model2(baseX_).data,axis=1)\n",
        "print(predall)\n",
        "errimg = []\n",
        "for i in range(300):\n",
        "    if predall[i] !=basey[i] :\n",
        "        errimg.append(baseX[i])\n",
        "showBimages(errimg,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU35RhhFx9gL",
        "colab_type": "text"
      },
      "source": [
        "中間層がたったの16ノードの三層ニューラルネットでもあまり認識率に変わりがなかった"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlmsj-Udx9gL",
        "colab_type": "text"
      },
      "source": [
        "[Batch Normalization：ニューラルネットワークの学習を加速させる汎用的で強力な手法](https://deepage.net/deep_learning/2016/10/26/batch_normalization.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRyER5v6x9gM",
        "colab_type": "text"
      },
      "source": [
        "# 3.3.3 よりディープなCNN\n",
        "畳み込み×２　⇒　プーリング　⇒　畳み込み　　⇒　プーリング　⇒　畳み込み　⇒　プーリング　⇒　全結合３層"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS2kmVTyx9gM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet3(chainer.Chain):\n",
        "    def __init__(self):\n",
        "        super(MyNet3,self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv1 = L.Convolution2D(3,32,3,1,1)\n",
        "            self.conv2 = L.Convolution2D(32,32,3,1,1)\n",
        "            self.bnorm1 = L.BatchNormalization(32)\n",
        "            self.conv3 = L.Convolution2D(32,64,3,1,1)\n",
        "            self.bnorm2 = L.BatchNormalization(64)\n",
        "            self.conv4 = L.Convolution2D(64,128,3,1,1)\n",
        "            self.bnorm3 = L.BatchNormalization(128)\n",
        "            self.l1 = L.Linear(2048,512)\n",
        "            self.bnorm4 = L.BatchNormalization(512)\n",
        "            self.l2 = L.Linear(512,256)\n",
        "            self.bnorm5 = L.BatchNormalization(256)\n",
        "            self.l3 = L.Linear(256,3)\n",
        "\n",
        "    def __call__(self,x):\n",
        "        h = Variable(x)\n",
        "        h = F.relu(self.conv1(h))\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.dropout(h)\n",
        "        h = F.max_pooling_2d(h,2,2)\n",
        "        h = self.bnorm1(h)\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = F.max_pooling_2d(h,2,2)\n",
        "        h = self.bnorm2(h)\n",
        "        h = F.relu(self.conv4(h))\n",
        "        h = F.max_pooling_2d(h,2,2)\n",
        "        h = self.bnorm3(h)\n",
        "        h = F.dropout(F.relu(self.l1(h)))\n",
        "        h = self.bnorm4(h)\n",
        "        h = F.dropout(F.relu(self.l2(h)))\n",
        "        h = self.bnorm5(h)\n",
        "        if chainer.config.train:\n",
        "            return self.l3(h)\n",
        "        return F.softmax(self.l3(h))\n",
        "    \n",
        "model = MyNet3()\n",
        "# model = L.Classifier(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhpQzuSDx9gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = MyNet3()\n",
        "\n",
        "optimizer = optimizers.Adam(0.001)\n",
        "optimizer.setup(model3)\n",
        "\n",
        "rec = trainloop(model = model3, max_epoch=20, batchsize =50,traintimes = 0)\n",
        "showlgraph(rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxyJnwB6x9gP",
        "colab_type": "text"
      },
      "source": [
        "ディープなので時間がかかります。その割にはそれほどパフォーマンスが上がりません。\n",
        "深くなるほどパラメータが増えるのでチューニングが非常に難しいです。\n",
        "\n",
        "それでもこれほど深くても学習が進むようになったのは最近の研究成果の賜物なのです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-RDXAcax9gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 誤りデータの確認\n",
        "predall  = np.argmax(model3(baseX_).data,axis=1)\n",
        "print(predall)\n",
        "errimg = []\n",
        "for i in range(300):\n",
        "    if predall[i] !=basey[i] :\n",
        "        errimg.append(baseX[i])\n",
        "showBimages(errimg,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ-o9OGqx9gR",
        "colab_type": "text"
      },
      "source": [
        "ネットが深くて時間がかかる割に結果はぱっとしない"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_JrSPZTx9gR",
        "colab_type": "text"
      },
      "source": [
        "# 3.3.4 全結合層がないとどうなるか\n",
        "\n",
        "```\n",
        "1. 3x3 　畳み込み×１６\n",
        "2. 7x7 畳み込み×４\n",
        "3.  １と２を合わせたチャネル　\n",
        "  ⇒　4x4 ストライド 2 の max pooling \n",
        "  ⇒　畳み込み 64 \n",
        "  ⇒　4x4 ストライド 2 の max pooling \n",
        "\n",
        "全結合層なし\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvnvTw0ox9gS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNet4(chainer.Chain):\n",
        "    def __init__(self):\n",
        "        super(MyNet4,self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv1 = L.Convolution2D(3,16,3,1,1)\n",
        "            self.conv2 = L.Convolution2D(3,4,7,1,3)\n",
        "            self.conv3 = L.Convolution2D(20,64,1,1)\n",
        "            # self.conv4 = L.Convolution2D(32,64,3,1,1)\n",
        "            self.l2= L.Linear(3136,3)\n",
        "            #self.l2 = L.Linear(256,3)\n",
        "\n",
        "    def __call__(self,x):\n",
        "        h = Variable(x)\n",
        "        h1 = F.relu(self.conv1(h))\n",
        "        h2 = F.relu(self.conv2(h))\n",
        "        h = F.hstack([h1 ,h2])\n",
        "        h = F.max_pooling_2d(h,4,2)\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = F.max_pooling_2d(h,4,2)\n",
        "        # h = F.relu(self.conv4(h))\n",
        "        # h = F.max_pooling_2d(h,2,2)\n",
        "        # h = F.dropout(F.relu(self.l1(h)))\n",
        "        if chainer.config.train:\n",
        "            return self.l2(h)\n",
        "        return F.softmax(self.l2(h))\n",
        "    \n",
        "model = MyNet4()\n",
        "# model = L.Classifier(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sejYk7kbx9gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model4 = MyNet4()\n",
        "\n",
        "optimizer = optimizers.Adam(0.001)  # 学習係数 0.001 がデフォルト\n",
        "optimizer.setup(model4)\n",
        "\n",
        "rec = trainloop(model = model4,max_epoch=20, batchsize =50,traintimes = 0)\n",
        "showlgraph(rec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEJ8oT88x9gY",
        "colab_type": "text"
      },
      "source": [
        "意外なことに、わりと安定したパフォーマンスが得られます。良い学習セットに当たれば７０％を超えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev8lsmW1x9ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predall  = np.argmax(model4(baseX_).data,axis=1)\n",
        "print(predall)\n",
        "errimg = []\n",
        "for i in range(300):\n",
        "    if predall[i] !=basey[i] :\n",
        "        errimg.append(baseX[i])\n",
        "showBimages(errimg,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stogTX4ax9gb",
        "colab_type": "text"
      },
      "source": [
        "??? 正解率が高かったのに正解率が低かった場合より誤り画像の数が多くて、「あれっ？」と思うことがありますが、それは正解率はテスト画像セットに対する値で、ここで表示している誤り画像は訓練画像とテスト画像を合わせた場合の誤りだからです。\n",
        "\n",
        "テスト画像に対する正答率は高いが、訓練画像で誤ってしまうという場合があるわけです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2qHhar6x9gc",
        "colab_type": "text"
      },
      "source": [
        "# ４．別のデータセットでの検証\n",
        "\n",
        "最後に、train （訓練用）50000枚中のチューリップ、ヒマワリ、バラの画像 各 500枚合計1500枚で認識率を出してみよう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q16nS6EMx9gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "turip2 = getCat(trainDB,'チューリップ')\n",
        "sunflower2 = getCat(trainDB,'ヒマワリ')\n",
        "rose2 = getCat(trainDB,'バラ')\n",
        "X2 = np.array(turip2+sunflower2+rose2)\n",
        "y2 = np.array([0]*500+[1]*500+[2]*500).astype(np.int32) # 正解ラベル\n",
        "X2_ = X2.copy().reshape((1500,3,32,32)).astype(np.float32)\n",
        "X2_[:,0,:,:]=X2_[:,0,:,:]-mean[0]\n",
        "X2_[:,1,:,:]=X2_[:,1,:,:]-mean[1]\n",
        "X2_[:,2,:,:]=X2_[:,2,:,:]-mean[2]   # mean は学習用のものを使う\n",
        "X2_ = X2_/127.0  # -1〜+1 で表現\n",
        "\n",
        "predall2  = np.argmax(model4(X2_).data,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "daVK13PAx9ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s1,s2,s3 = 0,0,0\n",
        "\n",
        "for i in range(500):\n",
        "    if predall2[i] != 0:\n",
        "        s1 += 1\n",
        "    if predall2[500+i] != 1:\n",
        "        s2 += 1\n",
        "    if predall2[1000+i] != 2:\n",
        "        s3 += 1\n",
        "\n",
        "print(\"チューリップの誤認識は {} 枚 正解率 {}%\".format(s1, np.round((500-s1)/5,2)))\n",
        "print(\"ヒマワリの誤認識は {} 枚 正解率 {}%\".format(s2, np.round((500-s2)/5,2)))\n",
        "print(\"バラの誤認識は {} 枚 正解率 {}%\".format(s3, np.round((500-s3)/5,2)))\n",
        "\n",
        "es = s1+s2+s3\n",
        "cs = 1500 - es\n",
        "print(\"全枚数 {} 枚中、正解 {} 枚、不正解{}枚、正解率{}%\".format(1500, cs,es,np.round(cs/15,2)) )\n",
        "'''errimg2 = []\n",
        "for i in range(1500):\n",
        "    if predall2[i] !=y2[i] :\n",
        "        errimg2.append(X2[i])\n",
        "showBimages(errimg2,0,len(errimg2))''';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwYIVwrDx9gg",
        "colab_type": "text"
      },
      "source": [
        "学習した枚数が150枚で検証データ150枚での正答率は全体の正答率とほぼ同じでした。\n",
        "画像に統計的な偏りがなかったということと、それを前提として150枚のサンプル調査で全体のパフォーマンスがだいたい予想できているということを意味します。\n",
        "\n",
        "今回はたったの3カテゴリなのにこんなに低い正解率でしたが、CIFAR-100の識別問題は結構難しく、下記の [What is the class of this image ?](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)によれば、世界最高で75％程度の認識率です。もっともそれは100カテゴリでの数字ですが。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvySbRDfx9gg",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 参考文献など\n",
        "\n",
        "実装に関して参考にしたサイト\n",
        "- [chainer tutorial](https://docs.chainer.org/en/latest/tutorial/train_loop.html)\n",
        "- [CIFAR-10, CIFAR-100のデータを読み込む方法](http://qiita.com/supersaiakujin/items/5e9d2b2850e256f99982)\n",
        "\n",
        "CNNの分かりやすい解説\n",
        "- [定番のConvolutional Neural Networkをゼロから理解する](https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html)\n",
        "- [Optimizer についての解説](http://qiita.com/tokkuman/items/1944c00415d129ca0ee9)\n",
        "\n",
        "chainer には CIFAR-10, CIFAR-100のデータを読み込むためのメソッドが用意されているのでそれを使えば一発なのですが、今回はそれを使っていません。\n",
        "\n",
        "さまざまな認識課題とそのチャレンジ状況をまとめてくれているサイト\n",
        "\n",
        "- [What is the class of this image ?](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)\n",
        "\n",
        "- [カテゴリー別アーカイブ: CIFAR-100](http://tensorflow.classcat.com/category/cifar-100/)\n",
        "-- [TensorFlow の各種ドキュメントの翻訳 | TensorFlow の簡単な応用例](http://tensorflow.classcat.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzY4Czlgx9gh",
        "colab_type": "text"
      },
      "source": [
        "# 付録"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOcTStb1x9gh",
        "colab_type": "text"
      },
      "source": [
        "# CIFER-100　のカテゴリ分類\n",
        "|||\n",
        "|:--|:--|\n",
        "|スーパークラス|クラス|\n",
        "|海洋哺乳類|ビーバー, イルカ, カワウソ, アザラシ, クジラ|\n",
        "|魚類|観賞魚, ヒラメ, エイ, サメ, マス|\n",
        "|花|ラン, ポピー, バラ, ヒマワリ, チューリップ|\n",
        "|食品|ボトル, ボウル, カン, カップ, プレート|\n",
        "|果物と野菜|リンゴ, キノコ, オレンジ, ナシ, ピーマン|\n",
        "|家電|時計, キーボード, ランプ, 電話, テレビ|\n",
        "|家具|ベッド, 椅子, ソファー, テーブル, タンス|\n",
        "|昆虫|蜂, 甲虫, 蝶, いも虫, ゴキブリ|\n",
        "|大型肉食獣|クマ, ヒョウ, ライオン, トラ,オオカミ|\n",
        "|屋外の大型建造物|橋, 城, 家, 道, 超高層ビル|\n",
        "|自然シーン|雲, 森, 山, 平原, 海|\n",
        "|草食または雑食の動物|ラクダ, ウシ, チンパンジー, ゾウ, カンガルー|\n",
        "|中型哺乳類|キツネ, ヤマアラシ, フクロネズミ, アライグマ, スカンク|\n",
        "|無脊椎動物（昆虫は除く）|カニ, ロブスター, カタツムリ, クモ, ミミズ|\n",
        "|人|赤ちゃん, 男の子, 女の子, 男性, 女性|\n",
        "|爬虫類|ワニ, 恐竜, トカゲ, ヘビ, カメ|\n",
        "|小型哺乳類|ハムスター, マウス, ウサギ, トガリネズミ, リス|\n",
        "|木|カエデ, カシ, ヤシ, マツ,ヤナギ|\n",
        "|乗り物 1|自転車, バス, オートバイ, ピックアップトラック, 電車|\n",
        "|乗り物 2|芝刈り機, ロケット, 路面電車, タンク, トラクタ|\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "_910KNebx9gi",
        "colab_type": "text"
      },
      "source": [
        "### taxonomy.txt\n",
        "\n",
        "以下が、プログラム中で読み込んでいるカテゴリ表（taxonomy.txt）の内容です。メモ帳等にコピペして taxonomy.txt というファイル名でこのプログラムと同じフォルダに保存して下さい。\n",
        "\n",
        "---\n",
        "\n",
        "```\n",
        "id,ccat,fcat,cword,fword\n",
        "0,0,4,水生哺乳類,ビーバー\n",
        "1,0,30,水生哺乳類,イルカ\n",
        "2,0,55,水生哺乳類,カワウソ\n",
        "3,0,72,水生哺乳類,アザラシ\n",
        "4,0,95,水生哺乳類,クジラ\n",
        "5,1,1,魚,観賞魚\n",
        "6,1,32,魚,ヒラメ\n",
        "7,1,67,魚,エイ\n",
        "8,1,73,魚,サメ\n",
        "9,1,91,魚,マス\n",
        "10,2,54,花,ラン\n",
        "11,2,62,花,ポピー\n",
        "12,2,70,花,バラ\n",
        "13,2,82,花,ヒマワリ\n",
        "14,2,92,花,チューリップ\n",
        "15,3,9,食器,ボトル\n",
        "16,3,10,食器,ボウル\n",
        "17,3,16,食器,缶\n",
        "18,3,28,食器,カップ\n",
        "19,3,61,食器,プレート\n",
        "20,4,0,果物と野菜,リンゴ\n",
        "21,4,51,果物と野菜,キノコ\n",
        "22,4,53,果物と野菜,オレンジ\n",
        "23,4,57,果物と野菜,ナシ\n",
        "24,4,83,果物と野菜,ピーマン\n",
        "25,5,22,家電,時計\n",
        "26,5,39,家電,キーボード\n",
        "27,5,40,家電,ランプ\n",
        "28,5,86,家電,電話\n",
        "29,5,87,家電,テレビ\n",
        "30,6,5,家具,ベッド\n",
        "31,6,20,家具,椅子\n",
        "32,6,25,家具,ソファー\n",
        "33,6,84,家具,テーブル\n",
        "34,6,94,家具,タンス\n",
        "35,7,6,昆虫,蜂\n",
        "36,7,7,昆虫,甲虫\n",
        "37,7,14,昆虫,蝶\n",
        "38,7,18,昆虫,いも虫\n",
        "39,7,24,昆虫,ゴキブリ\n",
        "40,8,3,大型肉食獣,クマ\n",
        "41,8,42,大型肉食獣,ヒョウ\n",
        "42,8,43,大型肉食獣,ライオン\n",
        "43,8,88,大型肉食獣,トラ\n",
        "44,8,97,大型肉食獣,オオカミ\n",
        "45,9,12,屋外の大型建造物,橋\n",
        "46,9,17,屋外の大型建造物,城\n",
        "47,9,37,屋外の大型建造物,家\n",
        "48,9,68,屋外の大型建造物,道路\n",
        "49,9,76,屋外の大型建造物,超高層ビル\n",
        "50,10,23,自然シーン,雲\n",
        "51,10,33,自然シーン,森林\n",
        "52,10,49,自然シーン,山\n",
        "53,10,60,自然シーン,平原\n",
        "54,10,71,自然シーン,海\n",
        "55,11,15,草食または雑食の動物,ヒツジ\n",
        "56,11,19,草食または雑食の動物,ウシ\n",
        "57,11,21,草食または雑食の動物,チンパンジー\n",
        "58,11,31,草食または雑食の動物,ゾウ\n",
        "59,11,38,草食または雑食の動物,カンガルー\n",
        "60,12,34,中型哺乳類,キツネ\n",
        "61,12,63,中型哺乳類,ヤマアラシ\n",
        "62,12,64,中型哺乳類,フクロネズミ\n",
        "63,12,66,中型哺乳類,ラクーン\n",
        "64,12,75,中型哺乳類,スカンク\n",
        "65,13,26,無脊椎動物（昆虫は除く）,カニ\n",
        "66,13,45,無脊椎動物（昆虫は除く）,ロブスター\n",
        "67,13,77,無脊椎動物（昆虫は除く）,カタツムリ\n",
        "68,13,79,無脊椎動物（昆虫は除く）,クモ\n",
        "69,13,99,無脊椎動物（昆虫は除く）,ミミズ\n",
        "70,14,2,人,赤ちゃん\n",
        "71,14,11,人,男の子\n",
        "72,14,35,人,女の子\n",
        "73,14,46,人,男性\n",
        "74,14,98,人,女性\n",
        "75,15,27,爬虫類,クロコダイル\n",
        "76,15,29,爬虫類,恐竜\n",
        "77,15,44,爬虫類,トカゲ\n",
        "78,15,78,爬虫類,ヘビ\n",
        "79,15,93,爬虫類,カメ\n",
        "80,16,36,小型哺乳類,ハムスター\n",
        "81,16,50,小型哺乳類,マウス\n",
        "82,16,65,小型哺乳類,ウサギ\n",
        "83,16,74,小型哺乳類,トガリネズミ\n",
        "84,16,80,小型哺乳類,リス\n",
        "85,17,47,木,カエデ\n",
        "86,17,52,木,カシ\n",
        "87,17,56,木,ヤシ\n",
        "88,17,59,木,マツ\n",
        "89,17,96,木,ヤナギ\n",
        "90,18,8,乗り物1,自転車\n",
        "91,18,13,乗り物1,バス\n",
        "92,18,48,乗り物1,オートバイ\n",
        "93,18,58,乗り物1,ピックアップトラック\n",
        "94,18,90,乗り物1,列車\n",
        "95,19,41,乗り物2,芝刈り機\n",
        "96,19,69,乗り物2,ロケット\n",
        "97,19,81,乗り物2,路面電車\n",
        "98,19,85,乗り物2,タンク\n",
        "99,19,89,乗り物2,トラクター\n",
        "```\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "XkUqYpLmx9gi",
        "colab_type": "text"
      },
      "source": [
        "# 課題\n",
        "1. まず、ここまでのプログラムを上から順に実行し少なくとも、「☆」付きの「☆誤り事例を表示」までは SHIFT+ENTER で実行して下さい。\n",
        "2. 内容を理解して、下のプログラムの「赤ちゃん」「山」「バス」の部分を別のカテゴリに置き換えて、以下を実行し、結果をレポートにまとめて報告する。\n",
        "\n",
        "## 考察すべき事項\n",
        "1. 分類対象カテゴリ　　　認識精度の高い組わせと低い組合せ、なぜそうなのか\n",
        "2. 識別モデル  myNet, myNet2, myNet3, myNet4 、その他\n",
        "3. どのオプティマイザーがよいか\n",
        "\n",
        "表、グラフ、図を貼っただけのものはレポートではありません。\n",
        "課題内容や手順、考察をきちんとした文章を記載すること。\n",
        "\n",
        "また、理解できない言葉や概念は調べること。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdLPCiZ0x9gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "catname1,catname2,catname3 = '赤ちゃん','山','バス' # ←できて当然であまりよろしくない例\n",
        "\n",
        "cat1 = getCat(testDB,catname1) # catname1 の画像データを抽出\n",
        "cat2 = getCat(testDB,catname2) # catname２ の画像データを抽出\n",
        "cat3 = getCat(testDB,catname3) # catname３ の画像データを抽出\n",
        "\n",
        "X3 = np.array(cat1+cat2+cat3)\n",
        "y3 = np.array([0]*100+[1]*100+[2]*100).astype(np.int32) # 正解ラベル\n",
        "\n",
        "X3_ = X3.copy().reshape((300,3,32,32)).astype(np.float32) # ４次元データ化\n",
        "mean3 = np.average(np.average(np.average(X3_,axis=0),axis=1),axis=1) # RGB それぞれの平均\n",
        "print(\"RGB平均値\",mean3)\n",
        "\n",
        "X3_[:,0,:,:]=X3_[:,0,:,:]-mean3[0] # 各データから RGB の平均値を引く。\n",
        "X3_[:,1,:,:]=X3_[:,1,:,:]-mean3[1]\n",
        "X3_[:,2,:,:]=X3_[:,2,:,:]-mean3[2]   \n",
        "X3_ = X3_/127.0  # -1〜+1 の表現に変換\n",
        "\n",
        "Pdata3 = [(x,label) for x,label in zip(X3_,y3)] # データとラベルのペアデータ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVaA15Eux9gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データをシャッフルして半分をて訓練用、半分をテスト用に分ける\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "ss =  StratifiedShuffleSplit(n_splits=5, train_size=0.5, test_size=0.5) \n",
        "for g1, g2 in ss.split(Pdata3, y3):\n",
        "    train = [Pdata3[x] for x in g1]\n",
        "    test = [Pdata3[x] for x in g2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1buVslqx9gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyNet() # <= 認識ネットワークを変えるならここを書き換える\n",
        "\n",
        "# 一番最初の CNN のモデルで　２５エポック（エポックとは全学習データを一通り１度学習すること）\n",
        "# 学習は １度に50 画像分ずつ学習。\n",
        "\n",
        "optimizer = optimizers.Adam(alpha=0.0005, beta1=0.9, beta2=0.999, eps=1e-08)  # 学\n",
        "# optimizer = optimizers.SGD(lr=0.01)\n",
        "# optimizer = optimizers.MomentumSGD(lr=0.01, momentum=0.9)\n",
        "# optimizer = optimizers.RMSpropGraves(lr=0.0001, alpha=0.95, momentum=0.9, eps=0.0001)\n",
        "# optimizer = optimizers.AdaDelta(rho=0.95, eps=1e-06)\n",
        "optimizer.setup(model)\n",
        "trainloop(model = model, max_epoch=20, batchsize =10,traintimes = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fikhFe4Ox9gn",
        "colab_type": "text"
      },
      "source": [
        "### 上に表示されている結果を見出しの行から一番下までマウスで選んで「コピー」し、次のブロックを実行してみて下さい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RQ1Nkugx9gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_clipboard()\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1llY5vQEx9go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if df.size >50:\n",
        "    plt.plot(df['epoc'],df['train_loss'])\n",
        "    plt.plot(df['epoc'],df['test_loss'])\n",
        "    plt.plot(df['epoc'],df['train_accuracy'])\n",
        "    plt.plot(df['epoc'],df['test_accuracy'])\n",
        "    plt.title(\"loss & accuracy\")\n",
        "    plt.xlabel(\"epocs\")\n",
        "    plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-e3KVd0x9gp",
        "colab_type": "text"
      },
      "source": [
        "最後に誤認識された画像を確認しておきましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osvqFQWXx9gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predall  = np.argmax(model(X３_).data,axis=1)\n",
        "print(predall)\n",
        "errimg = []\n",
        "for i in range(300):\n",
        "    if predall[i] !=basey[i] :\n",
        "        errimg.append(X3[i])\n",
        "\n",
        "s1,s2,s3 = 0,0,0\n",
        "for i in range(100):\n",
        "    if predall[i] != 0:\n",
        "        s1 += 1\n",
        "    if predall[100+i] != 1:\n",
        "        s2 += 1\n",
        "    if predall[200+i] != 2:\n",
        "        s3 += 1\n",
        "\n",
        "print(\"{}の誤認識は {} 枚 正解率 {}%\".format(catname1,s1, 100-s1))\n",
        "print(\"{}の誤認識は {} 枚 正解率 {}%\".format(catname2,s2, 100-s2))\n",
        "print(\"{}の誤認識は {} 枚 正解率 {}%\".format(catname3,s3, 100-s3))\n",
        "es = s1+s2+s3\n",
        "cs = 300 - es\n",
        "print(\"全枚数 {} 枚中、正解 {} 枚、不正解{}枚、正解率{}%\".format(300, cs,es,np.round(cs/3,2)) )\n",
        "showBimages(errimg,0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2crpkJ_hx9gr",
        "colab_type": "text"
      },
      "source": [
        "# お疲れ様でした"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uVsUIiRx9gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
