{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIChallenge003-画像の水増し ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/MLLesson/blob/master/ML08%20%E4%B8%80%E8%88%AC%E7%89%A9%E4%BD%93%E8%AA%8D%E8%AD%98/AIChallenge/003_%E7%94%BB%E5%83%8F%E3%81%AE%E6%B0%B4%E5%A2%97%E3%81%97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lraSof5Dlv83"
      },
      "source": [
        "# 0. 準備\n",
        "## 0.1 ハードウェアアクセラレータの設定\n",
        "\n",
        "1. [「AIChallenge001-画像の収集」を済ませておく](https://github.com/aquapathos/BasicAI/blob/master/AIChallenge001_%E7%94%BB%E5%83%8F%E3%81%AE%E5%8F%8E%E9%9B%86.ipynb)\n",
        "\n",
        "2. [「ランタイム」メニューを開く]()\n",
        "3. [「ランタイムのタイプを変更」をクリック]()\n",
        "4. [[「ハードウェアアクセラレータ」で **GPU** を選択し，「保存」]()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D_x2m9coOKC"
      },
      "source": [
        "# 1. Google Drive をマウント\n",
        "AIChallenge001 で保存した画像データを使うために Google Drive に接続します。\n",
        "\n",
        "1. [次のセルを実行する]()\n",
        "2. [リンクと入力フィールドが表示されるのでリンクをクリック]()\n",
        "3. [アクセスリクエストを許可するとアクセス用のコードが表示されるのでコピー]()\n",
        "4. [Enter your authorization code: フィールドに貼り付けて Enter]()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISH2fMainqnu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ7Cr-AupBM7"
      },
      "source": [
        "# ２．　画像の読み込みと表示\n",
        "##  2.1 関数定義\n",
        "001 で使ったプログラムと同じです。　[次のセルを実行]() \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFgbG31MoyqR"
      },
      "source": [
        "import pickle\n",
        "import os,math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "    \n",
        "# pickle 形式で保存された画像データの読み込み\n",
        "def loadCategoryImages(fname, folder = \".\"):\n",
        "    f = open(folder+\"/\"+fname,'rb')\n",
        "    cat = pickle.load(f)\n",
        "    f.close\n",
        "    return cat\n",
        "\n",
        "# 画像データの表示\n",
        "# start番からnpic枚表示する関数を定義\n",
        "plt.rcParams['figure.figsize'] = (12.0, 7.0)\n",
        "def showimg(images, start = 0, npic = 48):\n",
        "    n = npic if len(images) >= start+npic else len(images) - start\n",
        "    plt.figure(figsize=(8,7.5*(math.ceil(n/8))/6),dpi=150)\n",
        "    i = 0\n",
        "    while True:\n",
        "        if i < n :  \n",
        "            plt.subplot((n-1)//8+1,8,i+1)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.imshow(images[start+i][:,:,::-1])\n",
        "            plt.title(\"{}\".format(start+i))\n",
        "            i += 1\n",
        "        else:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0Eb_6vippUp"
      },
      "source": [
        "## 2.2 画像データの読み込みと内容確認\n",
        "\n",
        "先に収集した画像データを読み込み、一部を表示して内容が同じか確認しておきます。　[次のセルを実行]() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zP2kHUDpiaC"
      },
      "source": [
        "GFOLDER = \"drive/My Drive/LDATA\"  # データ保存用のフォルダ名\n",
        "c0img = loadCategoryImages(\"ネコ.pkl\", folder=GFOLDER)\n",
        "c1img = loadCategoryImages(\"イヌ.pkl\", folder=GFOLDER)\n",
        "showimg(c0img,0,16)\n",
        "showimg(c1img,0,16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC0GRUKRLrNn"
      },
      "source": [
        "# データの水増し\n",
        "**[ImageDataGenerator](https://keras.io/ja/preprocessing/image/)** を用いてデータを水増しする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wam8sDSXLoFC"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "def dataInflation1(inimg,num):\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "            rotation_range=0, # 画像をランダムに回転する\n",
        "            width_shift_range=0.2, # ランダムに水平シフト\n",
        "            height_shift_range=0.2, # ランダムに垂直シフト\n",
        "            shear_range=5, # 剪断\n",
        "            zoom_range=0.2, # ランダムにズームする範囲\n",
        "            horizontal_flip=True, # 水平方向に入力をランダムに反転\n",
        "            vertical_flip=True, # 垂直方向に入力をランダムに反転\n",
        "            rescale=1.0 / 255, # 与えられた値をデータに積算する\n",
        "            )\n",
        "    \n",
        "    # 出力先ディレクトリを作成\n",
        "    tmpdir = \"tmp/tmp\"\n",
        "    os.makedirs(tmpdir,exist_ok=True)\n",
        "    inimg = inimg.reshape((1,) + inimg.shape)  # 次元を４次元に（ImageDataGeneratorの仕様)\n",
        "\n",
        "    # 種となる画像から num+1 個のバリエーションを生成 \n",
        "    g = datagen.flow(inimg, batch_size=1, save_to_dir=tmpdir, save_prefix='img', save_format='png')\n",
        "    for i in range(num+1): # すべて成功すればnum-1個で良いのだが、稀に生成に失敗するので２つ余分に作っておく\n",
        "        batch = g.next()\n",
        "\n",
        "    pathes = glob(os.path.join(tmpdir, \"*.png\"))[:num-1]\n",
        "    outimgs = [inimg.reshape(inimg.shape[1:])]\n",
        "    for files in pathes:\n",
        "        img = image.load_img(files)\n",
        "        outimgs.append(np.array(img))\n",
        "    shutil.rmtree(tmpdir)\n",
        "    return np.array(outimgs)\n",
        "\n",
        "def dataInflation(X,num):\n",
        "    Xs = []\n",
        "    for img in X:\n",
        "        Xs.extend(dataInflation1(img,num=num))\n",
        "    return Xs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkkSCAEjM2AM"
      },
      "source": [
        "### 動作確認\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1kllZypV_u3"
      },
      "source": [
        "IMG = dataInflation(c0img,4)\n",
        "showimg(IMG,48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phYxkm4PqTe7"
      },
      "source": [
        "# 3. 学習と認識の実験\n",
        "\n",
        "## 3.1 学習モデル\n",
        "\n",
        "水増しなしの時と同じなので説明省略\n",
        "\n",
        "## 3.2 学習データの作成\n",
        "\n",
        "画像データを訓練用とテスト用に分割し，学習用のデータをXtrainとXtestに分割します．\n",
        "\n",
        "[次のセルを実行]() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW4JXLdsqMSY"
      },
      "source": [
        "#  変数の初期化\n",
        "\n",
        "INFLATION = 24\n",
        "def make_dataset(catalist):\n",
        "    # catlist で与えられた画像データのリストから訓練用とテスト用のデータを作成し，\n",
        "    # Xtrain (訓練用画像), ytrain（訓練例の正解)，Xtrain (テスト用画像), ytrain（テスト画像に対する)，NDATA（1カテゴリ当たりのデータ数）\n",
        "    # 学習に用いるデータ数を、一番データ数の少ないカテゴリのデータ数に合わせる\n",
        "    mindata = np.inf # 十分大きな数\n",
        "    for cat in catalist:\n",
        "        if len(cat) < mindata:\n",
        "            mindata = len(cat)\n",
        "    # ここに到達した時点で、mindata にはもっともデータ数の少ないカテゴリのデータ数が入っている\n",
        "    NDATA = mindata\n",
        "    threer = mindata%3\n",
        "    NDATA = mindata - threer  #  個数を３の倍数となるよう調整\n",
        "\n",
        "    Xtrain,Xtest = [],[]  # 入力画像のリスト\n",
        "    ytrain,ytest = [],[]  #  ラベルのリスト\n",
        "    for cimgs in catalist:\n",
        "        Xtrain = Xtrain + cimgs[0:int(2*NDATA/3)]\n",
        "        Xtest = Xtest + cimgs[int(2*NDATA/3):NDATA]\n",
        "    # 訓練用データXtrainをINFLATION倍に水増し\n",
        "    Xtrain = dataInflation(Xtrain,INFLATION)\n",
        "    for label in range(len(catalist)):\n",
        "        ytrain = ytrain + [label]*int(2*NDATA/3*INFLATION)\n",
        "        ytest = ytest + [label]*int(NDATA/3)\n",
        "\n",
        "    return Xtrain,ytrain,Xtest,ytest,NDATA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvACEF10OL3s"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXADtN5PL9J7"
      },
      "source": [
        "次のプログラムで，**CATALIST = [c1img,c2img]** の部分で認識対象となるカテゴリの画像データを指定する．カテゴリは２つである必要はなく，例えば，４つならば，\n",
        "\n",
        "**CATALIST = [c1img,c2img,c3img,c4img]**   \n",
        "\n",
        "等としてください．　[次のセルを実行]() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqYHgIBZI2BK"
      },
      "source": [
        "CATALIST = [c0img,c1img] # c0img:ネコ，c1img：イヌ\n",
        "Xtrain,ytrain,Xtest,ytest,NDATA = make_dataset(CATALIST) \n",
        "\n",
        "# データ数の確認\n",
        "ntrain = len(Xtrain)\n",
        "ntest  = len(Xtest)\n",
        "print(\"カテゴリ数 {}   1カテゴリ当たりのデータ数 {}\".format(len(CATALIST),NDATA))\n",
        "print(\"訓練用 {} テスト用 {}  　データ総数 {}\".format(ntrain,ntest,ntrain+ntest))\n",
        "\n",
        "# 正解データの確認\n",
        "print(ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiNtQP1PPna5"
      },
      "source": [
        "# model1  全結合２層ネットワーク\n",
        "\n",
        "## モデル定義\n",
        "[以下のセルを順に実行していってください．]() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmefCO_RI58U"
      },
      "source": [
        "# tensorflow2.x を前提としている。1.x の場合、tensorflow.keras を ただの keras に変える。\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers  import Input, Activation, Dropout, Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger,TensorBoard\n",
        "\n",
        "SIZE = 128\n",
        "\n",
        "# 変数の宣言\n",
        "CLASSES= len(CATALIST)  #  カテゴリ数　ここでは　2　\n",
        "DATASIZE = SIZE *  SIZE * 3\n",
        "\n",
        "# Model 1\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(CLASSES, activation='softmax', input_shape=(DATASIZE,)))\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "from IPython.display import Image, display_png\n",
        "#学習モデル図の作成\n",
        "plot_model(model1, to_file='model1.png')\n",
        "display_png(Image('model1.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFPTlM4SSGwp"
      },
      "source": [
        "## ニューラルネットワークの設定と学習の実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynJxHwjZSZdw"
      },
      "source": [
        "model = model1\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).reshape(len(Xtrain),DATASIZE).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=5)   #  訓練用データのロスが改善されなくなったら5エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsfwcfTlSk_7"
      },
      "source": [
        "### 学習過程のグラフ化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2eVo7gaSeYK"
      },
      "source": [
        "from matplotlib import cm\n",
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss') # 誤差\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy') #  正解率\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwfb_a9BS8S_"
      },
      "source": [
        "## 訓練データに対する識別結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlfNMGh-SwSJ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "catnamelist = ['ネコ','イヌ']\n",
        "\n",
        "# 訓練データに対する識別結果\n",
        "def recognitionResult(Xdata, ydata, catnamelist=catnamelist):\n",
        "    ndata = len(Xdata) # データ数\n",
        "    predictT = model.predict(Xdata)\n",
        "    predictT = [np.argmax(n1)  for n1 in predictT]\n",
        "    NCAT = len(CATALIST) # カテゴリ数\n",
        "    ct1 = np.zeros((NCAT,NCAT),np.uint16) # 認識結果集計表\n",
        "    Error = []\n",
        "    for i in range(ndata):\n",
        "        ct1[ydata[i],predictT[i]] += 1\n",
        "        if ydata[i] != predictT[i]:\n",
        "            Error.append([i,ydata[i],predictT[i]])\n",
        "    print(\"誤認識データ（[データ番号, 正解, 認識結果]）\\n {0} \\n　正解率={1:5.1f}　誤り率＝{2:5.1f} %\\n\".format(Error,100*(ndata-len(Error))/ndata,100*len(Error)/ndata))\n",
        "    print(\"正解カテゴリに対する認識結果と正解率\")\n",
        "    crossT1 = pd.concat([pd.DataFrame(catnamelist,columns=['正解カテゴリ']),pd.DataFrame(ct1,columns=catnamelist)],axis=1)\n",
        "    crossT1 = pd.concat([crossT1,pd.DataFrame([np.round(1000*crossT1[cat][i]/ndata*NCAT)/10 for i,cat in enumerate(catnamelist)],columns=['正解率'])],axis=1).set_index('正解カテゴリ')\n",
        "\n",
        "    return Error, crossT1\n",
        "\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kw8t95UTCOB"
      },
      "source": [
        "# 認識間違いの表示\n",
        "plt.rcParams['figure.figsize'] = (12.0, 7.0)\n",
        "def showEimg(errlist, images):\n",
        "    last = len(errlist) if len(errlist) < 48 else 48\n",
        "    if last == 0 : return\n",
        "    plt.figure(figsize=(8,7.5*(math.ceil(last/8))/6),dpi=150)\n",
        "    for i in range(last):\n",
        "            plt.subplot((last-1)//8+1,8,i+1)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.imshow(images[errlist[i][0]][:,:,::-1])\n",
        "            plt.title(\"{}→{}\".format(errlist[i][1],errlist[i][2]))\n",
        "\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:イヌ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUGFyES2TjZF"
      },
      "source": [
        "## テストデータに対する識別結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91avTjbeTO69"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "X = (np.array(Xtest).reshape(len(Xtest),DATASIZE).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=X, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1KOWcnTTpym"
      },
      "source": [
        "# 誤認識したデータの表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:イヌ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYqBeEemUDsu"
      },
      "source": [
        "# model 2　　３層全結合バックプロパゲーションネットワーク（中間層1024ノード）\n",
        "\n",
        "## モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT4L05KST2ZG"
      },
      "source": [
        "# Model 2\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(1024,activation='relu',input_shape=(DATASIZE,)))\n",
        "# model2.add(Dropout(rate=0.5))\n",
        "model2.add(Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "#学習モデル図の作成\n",
        "plot_model(model2, to_file='model2.png')\n",
        "display_png(Image('model2.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etr4S-JwUSL6"
      },
      "source": [
        "## ニューラルネットワークの設定と学習の実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIAMzbaJUJ5H"
      },
      "source": [
        "model = model2\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).reshape(len(Xtrain),DATASIZE).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=5)   #  訓練用データのロスが改善されなくなったら5エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=200,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJBIRVMRWOqb"
      },
      "source": [
        "### 学習過程のグラフ化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB6wwobWUcOA"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss')\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JRvplSqWgHn"
      },
      "source": [
        "## 訓練データに対する識別結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0XHSPxjUlHx"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUkoO-5xVB6W"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:イヌ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IBJfT97WiDG"
      },
      "source": [
        "## テストデータに対する識別結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBatLdYVMYq"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "X = (np.array(Xtest).reshape(len(Xtest),DATASIZE).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=X, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5CfOjbLVRJq"
      },
      "source": [
        "# 誤認識したデータの表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:イヌ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdYODYmQVmt7"
      },
      "source": [
        "# model 3  CNN(畳み込みネットワーク）\n",
        "\n",
        "## モデル定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luqxaqp8Vd20"
      },
      "source": [
        "# Model ３\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3),input_shape=(SIZE, SIZE,3), activation='relu',padding='same'))\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))  # 64 x 64 x 64\n",
        "model3.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))  #  32 x 32 x 128\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(1024, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "model3.add(Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model3.summary()\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer = optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#学習モデル図の作成\n",
        "plot_model(model3, to_file='model3.png')\n",
        "display_png(Image('model3.png'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-VybtBGV4KJ"
      },
      "source": [
        "## ニューラルネットワークの設定と学習の実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Jjj62UVuiZ"
      },
      "source": [
        "model = model3\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=3)   #  訓練用データのロスが改善されなくなったら3エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7k4gIQCWRgf"
      },
      "source": [
        "### 学習過程のグラフ化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFc0xPApV7ZL"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss')\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbRt7bi1Wm-1"
      },
      "source": [
        "## 訓練データに対する識別結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oalp1OeDWSee"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF0CaOsKW2SX"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:イヌ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI50p-u0WpcI"
      },
      "source": [
        "## テストデータに対する識別結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTIxoaZvWn53"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "Xte = (np.array(Xtest).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=Xte, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMe07QepW7oh"
      },
      "source": [
        "showEimg(TestError[:96],Xtest)\n",
        "# 0:ネコ、1:イヌ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaILatxaYRKL"
      },
      "source": [
        "# ネコとカメ\n",
        "\n",
        "イヌの代わりにカメで同じ実験をやってみましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DF7PoLrXDjz"
      },
      "source": [
        "# c0img = loadCategoryImages(\"ネコ.pkl\", folder=GFOLDER)\n",
        "c2img = loadCategoryImages(\"カメ.pkl\", folder=GFOLDER)\n",
        "showimg(c0img,0,16)\n",
        "showimg(c2img,0,16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IABIMRyNb_U-"
      },
      "source": [
        "catnamelist = ['ネコ','カメ']\n",
        "CATALIST=[c0img,c2img] # c0img:ネコ, c2img:カメ\n",
        "\n",
        "# 訓練用とテスト用に分割\n",
        "Xtrain,ytrain,Xtest,ytest,NDATA = make_dataset(CATALIST) \n",
        "\n",
        "# データ数の確認\n",
        "ntrain = len(Xtrain)\n",
        "ntest  = len(Xtest)\n",
        "print(\"カテゴリ数 {}   1カテゴリ当たりのデータ数 {}\".format(len(CATALIST),NDATA))\n",
        "print(\"訓練用 {} テスト用 {}  　データ総数 {}\".format(ntrain,ntest,ntrain+ntest))\n",
        "\n",
        "# 正解データの確認 (ytrainは多すぎるので ytest のみ表示)\n",
        "print(ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt9wjl71qOGV"
      },
      "source": [
        "## model1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfijQMaidDZE"
      },
      "source": [
        "# 変数の宣言\n",
        "CLASSES= len(CATALIST)  #  カテゴリ数　ここでは　2　\n",
        "DATASIZE = SIZE *  SIZE * 3\n",
        "\n",
        "# Model 1\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(CLASSES, activation='softmax', input_shape=(DATASIZE,)))\n",
        "\n",
        "model = model1\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).reshape(len(Xtrain),DATASIZE).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=5)   #  訓練用データのロスが改善されなくなったら5エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzHMMxcdvha"
      },
      "source": [
        "from matplotlib import cm\n",
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss') # 誤差\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy') #  正解率\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuUzkCmjqXtg"
      },
      "source": [
        "## 訓練データに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvZcnT3-dwdK"
      },
      "source": [
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R01EC9GAd9qu"
      },
      "source": [
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnh8YKXHraNP"
      },
      "source": [
        "## テストデータに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxlJYaKDeNLr"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "X = (np.array(Xtest).reshape(len(Xtest),DATASIZE).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=X, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5hVj8D2eZ8O"
      },
      "source": [
        "# 誤認識したデータの表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIcevGpfq5X9"
      },
      "source": [
        "## model2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q39rI2WzejTb"
      },
      "source": [
        "# Model 2\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(1024,activation='relu',input_shape=(DATASIZE,)))\n",
        "# model2.add(Dropout(rate=0.5))\n",
        "model2.add(Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model = model2\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).reshape(len(Xtrain),DATASIZE).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=5)   #  訓練用データのロスが改善されなくなったら2エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NJIf6IZezGl"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss')\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE5YFDO4rDI4"
      },
      "source": [
        "## 訓練データに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGOoEc1pfL3m"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ITQI-vmfUFR"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFYSNxp4f5ZV"
      },
      "source": [
        "## テストデータに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37zLcNKZfoNx"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "X = (np.array(Xtest).reshape(len(Xtest),DATASIZE).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=X, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otjlu61bf_kz"
      },
      "source": [
        "# 誤認識したデータの表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuU_EnrRr9_h"
      },
      "source": [
        "# model3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BveA-hM_gM3C"
      },
      "source": [
        "# Model ３\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3),input_shape=(SIZE, SIZE,3), activation='relu',padding='same'))\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))  # 64 x 64 x 64\n",
        "model3.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))  #  32 x 32 x 128\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(1024, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "model3.add(Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer = optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model = model3\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=3)   #  訓練用データのロスが改善されなくなったら3エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEazEqF9snhz"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss')\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFnB8x65s0Nv"
      },
      "source": [
        "# 訓練データに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTSUQL6ysoV5"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmafZgO6s_Fe"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfk--xZ7tLK9"
      },
      "source": [
        "## テストデータに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb4YizartCgL"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "Xte = (np.array(Xtest).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=Xte, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA-x-jTctlRT"
      },
      "source": [
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2W6WnQjvoSS"
      },
      "source": [
        "# ネコ，イヌ，カメ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csmYLYwqv6L5"
      },
      "source": [
        "## データの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvtN435-tnZE"
      },
      "source": [
        "catnamelist = ['ネコ','イヌ','カメ']\n",
        "CATALIST=[c0img,c1img,c2img] # c0img:ネコ, c1img:イヌ，c2img:カメ\n",
        "\n",
        "# 訓練用とテスト用に分割\n",
        "Xtrain,ytrain,Xtest,ytest,NDATA = make_dataset(CATALIST) \n",
        "\n",
        "# データ数の確認\n",
        "ntrain = len(Xtrain)\n",
        "ntest  = len(Xtest)\n",
        "print(\"カテゴリ数 {}   1カテゴリ当たりのデータ数 {}\".format(len(CATALIST),NDATA))\n",
        "print(\"訓練用 {} テスト用 {}  　データ総数 {}\".format(ntrain,ntest,ntrain+ntest))\n",
        "\n",
        "# 正解データの確認\n",
        "print(ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCGUwUiVxCL2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxbDLEeJwKf0"
      },
      "source": [
        "# 変数の宣言\n",
        "CLASSES= len(CATALIST)  #  カテゴリ数　ここでは　３　\n",
        "DATASIZE = SIZE *  SIZE * 3\n",
        "\n",
        "# Model 1\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(CLASSES, activation='softmax', input_shape=(DATASIZE,)))\n",
        "\n",
        "model = model1\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).reshape(len(Xtrain),DATASIZE).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=5)   #  訓練用データのロスが改善されなくなったら5エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBwlvPAGxOjg"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss')\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_LcHcsQxoFu"
      },
      "source": [
        "## 訓練データに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlrAemKKxYDk"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKMLkFAgx5IX"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:イヌ，2:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afP0pR99y3nE"
      },
      "source": [
        "## テストデータに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b094ZQzwynZu"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "X = (np.array(Xtest).reshape(len(Xtest),DATASIZE).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=X, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHySrUjV1hh0"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:イヌ，2：カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfGRtCzz0Dik"
      },
      "source": [
        "# model2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cISWwuCzFel"
      },
      "source": [
        "# Model 2\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(1024,activation='relu',input_shape=(DATASIZE,)))\n",
        "# model2.add(Dropout(rate=0.5))\n",
        "model2.add(Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model = model2\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).reshape(len(Xtrain),DATASIZE).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=5)   #  訓練用データのロスが改善されなくなったら2エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTv4Sspx0QtZ"
      },
      "source": [
        "## 訓練データに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K57rpYsD0GNB"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPV99Q4Q0U0_"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:イヌ，2:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALpGdlUS0izL"
      },
      "source": [
        "# テストデータに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPOKSLUY0gyo"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "X = (np.array(Xtest).reshape(len(Xtest),DATASIZE).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=X, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n98V87zk018S"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:イヌ，2：カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dhoGwDc2mdP"
      },
      "source": [
        "# model3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xws6Pxot2ErH"
      },
      "source": [
        "# Model ３\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(3, 3),input_shape=(SIZE, SIZE,3), activation='relu',padding='same'))\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))  # 64 x 64 x 64\n",
        "model3.add(Conv2D(128, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))  #  32 x 32 x 128\n",
        "model3.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(1024, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(64, activation='relu'))\n",
        "model3.add(Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer = optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model = model3\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# データを 浮動小数点数に変換し、[0,255] → [0,1] に変換\n",
        "X = (np.array(Xtrain).astype('float32'))/255\n",
        "y = np.array(ytrain).astype('float32')\n",
        "es = EarlyStopping(monitor='loss', patience=3)   #  訓練用データのロスが改善されなくなったら3エポック後に停止\n",
        "tb_cb = TensorBoard(log_dir='tblog', histogram_freq=1, write_graph=True)\n",
        "csv_logger = CSVLogger('training.log')\n",
        "hist = model.fit(X , y,\n",
        "                 epochs=100,\n",
        "                 verbose=1,\n",
        "                 callbacks=[es, csv_logger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AwrUn8c22_b"
      },
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "acc = hist.history['accuracy']\n",
        "loss = hist.history['loss']\n",
        "ax1.plot(range(1, len(loss)+1), loss,color=cm.Set1.colors[0],label='loss')\n",
        "ax2.plot(range(1, len(acc)+1), acc,color=cm.Set1.colors[1],label='accuracy')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj2V7XCK360S"
      },
      "source": [
        "# 訓練データに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS_yAvX03NPp"
      },
      "source": [
        "# 訓練データに対する識別結果\n",
        "TrainError, crossTable = recognitionResult(Xdata=X, ydata=ytrain, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCB_pYtZ3Vbu"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TrainError,Xtrain)\n",
        "# 0:ネコ、1:イヌ，2:カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niNjVzv33z_0"
      },
      "source": [
        "## テストデータに対する識別実験結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay94d9Fi3kz1"
      },
      "source": [
        "# テストデータでの識別結果\n",
        "Xte = (np.array(Xtest).astype('float32'))/255\n",
        "TestError, crossTable = recognitionResult(Xdata=Xte, ydata=ytest, catnamelist=catnamelist)\n",
        "crossTable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgvkb-rQ4IYA"
      },
      "source": [
        "# 誤認識した画像を表示\n",
        "showEimg(TestError,Xtest)\n",
        "# 0:ネコ、1:イヌ，2：カメ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWvYIpwp_g0O"
      },
      "source": [
        "# 課題\n",
        "\n",
        "**水増しなしと水増しありの結果を比較しなさい。**\n",
        "\n",
        "\n",
        "余裕があれば次のような追加実験をしましょう．同じ実験を何度か繰り返し，同じ傾向がみられるかどうか検証すること。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUDEQsYWn76-"
      },
      "source": [
        "i"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}